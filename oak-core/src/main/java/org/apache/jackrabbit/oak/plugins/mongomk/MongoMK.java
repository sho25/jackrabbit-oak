begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|ref
operator|.
name|WeakReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|CheckForNull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nonnull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|api
operator|.
name|MicroKernel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|api
operator|.
name|MicroKernelException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|blobs
operator|.
name|BlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|blobs
operator|.
name|MemoryBlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|json
operator|.
name|JsopReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|json
operator|.
name|JsopStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|json
operator|.
name|JsopTokenizer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|json
operator|.
name|JsopWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|CacheLIRS
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|CacheStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|CacheValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|EmpiricalWeigher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|PathUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|Node
operator|.
name|Children
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|Revision
operator|.
name|RevisionComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|blob
operator|.
name|MongoBlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|util
operator|.
name|TimingDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|util
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|Cache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|Weigher
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|mongodb
operator|.
name|DB
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkNotNull
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkState
import|;
end_import

begin_comment
comment|/**  * A MicroKernel implementation that stores the data in a MongoDB.  */
end_comment

begin_class
specifier|public
class|class
name|MongoMK
implements|implements
name|MicroKernel
implements|,
name|RevisionContext
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MongoMK
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * The threshold where special handling for many child node starts.      */
specifier|static
specifier|final
name|int
name|MANY_CHILDREN_THRESHOLD
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.manyChildren"
argument_list|,
literal|50
argument_list|)
decl_stmt|;
comment|/**      * Enable the LIRS cache.      */
specifier|static
specifier|final
name|boolean
name|LIRS_CACHE
init|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"oak.mongoMK.lirsCache"
argument_list|,
literal|"false"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Do not cache more than this number of children for a document.      */
specifier|private
specifier|static
specifier|final
name|int
name|NUM_CHILDREN_CACHE_LIMIT
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.childrenCacheLimit"
argument_list|,
literal|1000
argument_list|)
decl_stmt|;
comment|/**      * When trying to access revisions that are older than this many      * milliseconds, a warning is logged. The default is one minute.      */
specifier|private
specifier|static
specifier|final
name|int
name|WARN_REVISION_AGE
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.revisionAge"
argument_list|,
literal|60
operator|*
literal|1000
argument_list|)
decl_stmt|;
comment|/**      * Enable background operations      */
specifier|private
specifier|static
specifier|final
name|boolean
name|ENABLE_BACKGROUND_OPS
init|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"oak.mongoMK.backgroundOps"
argument_list|,
literal|"true"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Enable fast diff operations.      */
specifier|private
specifier|static
specifier|final
name|boolean
name|FAST_DIFF
init|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"oak.mongoMK.fastDiff"
argument_list|,
literal|"true"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * How long to remember the relative order of old revision of all cluster      * nodes, in milliseconds. The default is one hour.      */
specifier|private
specifier|static
specifier|final
name|int
name|REMEMBER_REVISION_ORDER_MILLIS
init|=
literal|60
operator|*
literal|60
operator|*
literal|1000
decl_stmt|;
comment|/**      * The delay for asynchronous operations (delayed commit propagation and      * cache update).      */
specifier|protected
name|int
name|asyncDelay
init|=
literal|1000
decl_stmt|;
comment|/**      * Whether this instance is disposed.      */
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
comment|/**      * The MongoDB store (might be used by multiple MongoMKs).      */
specifier|private
specifier|final
name|DocumentStore
name|store
decl_stmt|;
comment|/**      * The MongoDB blob store.      */
specifier|private
specifier|final
name|BlobStore
name|blobStore
decl_stmt|;
comment|/**      * The cluster instance info.      */
specifier|private
specifier|final
name|ClusterNodeInfo
name|clusterNodeInfo
decl_stmt|;
comment|/**      * The unique cluster id, similar to the unique machine id in MongoDB.      */
specifier|private
specifier|final
name|int
name|clusterId
decl_stmt|;
comment|/**      * The splitting point in milliseconds. If a document is split, revisions      * older than this number of milliseconds are moved to a different document.      * The default is 0, meaning documents are never split. Revisions that are      * newer than this are kept in the newest document.      */
specifier|private
specifier|final
name|long
name|splitDocumentAgeMillis
decl_stmt|;
comment|/**      * The node cache.      *      * Key: path@rev, value: node      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|Node
argument_list|>
name|nodeCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeCacheStats
decl_stmt|;
comment|/**      * Child node cache.      *       * Key: path@rev, value: children      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|Node
operator|.
name|Children
argument_list|>
name|nodeChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeChildrenCacheStats
decl_stmt|;
comment|/**      * Diff cache.      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|Diff
argument_list|>
name|diffCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|diffCacheStats
decl_stmt|;
comment|/**      * Child doc cache.      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|NodeDocument
operator|.
name|Children
argument_list|>
name|docChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|docChildrenCacheStats
decl_stmt|;
comment|/**      * The unsaved last revisions. This contains the parents of all changed      * nodes, once those nodes are committed but the parent node itself wasn't      * committed yet. The parents are not immediately persisted as this would      * cause each commit to change all parents (including the root node), which      * would limit write scalability.      *       * Key: path, value: revision.      */
specifier|private
specifier|final
name|UnsavedModifications
name|unsavedLastRevisions
init|=
operator|new
name|UnsavedModifications
argument_list|()
decl_stmt|;
comment|/**      * Set of IDs for documents that may need to be split.      */
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|splitCandidates
init|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
comment|/**      * The last known revision for each cluster instance.      *       * Key: the machine id, value: revision.      */
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastKnownRevision
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
argument_list|()
decl_stmt|;
comment|/**      * The last known head revision. This is the last-known revision.      */
specifier|private
specifier|volatile
name|Revision
name|headRevision
decl_stmt|;
specifier|private
name|Thread
name|backgroundThread
decl_stmt|;
comment|/**      * Enable using simple revisions (just a counter). This feature is useful      * for testing.      */
specifier|private
name|AtomicInteger
name|simpleRevisionCounter
decl_stmt|;
comment|/**      * The comparator for revisions.      */
specifier|private
specifier|final
name|RevisionComparator
name|revisionComparator
decl_stmt|;
comment|/**      * Unmerged branches of this MongoMK instance.      */
comment|// TODO at some point, open (unmerged) branches
comment|// need to be garbage collected (in-memory and on disk)
specifier|private
specifier|final
name|UnmergedBranches
name|branches
decl_stmt|;
specifier|private
name|boolean
name|stopBackground
decl_stmt|;
name|MongoMK
parameter_list|(
name|Builder
name|builder
parameter_list|)
block|{
if|if
condition|(
name|builder
operator|.
name|isUseSimpleRevision
argument_list|()
condition|)
block|{
name|this
operator|.
name|simpleRevisionCounter
operator|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|DocumentStore
name|s
init|=
name|builder
operator|.
name|getDocumentStore
argument_list|()
decl_stmt|;
if|if
condition|(
name|builder
operator|.
name|getTiming
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|TimingDocumentStoreWrapper
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|store
operator|=
name|s
expr_stmt|;
name|this
operator|.
name|blobStore
operator|=
name|builder
operator|.
name|getBlobStore
argument_list|()
expr_stmt|;
name|int
name|cid
init|=
name|builder
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
name|splitDocumentAgeMillis
operator|=
name|builder
operator|.
name|getSplitDocumentAgeMillis
argument_list|()
expr_stmt|;
name|cid
operator|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.clusterId"
argument_list|,
name|cid
argument_list|)
expr_stmt|;
if|if
condition|(
name|cid
operator|==
literal|0
condition|)
block|{
name|clusterNodeInfo
operator|=
name|ClusterNodeInfo
operator|.
name|getInstance
argument_list|(
name|store
argument_list|)
expr_stmt|;
comment|// TODO we should ensure revisions generated from now on
comment|// are never "older" than revisions already in the repository for
comment|// this cluster id
name|cid
operator|=
name|clusterNodeInfo
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|clusterNodeInfo
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|clusterId
operator|=
name|cid
expr_stmt|;
name|this
operator|.
name|revisionComparator
operator|=
operator|new
name|RevisionComparator
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
name|this
operator|.
name|asyncDelay
operator|=
name|builder
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
name|this
operator|.
name|branches
operator|=
operator|new
name|UnmergedBranches
argument_list|(
name|revisionComparator
argument_list|)
expr_stmt|;
comment|//TODO Make stats collection configurable as it add slight overhead
comment|//TODO Expose the stats as JMX beans
name|nodeCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getNodeCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeCache
argument_list|,
literal|"MongoMk-Node"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getNodeCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeChildrenCache
argument_list|,
literal|"MongoMk-NodeChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|diffCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getDiffCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|diffCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|diffCache
argument_list|,
literal|"MongoMk-DiffCache"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getDiffCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getDocChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|docChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|docChildrenCache
argument_list|,
literal|"MongoMk-DocChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getDocChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|init
argument_list|()
expr_stmt|;
comment|// initial reading of the revisions of other cluster nodes
name|backgroundRead
argument_list|()
expr_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|headRevision
argument_list|,
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
name|headRevision
operator|=
name|newRevision
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Initialized MongoMK with clusterNodeId: {}"
argument_list|,
name|clusterId
argument_list|)
expr_stmt|;
block|}
name|void
name|init
parameter_list|()
block|{
name|headRevision
operator|=
name|newRevision
argument_list|()
expr_stmt|;
name|Node
name|n
init|=
name|readNode
argument_list|(
literal|"/"
argument_list|,
name|headRevision
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
comment|// root node is missing: repository is not initialized
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
literal|null
argument_list|,
name|headRevision
argument_list|)
decl_stmt|;
name|n
operator|=
operator|new
name|Node
argument_list|(
literal|"/"
argument_list|,
name|headRevision
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|n
argument_list|)
expr_stmt|;
name|commit
operator|.
name|applyToDocumentStore
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// initialize branchCommits
name|branches
operator|.
name|init
argument_list|(
name|store
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
name|backgroundThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|BackgroundOperation
argument_list|(
name|this
argument_list|,
name|isDisposed
argument_list|)
argument_list|,
literal|"MongoMK background thread"
argument_list|)
expr_stmt|;
name|backgroundThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|backgroundThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/**      * Create a new revision.      *       * @return the revision      */
name|Revision
name|newRevision
parameter_list|()
block|{
if|if
condition|(
name|simpleRevisionCounter
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|Revision
argument_list|(
name|simpleRevisionCounter
operator|.
name|getAndIncrement
argument_list|()
argument_list|,
literal|0
argument_list|,
name|clusterId
argument_list|)
return|;
block|}
return|return
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
return|;
block|}
name|void
name|runBackgroundOperations
parameter_list|()
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|backgroundRenewClusterIdLease
argument_list|()
expr_stmt|;
if|if
condition|(
name|simpleRevisionCounter
operator|!=
literal|null
condition|)
block|{
comment|// only when using timestamp
return|return;
block|}
if|if
condition|(
operator|!
name|ENABLE_BACKGROUND_OPS
operator|||
name|stopBackground
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
try|try
block|{
name|backgroundSplit
argument_list|()
expr_stmt|;
name|backgroundWrite
argument_list|()
expr_stmt|;
name|backgroundRead
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Background operation failed: "
operator|+
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|backgroundRenewClusterIdLease
parameter_list|()
block|{
if|if
condition|(
name|clusterNodeInfo
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|clusterNodeInfo
operator|.
name|renewLease
argument_list|(
name|asyncDelay
argument_list|)
expr_stmt|;
block|}
name|void
name|backgroundRead
parameter_list|()
block|{
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|,
name|asyncDelay
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastRevMap
init|=
name|doc
operator|.
name|getLastRev
argument_list|()
decl_stmt|;
name|boolean
name|hasNewRevisions
init|=
literal|false
decl_stmt|;
comment|// the (old) head occurred first
name|Revision
name|headSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// then we saw this new revision (from another cluster node)
name|Revision
name|otherSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|e
range|:
name|lastRevMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|machineId
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|machineId
operator|==
name|clusterId
condition|)
block|{
continue|continue;
block|}
name|Revision
name|r
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Revision
name|last
init|=
name|lastKnownRevision
operator|.
name|get
argument_list|(
name|machineId
argument_list|)
decl_stmt|;
if|if
condition|(
name|last
operator|==
literal|null
operator|||
name|r
operator|.
name|compareRevisionTime
argument_list|(
name|last
argument_list|)
operator|>
literal|0
condition|)
block|{
name|lastKnownRevision
operator|.
name|put
argument_list|(
name|machineId
argument_list|,
name|r
argument_list|)
expr_stmt|;
name|hasNewRevisions
operator|=
literal|true
expr_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|r
argument_list|,
name|otherSeen
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|hasNewRevisions
condition|)
block|{
comment|// TODO invalidating the whole cache is not really needed,
comment|// instead only those children that are cached could be checked
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
comment|// TODO only invalidate affected items
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
comment|// add a new revision, so that changes are visible
name|Revision
name|r
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
decl_stmt|;
comment|// the latest revisions of the current cluster node
comment|// happened before the latest revisions of other cluster nodes
name|revisionComparator
operator|.
name|add
argument_list|(
name|r
argument_list|,
name|headSeen
argument_list|)
expr_stmt|;
comment|// the head revision is after other revisions
name|headRevision
operator|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
block|}
name|revisionComparator
operator|.
name|purge
argument_list|(
name|Revision
operator|.
name|getCurrentTimestamp
argument_list|()
operator|-
name|REMEMBER_REVISION_ORDER_MILLIS
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|backgroundSplit
parameter_list|()
block|{
for|for
control|(
name|Iterator
argument_list|<
name|String
argument_list|>
name|it
init|=
name|splitCandidates
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|String
name|id
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|UpdateOp
name|op
range|:
name|doc
operator|.
name|split
argument_list|(
name|this
argument_list|)
control|)
block|{
name|NodeDocument
name|before
init|=
name|store
operator|.
name|createOrUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
decl_stmt|;
if|if
condition|(
name|before
operator|!=
literal|null
condition|)
block|{
name|NodeDocument
name|after
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Split operation on {}. Size before: {}, after: {}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|id
block|,
name|before
operator|.
name|getMemory
argument_list|()
block|,
name|after
operator|.
name|getMemory
argument_list|()
block|}
argument_list|)
expr_stmt|;
block|}
block|}
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
name|void
name|backgroundWrite
parameter_list|()
block|{
if|if
condition|(
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|ArrayList
argument_list|<
name|String
argument_list|>
name|paths
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
argument_list|)
decl_stmt|;
comment|// sort by depth (high depth first), then path
name|Collections
operator|.
name|sort
argument_list|(
name|paths
argument_list|,
operator|new
name|Comparator
argument_list|<
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|String
name|o1
parameter_list|,
name|String
name|o2
parameter_list|)
block|{
name|int
name|d1
init|=
name|Utils
operator|.
name|pathDepth
argument_list|(
name|o1
argument_list|)
decl_stmt|;
name|int
name|d2
init|=
name|Utils
operator|.
name|pathDepth
argument_list|(
name|o1
argument_list|)
decl_stmt|;
if|if
condition|(
name|d1
operator|!=
name|d2
condition|)
block|{
return|return
name|Integer
operator|.
name|signum
argument_list|(
name|d1
operator|-
name|d2
argument_list|)
return|;
block|}
return|return
name|o1
operator|.
name|compareTo
argument_list|(
name|o2
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|long
name|now
init|=
name|Revision
operator|.
name|getCurrentTimestamp
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|paths
control|)
block|{
name|Revision
name|r
init|=
name|unsavedLastRevisions
operator|.
name|get
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// FIXME: with below code fragment the root (and other nodes
comment|// 'close' to the root) will not be updated in MongoDB when there
comment|// are frequent changes.
if|if
condition|(
name|Revision
operator|.
name|getTimestampDifference
argument_list|(
name|now
argument_list|,
name|r
operator|.
name|getTimestamp
argument_list|()
argument_list|)
operator|<
name|asyncDelay
condition|)
block|{
continue|continue;
block|}
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
literal|null
argument_list|,
name|r
argument_list|)
decl_stmt|;
name|commit
operator|.
name|touchNode
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|store
operator|.
name|createOrUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|commit
operator|.
name|getUpdateOperationForNode
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|unsavedLastRevisions
operator|.
name|remove
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|dispose
parameter_list|()
block|{
comment|// force background write (with asyncDelay> 0, the root wouldn't be written)
comment|// TODO make this more obvious / explicit
comment|// TODO tests should also work if this is not done
name|asyncDelay
operator|=
literal|0
expr_stmt|;
name|runBackgroundOperations
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|isDisposed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
name|isDisposed
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|backgroundThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
if|if
condition|(
name|clusterNodeInfo
operator|!=
literal|null
condition|)
block|{
name|clusterNodeInfo
operator|.
name|dispose
argument_list|()
expr_stmt|;
block|}
name|store
operator|.
name|dispose
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Disposed MongoMK with clusterNodeId: {}"
argument_list|,
name|clusterId
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Get the node for the given path and revision. The returned object might      * not be modified directly.      *      * @param path      * @param rev      * @return the node      */
name|Node
name|getNode
parameter_list|(
annotation|@
name|Nonnull
name|String
name|path
parameter_list|,
annotation|@
name|Nonnull
name|Revision
name|rev
parameter_list|)
block|{
name|checkRevisionAge
argument_list|(
name|checkNotNull
argument_list|(
name|rev
argument_list|)
argument_list|,
name|checkNotNull
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Node
name|node
init|=
name|nodeCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
name|node
operator|=
name|readNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
expr_stmt|;
if|if
condition|(
name|node
operator|!=
literal|null
condition|)
block|{
name|nodeCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|node
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|node
return|;
block|}
comment|/**      * Enqueue the document with the given id as a split candidate.      *      * @param id the id of the document to check if it needs to be split.      */
name|void
name|addSplitCandidate
parameter_list|(
name|String
name|id
parameter_list|)
block|{
name|splitCandidates
operator|.
name|put
argument_list|(
name|id
argument_list|,
name|id
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|checkRevisionAge
parameter_list|(
name|Revision
name|r
parameter_list|,
name|String
name|path
parameter_list|)
block|{
comment|// TODO only log if there are new revisions available for the given node
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|headRevision
operator|.
name|getTimestamp
argument_list|()
operator|-
name|r
operator|.
name|getTimestamp
argument_list|()
operator|>
name|WARN_REVISION_AGE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Requesting an old revision for path "
operator|+
name|path
operator|+
literal|", "
operator|+
operator|(
operator|(
name|headRevision
operator|.
name|getTimestamp
argument_list|()
operator|-
name|r
operator|.
name|getTimestamp
argument_list|()
operator|)
operator|/
literal|1000
operator|)
operator|+
literal|" seconds old"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Checks that revision x is newer than another revision.      *       * @param x the revision to check      * @param previous the presumed earlier revision      * @return true if x is newer      */
name|boolean
name|isRevisionNewer
parameter_list|(
annotation|@
name|Nonnull
name|Revision
name|x
parameter_list|,
annotation|@
name|Nonnull
name|Revision
name|previous
parameter_list|)
block|{
return|return
name|revisionComparator
operator|.
name|compare
argument_list|(
name|x
argument_list|,
name|previous
argument_list|)
operator|>
literal|0
return|;
block|}
specifier|public
name|long
name|getSplitDocumentAgeMillis
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitDocumentAgeMillis
return|;
block|}
specifier|public
name|Children
name|getChildren
parameter_list|(
specifier|final
name|String
name|path
parameter_list|,
specifier|final
name|Revision
name|rev
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|)
throws|throws
name|MicroKernelException
block|{
name|checkRevisionAge
argument_list|(
name|rev
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Children
name|children
decl_stmt|;
try|try
block|{
name|children
operator|=
name|nodeChildrenCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|Children
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Children
name|call
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|readChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|limit
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Error occurred while fetching children nodes for path "
operator|+
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|//In case the limit> cached children size and there are more child nodes
comment|//available then refresh the cache
if|if
condition|(
name|children
operator|.
name|hasMore
condition|)
block|{
if|if
condition|(
name|limit
operator|>
name|children
operator|.
name|children
operator|.
name|size
argument_list|()
condition|)
block|{
name|children
operator|=
name|readChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|limit
argument_list|)
expr_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|children
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|children
return|;
block|}
name|Node
operator|.
name|Children
name|readChildren
parameter_list|(
name|String
name|path
parameter_list|,
name|Revision
name|rev
parameter_list|,
name|int
name|limit
parameter_list|)
block|{
comment|// TODO use offset, to avoid O(n^2) and running out of memory
comment|// to do that, use the *name* of the last entry of the previous batch of children
comment|// as the starting point
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|docs
decl_stmt|;
name|Children
name|c
init|=
operator|new
name|Children
argument_list|()
decl_stmt|;
name|int
name|rawLimit
init|=
name|limit
decl_stmt|;
name|Set
argument_list|<
name|Revision
argument_list|>
name|validRevisions
init|=
operator|new
name|HashSet
argument_list|<
name|Revision
argument_list|>
argument_list|()
decl_stmt|;
do|do
block|{
name|c
operator|.
name|children
operator|.
name|clear
argument_list|()
expr_stmt|;
name|c
operator|.
name|hasMore
operator|=
literal|true
expr_stmt|;
name|docs
operator|=
name|readChildren
argument_list|(
name|path
argument_list|,
name|rawLimit
argument_list|)
expr_stmt|;
name|int
name|numReturned
init|=
literal|0
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|numReturned
operator|++
expr_stmt|;
comment|// filter out deleted children
if|if
condition|(
name|doc
operator|.
name|isDeleted
argument_list|(
name|this
argument_list|,
name|rev
argument_list|,
name|validRevisions
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|doc
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
condition|)
block|{
comment|// add to children until limit is reached
name|c
operator|.
name|children
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|numReturned
operator|<
name|rawLimit
condition|)
block|{
comment|// fewer documents returned than requested
comment|// -> no more documents
name|c
operator|.
name|hasMore
operator|=
literal|false
expr_stmt|;
block|}
comment|// double rawLimit for next round
name|rawLimit
operator|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
operator|(
operator|(
name|long
operator|)
name|rawLimit
operator|)
operator|*
literal|2
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
name|c
operator|.
name|hasMore
condition|)
do|;
return|return
name|c
return|;
block|}
annotation|@
name|Nonnull
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|readChildren
parameter_list|(
specifier|final
name|String
name|path
parameter_list|,
name|int
name|limit
parameter_list|)
block|{
name|String
name|from
init|=
name|Utils
operator|.
name|getKeyLowerLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|to
init|=
name|Utils
operator|.
name|getKeyUpperLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|limit
operator|>
name|NUM_CHILDREN_CACHE_LIMIT
condition|)
block|{
comment|// do not use cache
return|return
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
return|;
block|}
comment|// check cache
name|NodeDocument
operator|.
name|Children
name|c
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|c
operator|==
literal|null
operator|||
operator|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
operator|!
name|c
operator|.
name|isComplete
operator|)
condition|)
block|{
name|c
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|docs
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|doc
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
name|c
operator|.
name|childNames
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|c
operator|.
name|isComplete
operator|=
name|docs
operator|.
name|size
argument_list|()
operator|<
name|limit
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
return|return
name|Iterables
operator|.
name|transform
argument_list|(
name|c
operator|.
name|childNames
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|NodeDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|NodeDocument
name|apply
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|String
name|p
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|path
argument_list|,
name|name
argument_list|)
decl_stmt|;
return|return
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|p
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
annotation|@
name|CheckForNull
specifier|private
name|Node
name|readNode
parameter_list|(
name|String
name|path
parameter_list|,
name|Revision
name|readRevision
parameter_list|)
block|{
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|doc
operator|.
name|getNodeAtRevision
argument_list|(
name|this
argument_list|,
name|readRevision
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getHeadRevision
parameter_list|()
throws|throws
name|MicroKernelException
block|{
return|return
name|headRevision
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
annotation|@
name|Nonnull
specifier|public
name|String
name|checkpoint
parameter_list|(
name|long
name|lifetime
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// FIXME: need to signal to the garbage collector that this revision
comment|// should not be collected until the requested lifetime is over
return|return
name|getHeadRevision
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getRevisionHistory
parameter_list|(
name|long
name|since
parameter_list|,
name|int
name|maxEntries
parameter_list|,
name|String
name|path
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// not currently called by oak-core
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Not implemented"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|waitForCommit
parameter_list|(
name|String
name|oldHeadRevisionId
parameter_list|,
name|long
name|timeout
parameter_list|)
throws|throws
name|MicroKernelException
throws|,
name|InterruptedException
block|{
comment|// not currently called by oak-core
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Not implemented"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getJournal
parameter_list|(
name|String
name|fromRevisionId
parameter_list|,
name|String
name|toRevisionId
parameter_list|,
name|String
name|path
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// not currently called by oak-core
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Not implemented"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|diff
parameter_list|(
specifier|final
name|String
name|fromRevisionId
parameter_list|,
specifier|final
name|String
name|toRevisionId
parameter_list|,
specifier|final
name|String
name|path
parameter_list|,
specifier|final
name|int
name|depth
parameter_list|)
throws|throws
name|MicroKernelException
block|{
name|String
name|key
init|=
name|fromRevisionId
operator|+
literal|"-"
operator|+
name|toRevisionId
operator|+
literal|"-"
operator|+
name|path
operator|+
literal|"-"
operator|+
name|depth
decl_stmt|;
try|try
block|{
return|return
name|diffCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|Diff
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Diff
name|call
parameter_list|()
throws|throws
name|Exception
block|{
return|return
operator|new
name|Diff
argument_list|(
name|diffImpl
argument_list|(
name|fromRevisionId
argument_list|,
name|toRevisionId
argument_list|,
name|path
argument_list|,
name|depth
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
operator|.
name|diff
return|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getCause
argument_list|()
operator|instanceof
name|MicroKernelException
condition|)
block|{
throw|throw
operator|(
name|MicroKernelException
operator|)
name|e
operator|.
name|getCause
argument_list|()
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
specifier|synchronized
name|String
name|diffImpl
parameter_list|(
name|String
name|fromRevisionId
parameter_list|,
name|String
name|toRevisionId
parameter_list|,
name|String
name|path
parameter_list|,
name|int
name|depth
parameter_list|)
throws|throws
name|MicroKernelException
block|{
if|if
condition|(
name|fromRevisionId
operator|.
name|equals
argument_list|(
name|toRevisionId
argument_list|)
condition|)
block|{
return|return
literal|""
return|;
block|}
if|if
condition|(
name|depth
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Only depth 0 is supported, depth is "
operator|+
name|depth
argument_list|)
throw|;
block|}
if|if
condition|(
name|path
operator|==
literal|null
operator|||
name|path
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
name|path
operator|=
literal|"/"
expr_stmt|;
block|}
name|Revision
name|fromRev
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|fromRevisionId
argument_list|)
decl_stmt|;
name|Revision
name|toRev
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|toRevisionId
argument_list|)
decl_stmt|;
name|Node
name|from
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|fromRev
argument_list|)
decl_stmt|;
name|Node
name|to
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|toRev
argument_list|)
decl_stmt|;
if|if
condition|(
name|from
operator|==
literal|null
operator|||
name|to
operator|==
literal|null
condition|)
block|{
comment|// TODO implement correct behavior if the node does't/didn't exist
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Diff is only supported if the node exists in both cases"
argument_list|)
throw|;
block|}
name|JsopWriter
name|w
init|=
operator|new
name|JsopStream
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|from
operator|.
name|getPropertyNames
argument_list|()
control|)
block|{
comment|// changed or removed properties
name|String
name|fromValue
init|=
name|from
operator|.
name|getProperty
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|String
name|toValue
init|=
name|to
operator|.
name|getProperty
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fromValue
operator|.
name|equals
argument_list|(
name|toValue
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|toValue
operator|==
literal|null
condition|)
block|{
name|w
operator|.
name|value
argument_list|(
name|toValue
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|w
operator|.
name|encodedValue
argument_list|(
name|toValue
argument_list|)
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|String
name|p
range|:
name|to
operator|.
name|getPropertyNames
argument_list|()
control|)
block|{
comment|// added properties
if|if
condition|(
name|from
operator|.
name|getProperty
argument_list|(
name|p
argument_list|)
operator|==
literal|null
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|p
argument_list|)
operator|.
name|encodedValue
argument_list|(
name|to
operator|.
name|getProperty
argument_list|(
name|p
argument_list|)
argument_list|)
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
comment|// TODO this does not work well for large child node lists
comment|// use a MongoDB index instead
name|int
name|max
init|=
name|MANY_CHILDREN_THRESHOLD
decl_stmt|;
name|Children
name|fromChildren
decl_stmt|,
name|toChildren
decl_stmt|;
name|fromChildren
operator|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|fromRev
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|toChildren
operator|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|toRev
argument_list|,
name|max
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fromChildren
operator|.
name|hasMore
operator|&&
operator|!
name|toChildren
operator|.
name|hasMore
condition|)
block|{
name|diffFewChildren
argument_list|(
name|w
argument_list|,
name|fromChildren
argument_list|,
name|fromRev
argument_list|,
name|toChildren
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|FAST_DIFF
condition|)
block|{
name|diffManyChildren
argument_list|(
name|w
argument_list|,
name|path
argument_list|,
name|fromRev
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|max
operator|=
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
name|fromChildren
operator|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|fromRev
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|toChildren
operator|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|toRev
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|diffFewChildren
argument_list|(
name|w
argument_list|,
name|fromChildren
argument_list|,
name|fromRev
argument_list|,
name|toChildren
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|w
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|private
name|void
name|diffManyChildren
parameter_list|(
name|JsopWriter
name|w
parameter_list|,
name|String
name|path
parameter_list|,
name|Revision
name|fromRev
parameter_list|,
name|Revision
name|toRev
parameter_list|)
block|{
name|long
name|minTimestamp
init|=
name|Math
operator|.
name|min
argument_list|(
name|fromRev
operator|.
name|getTimestamp
argument_list|()
argument_list|,
name|toRev
operator|.
name|getTimestamp
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|minValue
init|=
name|Commit
operator|.
name|getModified
argument_list|(
name|minTimestamp
argument_list|)
decl_stmt|;
name|String
name|fromKey
init|=
name|Utils
operator|.
name|getKeyLowerLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|toKey
init|=
name|Utils
operator|.
name|getKeyUpperLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|list
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|fromKey
argument_list|,
name|toKey
argument_list|,
name|NodeDocument
operator|.
name|MODIFIED
argument_list|,
name|minValue
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|list
control|)
block|{
name|String
name|id
init|=
name|doc
operator|.
name|getId
argument_list|()
decl_stmt|;
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|id
argument_list|)
decl_stmt|;
name|Node
name|fromNode
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|fromRev
argument_list|)
decl_stmt|;
name|Node
name|toNode
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|toRev
argument_list|)
decl_stmt|;
if|if
condition|(
name|fromNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in fromRev
if|if
condition|(
name|toNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in both revisions
comment|// check if different
if|if
condition|(
operator|!
name|fromNode
operator|.
name|getLastRevision
argument_list|()
operator|.
name|equals
argument_list|(
name|toNode
operator|.
name|getLastRevision
argument_list|()
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|p
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// does not exist in toRev -> was removed
name|w
operator|.
name|tag
argument_list|(
literal|'-'
argument_list|)
operator|.
name|value
argument_list|(
name|p
argument_list|)
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// does not exist in fromRev
if|if
condition|(
name|toNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in toRev
name|w
operator|.
name|tag
argument_list|(
literal|'+'
argument_list|)
operator|.
name|key
argument_list|(
name|p
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// does not exist in either revisions
comment|// -> do nothing
block|}
block|}
block|}
block|}
specifier|private
name|void
name|diffFewChildren
parameter_list|(
name|JsopWriter
name|w
parameter_list|,
name|Children
name|fromChildren
parameter_list|,
name|Revision
name|fromRev
parameter_list|,
name|Children
name|toChildren
parameter_list|,
name|Revision
name|toRev
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|childrenSet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|toChildren
operator|.
name|children
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|n
range|:
name|fromChildren
operator|.
name|children
control|)
block|{
if|if
condition|(
operator|!
name|childrenSet
operator|.
name|contains
argument_list|(
name|n
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'-'
argument_list|)
operator|.
name|value
argument_list|(
name|n
argument_list|)
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|Node
name|n1
init|=
name|getNode
argument_list|(
name|n
argument_list|,
name|fromRev
argument_list|)
decl_stmt|;
name|Node
name|n2
init|=
name|getNode
argument_list|(
name|n
argument_list|,
name|toRev
argument_list|)
decl_stmt|;
comment|// this is not fully correct:
comment|// a change is detected if the node changed recently,
comment|// even if the revisions are well in the past
comment|// if this is a problem it would need to be changed
if|if
condition|(
operator|!
name|n1
operator|.
name|getId
argument_list|()
operator|.
name|equals
argument_list|(
name|n2
operator|.
name|getId
argument_list|()
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|n
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|childrenSet
operator|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|fromChildren
operator|.
name|children
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|n
range|:
name|toChildren
operator|.
name|children
control|)
block|{
if|if
condition|(
operator|!
name|childrenSet
operator|.
name|contains
argument_list|(
name|n
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'+'
argument_list|)
operator|.
name|key
argument_list|(
name|n
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
operator|.
name|newline
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|nodeExists
parameter_list|(
name|String
name|path
parameter_list|,
name|String
name|revisionId
parameter_list|)
throws|throws
name|MicroKernelException
block|{
if|if
condition|(
operator|!
name|PathUtils
operator|.
name|isAbsolute
argument_list|(
name|path
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Path is not absolute: "
operator|+
name|path
argument_list|)
throw|;
block|}
name|revisionId
operator|=
name|revisionId
operator|!=
literal|null
condition|?
name|revisionId
else|:
name|headRevision
operator|.
name|toString
argument_list|()
expr_stmt|;
name|Revision
name|rev
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|revisionId
argument_list|)
decl_stmt|;
name|Node
name|n
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
return|return
name|n
operator|!=
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getChildNodeCount
parameter_list|(
name|String
name|path
parameter_list|,
name|String
name|revisionId
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// not currently called by oak-core
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Not implemented"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|String
name|getNodes
parameter_list|(
name|String
name|path
parameter_list|,
name|String
name|revisionId
parameter_list|,
name|int
name|depth
parameter_list|,
name|long
name|offset
parameter_list|,
name|int
name|maxChildNodes
parameter_list|,
name|String
name|filter
parameter_list|)
throws|throws
name|MicroKernelException
block|{
if|if
condition|(
name|depth
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Only depth 0 is supported, depth is "
operator|+
name|depth
argument_list|)
throw|;
block|}
name|revisionId
operator|=
name|revisionId
operator|!=
literal|null
condition|?
name|revisionId
else|:
name|headRevision
operator|.
name|toString
argument_list|()
expr_stmt|;
name|Revision
name|rev
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|revisionId
argument_list|)
decl_stmt|;
name|Node
name|n
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|JsopStream
name|json
init|=
operator|new
name|JsopStream
argument_list|()
decl_stmt|;
name|boolean
name|includeId
init|=
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|contains
argument_list|(
literal|":id"
argument_list|)
decl_stmt|;
name|includeId
operator||=
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|contains
argument_list|(
literal|":hash"
argument_list|)
expr_stmt|;
name|json
operator|.
name|object
argument_list|()
expr_stmt|;
name|n
operator|.
name|append
argument_list|(
name|json
argument_list|,
name|includeId
argument_list|)
expr_stmt|;
name|int
name|max
decl_stmt|;
if|if
condition|(
name|maxChildNodes
operator|==
operator|-
literal|1
condition|)
block|{
name|max
operator|=
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
name|maxChildNodes
operator|=
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
else|else
block|{
comment|// use long to avoid overflows
name|long
name|m
init|=
operator|(
operator|(
name|long
operator|)
name|maxChildNodes
operator|)
operator|+
name|offset
decl_stmt|;
name|max
operator|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|m
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
name|Children
name|c
init|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|max
argument_list|)
decl_stmt|;
for|for
control|(
name|long
name|i
init|=
name|offset
init|;
name|i
operator|<
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|maxChildNodes
operator|--
operator|<=
literal|0
condition|)
block|{
break|break;
block|}
name|String
name|name
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|c
operator|.
name|children
operator|.
name|get
argument_list|(
operator|(
name|int
operator|)
name|i
argument_list|)
argument_list|)
decl_stmt|;
name|json
operator|.
name|key
argument_list|(
name|name
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|c
operator|.
name|hasMore
condition|)
block|{
comment|// TODO use a better way to notify there are more children
name|json
operator|.
name|key
argument_list|(
literal|":childNodeCount"
argument_list|)
operator|.
name|value
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|json
operator|.
name|key
argument_list|(
literal|":childNodeCount"
argument_list|)
operator|.
name|value
argument_list|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|json
operator|.
name|endObject
argument_list|()
expr_stmt|;
return|return
name|json
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|String
name|commit
parameter_list|(
name|String
name|rootPath
parameter_list|,
name|String
name|json
parameter_list|,
name|String
name|baseRevId
parameter_list|,
name|String
name|message
parameter_list|)
throws|throws
name|MicroKernelException
block|{
name|Revision
name|baseRev
decl_stmt|;
if|if
condition|(
name|baseRevId
operator|==
literal|null
condition|)
block|{
name|baseRev
operator|=
name|headRevision
expr_stmt|;
name|baseRevId
operator|=
name|baseRev
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|baseRev
operator|=
name|Revision
operator|.
name|fromString
argument_list|(
name|baseRevId
argument_list|)
expr_stmt|;
block|}
name|JsopReader
name|t
init|=
operator|new
name|JsopTokenizer
argument_list|(
name|json
argument_list|)
decl_stmt|;
name|Revision
name|rev
init|=
name|newRevision
argument_list|()
decl_stmt|;
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
name|baseRev
argument_list|,
name|rev
argument_list|)
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|int
name|r
init|=
name|t
operator|.
name|read
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
name|JsopReader
operator|.
name|END
condition|)
block|{
break|break;
block|}
name|String
name|path
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|rootPath
argument_list|,
name|t
operator|.
name|readString
argument_list|()
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|r
condition|)
block|{
case|case
literal|'+'
case|:
name|t
operator|.
name|read
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
name|t
operator|.
name|read
argument_list|(
literal|'{'
argument_list|)
expr_stmt|;
name|parseAddNode
argument_list|(
name|commit
argument_list|,
name|t
argument_list|,
name|path
argument_list|)
expr_stmt|;
break|break;
case|case
literal|'-'
case|:
name|commit
operator|.
name|removeNode
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|markAsDeleted
argument_list|(
name|path
argument_list|,
name|commit
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|commit
operator|.
name|removeNodeDiff
argument_list|(
name|path
argument_list|)
expr_stmt|;
break|break;
case|case
literal|'^'
case|:
name|t
operator|.
name|read
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
name|String
name|value
decl_stmt|;
if|if
condition|(
name|t
operator|.
name|matches
argument_list|(
name|JsopReader
operator|.
name|NULL
argument_list|)
condition|)
block|{
name|value
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|value
operator|=
name|t
operator|.
name|readRawValue
argument_list|()
operator|.
name|trim
argument_list|()
expr_stmt|;
block|}
name|String
name|p
init|=
name|PathUtils
operator|.
name|getParentPath
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|propertyName
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|commit
operator|.
name|updateProperty
argument_list|(
name|p
argument_list|,
name|propertyName
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|commit
operator|.
name|updatePropertyDiff
argument_list|(
name|p
argument_list|,
name|propertyName
argument_list|,
name|value
argument_list|)
expr_stmt|;
break|break;
case|case
literal|'>'
case|:
block|{
comment|// TODO support moving nodes that were modified within this commit
name|t
operator|.
name|read
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
name|String
name|sourcePath
init|=
name|path
decl_stmt|;
name|String
name|targetPath
init|=
name|t
operator|.
name|readString
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|PathUtils
operator|.
name|isAbsolute
argument_list|(
name|targetPath
argument_list|)
condition|)
block|{
name|targetPath
operator|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|rootPath
argument_list|,
name|targetPath
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|nodeExists
argument_list|(
name|sourcePath
argument_list|,
name|baseRevId
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Node not found: "
operator|+
name|sourcePath
operator|+
literal|" in revision "
operator|+
name|baseRevId
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|nodeExists
argument_list|(
name|targetPath
argument_list|,
name|baseRevId
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Node already exists: "
operator|+
name|targetPath
operator|+
literal|" in revision "
operator|+
name|baseRevId
argument_list|)
throw|;
block|}
name|commit
operator|.
name|moveNode
argument_list|(
name|sourcePath
argument_list|,
name|targetPath
argument_list|)
expr_stmt|;
name|moveNode
argument_list|(
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
literal|'*'
case|:
block|{
comment|// TODO support copying nodes that were modified within this commit
name|t
operator|.
name|read
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
name|String
name|sourcePath
init|=
name|path
decl_stmt|;
name|String
name|targetPath
init|=
name|t
operator|.
name|readString
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|PathUtils
operator|.
name|isAbsolute
argument_list|(
name|targetPath
argument_list|)
condition|)
block|{
name|targetPath
operator|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|rootPath
argument_list|,
name|targetPath
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|nodeExists
argument_list|(
name|sourcePath
argument_list|,
name|baseRevId
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Node not found: "
operator|+
name|sourcePath
operator|+
literal|" in revision "
operator|+
name|baseRevId
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|nodeExists
argument_list|(
name|targetPath
argument_list|,
name|baseRevId
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Node already exists: "
operator|+
name|targetPath
operator|+
literal|" in revision "
operator|+
name|baseRevId
argument_list|)
throw|;
block|}
name|commit
operator|.
name|copyNode
argument_list|(
name|sourcePath
argument_list|,
name|targetPath
argument_list|)
expr_stmt|;
name|copyNode
argument_list|(
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
break|break;
block|}
default|default:
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"token: "
operator|+
operator|(
name|char
operator|)
name|t
operator|.
name|getTokenType
argument_list|()
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|baseRev
operator|.
name|isBranch
argument_list|()
condition|)
block|{
name|rev
operator|=
name|rev
operator|.
name|asBranchRevision
argument_list|()
expr_stmt|;
comment|// remember branch commit
name|Branch
name|b
init|=
name|branches
operator|.
name|getBranch
argument_list|(
name|baseRev
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|==
literal|null
condition|)
block|{
comment|// baseRev is marker for new branch
name|b
operator|=
name|branches
operator|.
name|create
argument_list|(
name|baseRev
operator|.
name|asTrunkRevision
argument_list|()
argument_list|,
name|rev
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|b
operator|.
name|addCommit
argument_list|(
name|rev
argument_list|)
expr_stmt|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// prepare commit
name|commit
operator|.
name|prepare
argument_list|(
name|baseRev
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|b
operator|.
name|removeCommit
argument_list|(
name|rev
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|b
operator|.
name|hasCommits
argument_list|()
condition|)
block|{
name|branches
operator|.
name|remove
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|rev
operator|.
name|toString
argument_list|()
return|;
block|}
else|else
block|{
name|commit
operator|.
name|apply
argument_list|()
expr_stmt|;
name|headRevision
operator|=
name|commit
operator|.
name|getRevision
argument_list|()
expr_stmt|;
return|return
name|rev
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|//------------------------< RevisionContext>-------------------------------
annotation|@
name|Override
specifier|public
name|UnmergedBranches
name|getBranches
parameter_list|()
block|{
return|return
name|branches
return|;
block|}
annotation|@
name|Override
specifier|public
name|UnsavedModifications
name|getPendingModifications
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
return|;
block|}
annotation|@
name|Override
specifier|public
name|RevisionComparator
name|getRevisionComparator
parameter_list|()
block|{
return|return
name|revisionComparator
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|publishRevision
parameter_list|(
name|Revision
name|foreignRevision
parameter_list|,
name|Revision
name|changeRevision
parameter_list|)
block|{
if|if
condition|(
name|revisionComparator
operator|.
name|compare
argument_list|(
name|headRevision
argument_list|,
name|foreignRevision
argument_list|)
operator|>=
literal|0
condition|)
block|{
comment|// already visible
return|return;
block|}
name|int
name|clusterNodeId
init|=
name|foreignRevision
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
if|if
condition|(
name|clusterNodeId
operator|==
name|this
operator|.
name|clusterId
condition|)
block|{
return|return;
block|}
comment|// the (old) head occurred first
name|Revision
name|headSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// then we saw this new revision (from another cluster node)
name|Revision
name|otherSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// and after that, the current change
name|Revision
name|changeSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|foreignRevision
argument_list|,
name|otherSeen
argument_list|)
expr_stmt|;
comment|// TODO invalidating the whole cache is not really needed,
comment|// but how to ensure we invalidate the right part of the cache?
comment|// possibly simply wait for the background thread to pick
comment|// up the changes, but this depends on how often this method is called
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
comment|// the latest revisions of the current cluster node
comment|// happened before the latest revisions of other cluster nodes
name|revisionComparator
operator|.
name|add
argument_list|(
name|headRevision
argument_list|,
name|headSeen
argument_list|)
expr_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|changeRevision
argument_list|,
name|changeSeen
argument_list|)
expr_stmt|;
comment|// the head revision is after other revisions
name|headRevision
operator|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
specifier|private
name|void
name|copyNode
parameter_list|(
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|false
argument_list|,
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|moveNode
parameter_list|(
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|true
argument_list|,
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|moveOrCopyNode
parameter_list|(
name|boolean
name|move
parameter_list|,
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
comment|// TODO Optimize - Move logic would not work well with very move of very large subtrees
comment|// At minimum we can optimize by traversing breadth wise and collect node id
comment|// and fetch them via '$in' queries
comment|// TODO Transient Node - Current logic does not account for operations which are part
comment|// of this commit i.e. transient nodes. If its required it would need to be looked
comment|// into
name|Node
name|n
init|=
name|getNode
argument_list|(
name|sourcePath
argument_list|,
name|commit
operator|.
name|getBaseRevision
argument_list|()
argument_list|)
decl_stmt|;
comment|// Node might be deleted already
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|Node
name|newNode
init|=
operator|new
name|Node
argument_list|(
name|targetPath
argument_list|,
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
decl_stmt|;
name|n
operator|.
name|copyTo
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|move
condition|)
block|{
name|markAsDeleted
argument_list|(
name|sourcePath
argument_list|,
name|commit
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|Node
operator|.
name|Children
name|c
init|=
name|getChildren
argument_list|(
name|sourcePath
argument_list|,
name|commit
operator|.
name|getBaseRevision
argument_list|()
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|srcChildPath
range|:
name|c
operator|.
name|children
control|)
block|{
name|String
name|childName
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|srcChildPath
argument_list|)
decl_stmt|;
name|String
name|destChildPath
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|targetPath
argument_list|,
name|childName
argument_list|)
decl_stmt|;
name|moveOrCopyNode
argument_list|(
name|move
argument_list|,
name|srcChildPath
argument_list|,
name|destChildPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|markAsDeleted
parameter_list|(
name|String
name|path
parameter_list|,
name|Commit
name|commit
parameter_list|,
name|boolean
name|subTreeAlso
parameter_list|)
block|{
name|Revision
name|rev
init|=
name|commit
operator|.
name|getBaseRevision
argument_list|()
decl_stmt|;
name|checkState
argument_list|(
name|rev
operator|!=
literal|null
argument_list|,
literal|"Base revision of commit must not be null"
argument_list|)
expr_stmt|;
name|commit
operator|.
name|removeNode
argument_list|(
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
name|subTreeAlso
condition|)
block|{
comment|// recurse down the tree
comment|// TODO causes issue with large number of children
name|Node
name|n
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
comment|// remove from the cache
name|nodeCache
operator|.
name|invalidate
argument_list|(
name|path
operator|+
literal|"@"
operator|+
name|rev
argument_list|)
expr_stmt|;
if|if
condition|(
name|n
operator|!=
literal|null
condition|)
block|{
name|Node
operator|.
name|Children
name|c
init|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|childPath
range|:
name|c
operator|.
name|children
control|)
block|{
name|markAsDeleted
argument_list|(
name|childPath
argument_list|,
name|commit
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|nodeChildrenCache
operator|.
name|invalidate
argument_list|(
name|n
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Remove the node from the cache
name|nodeCache
operator|.
name|invalidate
argument_list|(
name|path
operator|+
literal|"@"
operator|+
name|rev
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|parseAddNode
parameter_list|(
name|Commit
name|commit
parameter_list|,
name|JsopReader
name|t
parameter_list|,
name|String
name|path
parameter_list|)
block|{
name|Node
name|n
init|=
operator|new
name|Node
argument_list|(
name|path
argument_list|,
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|t
operator|.
name|matches
argument_list|(
literal|'}'
argument_list|)
condition|)
block|{
do|do
block|{
name|String
name|key
init|=
name|t
operator|.
name|readString
argument_list|()
decl_stmt|;
name|t
operator|.
name|read
argument_list|(
literal|':'
argument_list|)
expr_stmt|;
if|if
condition|(
name|t
operator|.
name|matches
argument_list|(
literal|'{'
argument_list|)
condition|)
block|{
name|String
name|childPath
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|path
argument_list|,
name|key
argument_list|)
decl_stmt|;
name|parseAddNode
argument_list|(
name|commit
argument_list|,
name|t
argument_list|,
name|childPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|value
init|=
name|t
operator|.
name|readRawValue
argument_list|()
operator|.
name|trim
argument_list|()
decl_stmt|;
name|n
operator|.
name|setProperty
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
name|t
operator|.
name|matches
argument_list|(
literal|','
argument_list|)
condition|)
do|;
name|t
operator|.
name|read
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
block|}
name|commit
operator|.
name|addNode
argument_list|(
name|n
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNodeDiff
argument_list|(
name|n
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|branch
parameter_list|(
annotation|@
name|Nullable
name|String
name|trunkRevisionId
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// nothing is written when the branch is created, the returned
comment|// revision simply acts as a reference to the branch base revision
name|Revision
name|revision
init|=
name|trunkRevisionId
operator|!=
literal|null
condition|?
name|Revision
operator|.
name|fromString
argument_list|(
name|trunkRevisionId
argument_list|)
else|:
name|headRevision
decl_stmt|;
return|return
name|revision
operator|.
name|asBranchRevision
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|String
name|merge
parameter_list|(
name|String
name|branchRevisionId
parameter_list|,
name|String
name|message
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// TODO improve implementation if needed
name|Revision
name|revision
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|branchRevisionId
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|revision
operator|.
name|isBranch
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Not a branch: "
operator|+
name|branchRevisionId
argument_list|)
throw|;
block|}
comment|// make branch commits visible
name|UpdateOp
name|op
init|=
operator|new
name|UpdateOp
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|Branch
name|b
init|=
name|branches
operator|.
name|getBranch
argument_list|(
name|revision
argument_list|)
decl_stmt|;
name|Revision
name|mergeCommit
init|=
name|newRevision
argument_list|()
decl_stmt|;
name|NodeDocument
operator|.
name|setModified
argument_list|(
name|op
argument_list|,
name|mergeCommit
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Revision
name|rev
range|:
name|b
operator|.
name|getCommits
argument_list|()
control|)
block|{
name|rev
operator|=
name|rev
operator|.
name|asTrunkRevision
argument_list|()
expr_stmt|;
name|NodeDocument
operator|.
name|setRevision
argument_list|(
name|op
argument_list|,
name|rev
argument_list|,
literal|"c-"
operator|+
name|mergeCommit
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|op
operator|.
name|containsMapEntry
argument_list|(
name|NodeDocument
operator|.
name|COLLISIONS
argument_list|,
name|rev
operator|.
name|toString
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|store
operator|.
name|findAndUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
operator|!=
literal|null
condition|)
block|{
comment|// remove from branchCommits map after successful update
name|b
operator|.
name|applyTo
argument_list|(
name|unsavedLastRevisions
argument_list|,
name|mergeCommit
argument_list|)
expr_stmt|;
name|branches
operator|.
name|remove
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Conflicting concurrent change. Update operation failed: "
operator|+
name|op
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// no commits in this branch -> do nothing
block|}
name|headRevision
operator|=
name|mergeCommit
expr_stmt|;
return|return
name|headRevision
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
annotation|@
name|Nonnull
specifier|public
name|String
name|rebase
parameter_list|(
annotation|@
name|Nonnull
name|String
name|branchRevisionId
parameter_list|,
annotation|@
name|Nullable
name|String
name|newBaseRevisionId
parameter_list|)
throws|throws
name|MicroKernelException
block|{
comment|// TODO conflict handling
name|Revision
name|r
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|branchRevisionId
argument_list|)
decl_stmt|;
name|Revision
name|base
init|=
name|newBaseRevisionId
operator|!=
literal|null
condition|?
name|Revision
operator|.
name|fromString
argument_list|(
name|newBaseRevisionId
argument_list|)
else|:
name|headRevision
decl_stmt|;
name|Branch
name|b
init|=
name|branches
operator|.
name|getBranch
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|==
literal|null
condition|)
block|{
comment|// empty branch
return|return
name|base
operator|.
name|asBranchRevision
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
if|if
condition|(
name|b
operator|.
name|getBase
argument_list|()
operator|.
name|equals
argument_list|(
name|base
argument_list|)
condition|)
block|{
return|return
name|branchRevisionId
return|;
block|}
comment|// add a pseudo commit to make sure current head of branch
comment|// has a higher revision than base of branch
name|Revision
name|head
init|=
name|newRevision
argument_list|()
operator|.
name|asBranchRevision
argument_list|()
decl_stmt|;
name|b
operator|.
name|rebase
argument_list|(
name|head
argument_list|,
name|base
argument_list|)
expr_stmt|;
return|return
name|head
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getLength
parameter_list|(
name|String
name|blobId
parameter_list|)
throws|throws
name|MicroKernelException
block|{
try|try
block|{
return|return
name|blobStore
operator|.
name|getBlobLength
argument_list|(
name|blobId
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|(
name|String
name|blobId
parameter_list|,
name|long
name|pos
parameter_list|,
name|byte
index|[]
name|buff
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|MicroKernelException
block|{
try|try
block|{
return|return
name|blobStore
operator|.
name|readBlob
argument_list|(
name|blobId
argument_list|,
name|pos
argument_list|,
name|buff
argument_list|,
name|off
argument_list|,
name|length
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|write
parameter_list|(
name|InputStream
name|in
parameter_list|)
throws|throws
name|MicroKernelException
block|{
try|try
block|{
return|return
name|blobStore
operator|.
name|writeBlob
argument_list|(
name|in
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|DocumentStore
name|getDocumentStore
parameter_list|()
block|{
return|return
name|store
return|;
block|}
specifier|public
name|void
name|setAsyncDelay
parameter_list|(
name|int
name|delay
parameter_list|)
block|{
name|this
operator|.
name|asyncDelay
operator|=
name|delay
expr_stmt|;
block|}
specifier|public
name|int
name|getAsyncDelay
parameter_list|()
block|{
return|return
name|asyncDelay
return|;
block|}
comment|/**      * Apply the changes of a node to the cache.      *       * @param rev the revision      * @param path the path      * @param isNew whether this is a new node      * @param isDelete whether the node is deleted      * @param isWritten whether the MongoDB documented was added / updated      * @param isBranchCommit whether this is from a branch commit      * @param added the list of added child nodes      * @param removed the list of removed child nodes      *      */
specifier|public
name|void
name|applyChanges
parameter_list|(
name|Revision
name|rev
parameter_list|,
name|String
name|path
parameter_list|,
name|boolean
name|isNew
parameter_list|,
name|boolean
name|isDelete
parameter_list|,
name|boolean
name|isWritten
parameter_list|,
name|boolean
name|isBranchCommit
parameter_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
name|added
parameter_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
name|removed
parameter_list|)
block|{
name|UnsavedModifications
name|unsaved
init|=
name|unsavedLastRevisions
decl_stmt|;
if|if
condition|(
name|isBranchCommit
condition|)
block|{
name|Revision
name|branchRev
init|=
name|rev
operator|.
name|asBranchRevision
argument_list|()
decl_stmt|;
name|unsaved
operator|=
name|branches
operator|.
name|getBranch
argument_list|(
name|branchRev
argument_list|)
operator|.
name|getModifications
argument_list|(
name|branchRev
argument_list|)
expr_stmt|;
block|}
comment|// track unsaved modifications of nodes that were not
comment|// written in the commit (implicitly modified parent)
comment|// or any modification if this is a branch commit
if|if
condition|(
operator|!
name|isWritten
operator|||
name|isBranchCommit
condition|)
block|{
name|Revision
name|prev
init|=
name|unsaved
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|prev
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|isRevisionNewer
argument_list|(
name|prev
argument_list|,
name|rev
argument_list|)
condition|)
block|{
comment|// revert
name|unsaved
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|prev
argument_list|)
expr_stmt|;
name|String
name|msg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Attempt to update "
operator|+
literal|"unsavedLastRevision for %s with %s, which is "
operator|+
literal|"older than current %s."
argument_list|,
name|path
argument_list|,
name|rev
argument_list|,
name|prev
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
else|else
block|{
comment|// the document was updated:
comment|// we no longer need to update it in a background process
name|unsaved
operator|.
name|remove
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
name|Children
name|c
init|=
name|nodeChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|path
operator|+
literal|"@"
operator|+
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|isNew
operator|||
operator|(
operator|!
name|isDelete
operator|&&
name|c
operator|!=
literal|null
operator|)
condition|)
block|{
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Children
name|c2
init|=
operator|new
name|Children
argument_list|()
decl_stmt|;
name|TreeSet
argument_list|<
name|String
argument_list|>
name|set
init|=
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|c
operator|!=
literal|null
condition|)
block|{
name|set
operator|.
name|addAll
argument_list|(
name|c
operator|.
name|children
argument_list|)
expr_stmt|;
block|}
name|set
operator|.
name|removeAll
argument_list|(
name|removed
argument_list|)
expr_stmt|;
name|set
operator|.
name|addAll
argument_list|(
name|added
argument_list|)
expr_stmt|;
name|c2
operator|.
name|children
operator|.
name|addAll
argument_list|(
name|set
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|c2
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|added
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|NodeDocument
operator|.
name|Children
name|docChildren
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|docChildren
operator|!=
literal|null
condition|)
block|{
name|int
name|currentSize
init|=
name|docChildren
operator|.
name|childNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|TreeSet
argument_list|<
name|String
argument_list|>
name|names
init|=
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|docChildren
operator|.
name|childNames
argument_list|)
decl_stmt|;
comment|// incomplete cache entries must not be updated with
comment|// names at the end of the list because there might be
comment|// a next name in MongoDB smaller than the one added
if|if
condition|(
operator|!
name|docChildren
operator|.
name|isComplete
condition|)
block|{
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
name|String
name|name
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|higher
argument_list|(
name|name
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|names
operator|.
name|add
argument_list|(
name|name
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// add all
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
name|names
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// any changes?
if|if
condition|(
name|names
operator|.
name|size
argument_list|()
operator|!=
name|currentSize
condition|)
block|{
comment|// create new cache entry with updated names
name|boolean
name|complete
init|=
name|docChildren
operator|.
name|isComplete
decl_stmt|;
name|docChildren
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|docChildren
operator|.
name|isComplete
operator|=
name|complete
expr_stmt|;
name|docChildren
operator|.
name|childNames
operator|.
name|addAll
argument_list|(
name|names
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|docChildren
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|public
name|CacheStats
name|getNodeCacheStats
parameter_list|()
block|{
return|return
name|nodeCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getNodeChildrenCacheStats
parameter_list|()
block|{
return|return
name|nodeChildrenCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getDiffCacheStats
parameter_list|()
block|{
return|return
name|diffCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getDocChildrenCacheStats
parameter_list|()
block|{
return|return
name|docChildrenCacheStats
return|;
block|}
specifier|public
name|ClusterNodeInfo
name|getClusterInfo
parameter_list|()
block|{
return|return
name|clusterNodeInfo
return|;
block|}
specifier|public
name|int
name|getPendingWriteCount
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
name|boolean
name|isCached
parameter_list|(
name|String
name|path
parameter_list|)
block|{
return|return
name|store
operator|.
name|isCached
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|path
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|void
name|stopBackground
parameter_list|()
block|{
name|stopBackground
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * A background thread.      */
specifier|static
class|class
name|BackgroundOperation
implements|implements
name|Runnable
block|{
specifier|final
name|WeakReference
argument_list|<
name|MongoMK
argument_list|>
name|ref
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
decl_stmt|;
specifier|private
name|int
name|delay
decl_stmt|;
name|BackgroundOperation
parameter_list|(
name|MongoMK
name|mk
parameter_list|,
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|ref
operator|=
operator|new
name|WeakReference
argument_list|<
name|MongoMK
argument_list|>
argument_list|(
name|mk
argument_list|)
expr_stmt|;
name|delay
operator|=
name|mk
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
name|this
operator|.
name|isDisposed
operator|=
name|isDisposed
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|delay
operator|!=
literal|0
operator|&&
operator|!
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
try|try
block|{
name|isDisposed
operator|.
name|wait
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
block|}
name|MongoMK
name|mk
init|=
name|ref
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|mk
operator|!=
literal|null
condition|)
block|{
name|mk
operator|.
name|runBackgroundOperations
argument_list|()
expr_stmt|;
name|delay
operator|=
name|mk
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**      * A (cached) result of the diff operation.      */
specifier|private
specifier|static
class|class
name|Diff
implements|implements
name|CacheValue
block|{
specifier|final
name|String
name|diff
decl_stmt|;
name|Diff
parameter_list|(
name|String
name|diff
parameter_list|)
block|{
name|this
operator|.
name|diff
operator|=
name|diff
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getMemory
parameter_list|()
block|{
return|return
name|diff
operator|.
name|length
argument_list|()
operator|*
literal|2
return|;
block|}
block|}
comment|/**      * A builder for a MongoMK instance.      */
specifier|public
specifier|static
class|class
name|Builder
block|{
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MEMORY_CACHE_SIZE
init|=
literal|256
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|private
name|DocumentStore
name|documentStore
decl_stmt|;
specifier|private
name|BlobStore
name|blobStore
decl_stmt|;
specifier|private
name|int
name|clusterId
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.clusterId"
argument_list|,
literal|0
argument_list|)
decl_stmt|;
specifier|private
name|int
name|asyncDelay
init|=
literal|1000
decl_stmt|;
specifier|private
name|boolean
name|timing
decl_stmt|;
specifier|private
name|Weigher
argument_list|<
name|String
argument_list|,
name|CacheValue
argument_list|>
name|weigher
init|=
operator|new
name|EmpiricalWeigher
argument_list|()
decl_stmt|;
specifier|private
name|long
name|nodeCacheSize
decl_stmt|;
specifier|private
name|long
name|childrenCacheSize
decl_stmt|;
specifier|private
name|long
name|diffCacheSize
decl_stmt|;
specifier|private
name|long
name|documentCacheSize
decl_stmt|;
specifier|private
name|long
name|docChildrenCacheSize
decl_stmt|;
specifier|private
name|boolean
name|useSimpleRevision
decl_stmt|;
specifier|private
name|long
name|splitDocumentAgeMillis
init|=
literal|5
operator|*
literal|60
operator|*
literal|1000
decl_stmt|;
specifier|public
name|Builder
parameter_list|()
block|{
name|memoryCacheSize
argument_list|(
name|DEFAULT_MEMORY_CACHE_SIZE
argument_list|)
expr_stmt|;
block|}
comment|/**          * Set the MongoDB connection to use. By default an in-memory store is used.          *           * @param db the MongoDB connection          * @return this          */
specifier|public
name|Builder
name|setMongoDB
parameter_list|(
name|DB
name|db
parameter_list|)
block|{
if|if
condition|(
name|db
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|documentStore
operator|=
operator|new
name|MongoDocumentStore
argument_list|(
name|db
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|blobStore
operator|=
operator|new
name|MongoBlobStore
argument_list|(
name|db
argument_list|)
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
comment|/**          * Use the timing document store wrapper.          *           * @param timing whether to use the timing wrapper.          * @return this          */
specifier|public
name|Builder
name|setTiming
parameter_list|(
name|boolean
name|timing
parameter_list|)
block|{
name|this
operator|.
name|timing
operator|=
name|timing
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|boolean
name|getTiming
parameter_list|()
block|{
return|return
name|timing
return|;
block|}
comment|/**          * Set the document store to use. By default an in-memory store is used.          *           * @param documentStore the document store          * @return this          */
specifier|public
name|Builder
name|setDocumentStore
parameter_list|(
name|DocumentStore
name|documentStore
parameter_list|)
block|{
name|this
operator|.
name|documentStore
operator|=
name|documentStore
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|DocumentStore
name|getDocumentStore
parameter_list|()
block|{
if|if
condition|(
name|documentStore
operator|==
literal|null
condition|)
block|{
name|documentStore
operator|=
operator|new
name|MemoryDocumentStore
argument_list|()
expr_stmt|;
block|}
return|return
name|documentStore
return|;
block|}
comment|/**          * Set the blob store to use. By default an in-memory store is used.          *           * @param blobStore the blob store          * @return this          */
specifier|public
name|Builder
name|setBlobStore
parameter_list|(
name|BlobStore
name|blobStore
parameter_list|)
block|{
name|this
operator|.
name|blobStore
operator|=
name|blobStore
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|BlobStore
name|getBlobStore
parameter_list|()
block|{
if|if
condition|(
name|blobStore
operator|==
literal|null
condition|)
block|{
name|blobStore
operator|=
operator|new
name|MemoryBlobStore
argument_list|()
expr_stmt|;
block|}
return|return
name|blobStore
return|;
block|}
comment|/**          * Set the cluster id to use. By default, 0 is used, meaning the cluster          * id is automatically generated.          *           * @param clusterId the cluster id          * @return this          */
specifier|public
name|Builder
name|setClusterId
parameter_list|(
name|int
name|clusterId
parameter_list|)
block|{
name|this
operator|.
name|clusterId
operator|=
name|clusterId
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|int
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
comment|/**          * Set the maximum delay to write the last revision to the root node. By          * default 1000 (meaning 1 second) is used.          *           * @param asyncDelay in milliseconds          * @return this          */
specifier|public
name|Builder
name|setAsyncDelay
parameter_list|(
name|int
name|asyncDelay
parameter_list|)
block|{
name|this
operator|.
name|asyncDelay
operator|=
name|asyncDelay
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|int
name|getAsyncDelay
parameter_list|()
block|{
return|return
name|asyncDelay
return|;
block|}
specifier|public
name|Weigher
argument_list|<
name|String
argument_list|,
name|CacheValue
argument_list|>
name|getWeigher
parameter_list|()
block|{
return|return
name|weigher
return|;
block|}
specifier|public
name|Builder
name|withWeigher
parameter_list|(
name|Weigher
argument_list|<
name|String
argument_list|,
name|CacheValue
argument_list|>
name|weigher
parameter_list|)
block|{
name|this
operator|.
name|weigher
operator|=
name|weigher
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|Builder
name|memoryCacheSize
parameter_list|(
name|long
name|memoryCacheSize
parameter_list|)
block|{
name|this
operator|.
name|nodeCacheSize
operator|=
name|memoryCacheSize
operator|*
literal|20
operator|/
literal|100
expr_stmt|;
name|this
operator|.
name|childrenCacheSize
operator|=
name|memoryCacheSize
operator|*
literal|10
operator|/
literal|100
expr_stmt|;
name|this
operator|.
name|diffCacheSize
operator|=
name|memoryCacheSize
operator|*
literal|2
operator|/
literal|100
expr_stmt|;
name|this
operator|.
name|docChildrenCacheSize
operator|=
name|memoryCacheSize
operator|*
literal|3
operator|/
literal|100
expr_stmt|;
name|this
operator|.
name|documentCacheSize
operator|=
name|memoryCacheSize
operator|-
name|nodeCacheSize
operator|-
name|childrenCacheSize
operator|-
name|diffCacheSize
operator|-
name|docChildrenCacheSize
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|long
name|getNodeCacheSize
parameter_list|()
block|{
return|return
name|nodeCacheSize
return|;
block|}
specifier|public
name|long
name|getChildrenCacheSize
parameter_list|()
block|{
return|return
name|childrenCacheSize
return|;
block|}
specifier|public
name|long
name|getDocumentCacheSize
parameter_list|()
block|{
return|return
name|documentCacheSize
return|;
block|}
specifier|public
name|long
name|getDocChildrenCacheSize
parameter_list|()
block|{
return|return
name|docChildrenCacheSize
return|;
block|}
specifier|public
name|long
name|getDiffCacheSize
parameter_list|()
block|{
return|return
name|diffCacheSize
return|;
block|}
specifier|public
name|Builder
name|setUseSimpleRevision
parameter_list|(
name|boolean
name|useSimpleRevision
parameter_list|)
block|{
name|this
operator|.
name|useSimpleRevision
operator|=
name|useSimpleRevision
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|boolean
name|isUseSimpleRevision
parameter_list|()
block|{
return|return
name|useSimpleRevision
return|;
block|}
specifier|public
name|Builder
name|setSplitDocumentAgeMillis
parameter_list|(
name|long
name|splitDocumentAgeMillis
parameter_list|)
block|{
name|this
operator|.
name|splitDocumentAgeMillis
operator|=
name|splitDocumentAgeMillis
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|long
name|getSplitDocumentAgeMillis
parameter_list|()
block|{
return|return
name|splitDocumentAgeMillis
return|;
block|}
comment|/**          * Open the MongoMK instance using the configured options.          *           * @return the MongoMK instance          */
specifier|public
name|MongoMK
name|open
parameter_list|()
block|{
return|return
operator|new
name|MongoMK
argument_list|(
name|this
argument_list|)
return|;
block|}
comment|/**          * Create a cache.          *           * @param<V> the value type          * @param maxWeight          * @return the cache          */
specifier|public
parameter_list|<
name|V
extends|extends
name|CacheValue
parameter_list|>
name|Cache
argument_list|<
name|String
argument_list|,
name|V
argument_list|>
name|buildCache
parameter_list|(
name|long
name|maxWeight
parameter_list|)
block|{
if|if
condition|(
name|LIRS_CACHE
condition|)
block|{
return|return
name|CacheLIRS
operator|.
name|newBuilder
argument_list|()
operator|.
name|weigher
argument_list|(
name|weigher
argument_list|)
operator|.
name|maximumWeight
argument_list|(
name|maxWeight
argument_list|)
operator|.
name|recordStats
argument_list|()
operator|.
name|build
argument_list|()
return|;
block|}
return|return
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|weigher
argument_list|(
name|weigher
argument_list|)
operator|.
name|maximumWeight
argument_list|(
name|maxWeight
argument_list|)
operator|.
name|recordStats
argument_list|()
operator|.
name|build
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

