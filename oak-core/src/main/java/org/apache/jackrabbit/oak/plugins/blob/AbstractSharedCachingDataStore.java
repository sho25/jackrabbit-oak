begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *   http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|blob
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|DigestOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|MessageDigest
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Stopwatch
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterators
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|io
operator|.
name|Closeables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListeningExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FilenameUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|core
operator|.
name|data
operator|.
name|AbstractDataStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|core
operator|.
name|data
operator|.
name|DataIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|core
operator|.
name|data
operator|.
name|DataRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|core
operator|.
name|data
operator|.
name|DataStoreException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|core
operator|.
name|data
operator|.
name|MultiDataStoreAware
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|blob
operator|.
name|datastore
operator|.
name|TypedDataStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|AbstractDataRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|AbstractSharedBackend
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|BlobOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|stats
operator|.
name|StatisticsProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|util
operator|.
name|TransientFileFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkArgument
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|BlobOptions
operator|.
name|UploadType
operator|.
name|SYNCHRONOUS
import|;
end_import

begin_comment
comment|/**  * Cache files locally and stage files locally for async uploads.  * Configuration:  *  *<pre>  *&lt;DataStore class="org.apache.jackrabbit.oak.plugins.blob.AbstractCachingDataStore">  *  *&lt;param name="{@link #setPath(String) path}"/>  *&lt;param name="{@link #setCacheSize(long) cacheSize}" value="68719476736"/>  *&lt;param name="{@link #setStagingSplitPercentage(int) stagingSplitPercentage}" value="10"/>  *&lt;param name="{@link #setUploadThreads(int) uploadThreads}" value="10"/>  *&lt;param name="{@link #setStagingPurgeInterval(int) stagingPurgeInterval}" value="300"/>  *&lt;param name="{@link #setStagingRetryInterval(int) stagingRetryInterval} " value="600"/>  *&lt;/DataStore>  */
end_comment

begin_class
specifier|public
specifier|abstract
class|class
name|AbstractSharedCachingDataStore
extends|extends
name|AbstractDataStore
implements|implements
name|MultiDataStoreAware
implements|,
name|SharedDataStore
implements|,
name|TypedDataStore
block|{
comment|/**      * Logger instance.      */
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AbstractSharedCachingDataStore
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * The digest algorithm used to uniquely identify records.      */
specifier|private
specifier|static
specifier|final
name|String
name|DIGEST
init|=
literal|"SHA-1"
decl_stmt|;
comment|/**      * The root path      */
specifier|private
name|String
name|path
decl_stmt|;
comment|/**      * The number of bytes in the cache. The default value is 64 GB.      */
specifier|private
name|long
name|cacheSize
init|=
literal|64L
operator|*
literal|1024
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|/**      * The % of cache utilized for upload staging.      */
specifier|private
name|int
name|stagingSplitPercentage
init|=
literal|10
decl_stmt|;
comment|/**      * The number of upload threads used for asynchronous uploads from staging.      */
specifier|private
name|int
name|uploadThreads
init|=
literal|10
decl_stmt|;
comment|/**      * The interval for remove job in seconds.      */
specifier|private
name|int
name|stagingPurgeInterval
init|=
literal|300
decl_stmt|;
comment|/**      * The interval for retry job in seconds.      */
specifier|private
name|int
name|stagingRetryInterval
init|=
literal|600
decl_stmt|;
comment|/**      * The root rootDirectory where the files are created.      */
specifier|private
name|File
name|rootDirectory
decl_stmt|;
comment|/**      * The rootDirectory where tmp files are created.      */
specifier|private
name|File
name|tmp
decl_stmt|;
comment|/**      * Statistics provider.      */
specifier|private
name|StatisticsProvider
name|statisticsProvider
decl_stmt|;
comment|/**      * DataStore cache      */
specifier|private
name|CompositeDataStoreCache
name|cache
decl_stmt|;
comment|/**      * The delegate backend      */
specifier|protected
name|AbstractSharedBackend
name|backend
decl_stmt|;
specifier|protected
name|ListeningExecutorService
name|listeningExecutor
decl_stmt|;
specifier|protected
name|ScheduledExecutorService
name|schedulerExecutor
decl_stmt|;
specifier|public
name|void
name|init
parameter_list|(
name|String
name|homeDir
parameter_list|)
throws|throws
name|DataStoreException
block|{
if|if
condition|(
name|path
operator|==
literal|null
condition|)
block|{
name|path
operator|=
name|homeDir
operator|+
literal|"/repository/datastore"
expr_stmt|;
block|}
name|path
operator|=
name|FilenameUtils
operator|.
name|normalizeNoEndSeparator
argument_list|(
operator|new
name|File
argument_list|(
name|path
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
expr_stmt|;
name|checkArgument
argument_list|(
name|stagingSplitPercentage
operator|>=
literal|0
operator|&&
name|stagingSplitPercentage
operator|<=
literal|50
argument_list|,
literal|"Staging percentage cache should be between 0 and 50"
argument_list|)
expr_stmt|;
name|this
operator|.
name|rootDirectory
operator|=
operator|new
name|File
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|this
operator|.
name|tmp
operator|=
operator|new
name|File
argument_list|(
name|rootDirectory
argument_list|,
literal|"tmp"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Temporary file created [{}]"
argument_list|,
name|tmp
operator|.
name|mkdirs
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|backend
operator|=
name|createBackend
argument_list|()
expr_stmt|;
name|backend
operator|.
name|init
argument_list|()
expr_stmt|;
name|this
operator|.
name|cache
operator|=
operator|new
name|CompositeDataStoreCache
argument_list|(
name|path
argument_list|,
name|cacheSize
argument_list|,
name|stagingSplitPercentage
argument_list|,
name|uploadThreads
argument_list|,
operator|new
name|CacheLoader
argument_list|<
name|String
argument_list|,
name|InputStream
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|InputStream
name|load
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|Exception
block|{
name|InputStream
name|is
init|=
literal|null
decl_stmt|;
name|boolean
name|threw
init|=
literal|true
decl_stmt|;
try|try
block|{
name|is
operator|=
name|backend
operator|.
name|read
argument_list|(
operator|new
name|DataIdentifier
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|threw
operator|=
literal|false
expr_stmt|;
block|}
finally|finally
block|{
name|Closeables
operator|.
name|close
argument_list|(
name|is
argument_list|,
name|threw
argument_list|)
expr_stmt|;
block|}
return|return
name|is
return|;
block|}
block|}
argument_list|,
operator|new
name|StagingUploader
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|String
name|id
parameter_list|,
name|File
name|file
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|backend
operator|.
name|write
argument_list|(
operator|new
name|DataIdentifier
argument_list|(
name|id
argument_list|)
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|,
name|statisticsProvider
argument_list|,
name|listeningExecutor
argument_list|,
name|schedulerExecutor
argument_list|,
name|stagingPurgeInterval
argument_list|,
name|stagingRetryInterval
argument_list|)
expr_stmt|;
block|}
specifier|protected
specifier|abstract
name|AbstractSharedBackend
name|createBackend
parameter_list|()
function_decl|;
annotation|@
name|Override
specifier|public
name|DataRecord
name|getRecord
parameter_list|(
name|DataIdentifier
name|identifier
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|DataRecord
name|record
init|=
name|getRecordIfStored
argument_list|(
name|identifier
argument_list|)
decl_stmt|;
if|if
condition|(
name|record
operator|!=
literal|null
condition|)
block|{
return|return
name|record
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|DataStoreException
argument_list|(
literal|"Record "
operator|+
name|identifier
operator|+
literal|" does not exist"
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|DataRecord
name|getRecordIfStored
parameter_list|(
name|DataIdentifier
name|dataIdentifier
parameter_list|)
throws|throws
name|DataStoreException
block|{
comment|// Return file attributes from cache only if corresponding file is cached
comment|// This avoids downloading the file for just accessing the meta data
name|File
name|cached
init|=
name|cache
operator|.
name|getIfPresent
argument_list|(
name|dataIdentifier
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|cached
operator|!=
literal|null
operator|&&
name|cached
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return
operator|new
name|FileCacheDataRecord
argument_list|(
name|this
argument_list|,
name|backend
argument_list|,
name|dataIdentifier
argument_list|,
name|cached
operator|.
name|length
argument_list|()
argument_list|,
name|cached
operator|.
name|lastModified
argument_list|()
argument_list|)
return|;
block|}
comment|// File not in cache so, retrieve the meta data from the backend explicitly
try|try
block|{
return|return
name|backend
operator|.
name|getRecord
argument_list|(
name|dataIdentifier
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error retrieving record [{}] from backend"
argument_list|,
name|dataIdentifier
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|DataRecord
name|addRecord
parameter_list|(
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|DataStoreException
block|{
return|return
name|addRecord
argument_list|(
name|inputStream
argument_list|,
operator|new
name|BlobOptions
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|DataRecord
name|addRecord
parameter_list|(
name|InputStream
name|inputStream
parameter_list|,
name|BlobOptions
name|blobOptions
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|Stopwatch
name|watch
init|=
name|Stopwatch
operator|.
name|createStarted
argument_list|()
decl_stmt|;
try|try
block|{
name|TransientFileFactory
name|fileFactory
init|=
name|TransientFileFactory
operator|.
name|getInstance
argument_list|()
decl_stmt|;
name|File
name|tmpFile
init|=
name|fileFactory
operator|.
name|createTransientFile
argument_list|(
literal|"upload"
argument_list|,
literal|null
argument_list|,
name|tmp
argument_list|)
decl_stmt|;
comment|// Copy the stream to the temporary file and calculate the
comment|// stream length and the message digest of the stream
name|MessageDigest
name|digest
init|=
name|MessageDigest
operator|.
name|getInstance
argument_list|(
name|DIGEST
argument_list|)
decl_stmt|;
name|OutputStream
name|output
init|=
operator|new
name|DigestOutputStream
argument_list|(
operator|new
name|FileOutputStream
argument_list|(
name|tmpFile
argument_list|)
argument_list|,
name|digest
argument_list|)
decl_stmt|;
name|long
name|length
init|=
literal|0
decl_stmt|;
try|try
block|{
name|length
operator|=
name|IOUtils
operator|.
name|copyLarge
argument_list|(
name|inputStream
argument_list|,
name|output
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|DataIdentifier
name|identifier
init|=
operator|new
name|DataIdentifier
argument_list|(
name|encodeHexString
argument_list|(
name|digest
operator|.
name|digest
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"SHA1 of [{}], length =[{}] took [{}] ms "
argument_list|,
name|identifier
argument_list|,
name|length
argument_list|,
name|watch
operator|.
name|elapsed
argument_list|(
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
argument_list|)
expr_stmt|;
comment|// asynchronously stage for upload if the size limit of staging cache permits
comment|// otherwise add to backend
if|if
condition|(
name|blobOptions
operator|.
name|getUpload
argument_list|()
operator|==
name|SYNCHRONOUS
operator|||
operator|!
name|cache
operator|.
name|stage
argument_list|(
name|identifier
operator|.
name|toString
argument_list|()
argument_list|,
name|tmpFile
argument_list|)
condition|)
block|{
name|backend
operator|.
name|write
argument_list|(
name|identifier
argument_list|,
name|tmpFile
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Added blob [{}] to backend"
argument_list|,
name|identifier
argument_list|)
expr_stmt|;
comment|// offer to download cache
name|cache
operator|.
name|getDownloadCache
argument_list|()
operator|.
name|put
argument_list|(
name|identifier
operator|.
name|toString
argument_list|()
argument_list|,
name|tmpFile
argument_list|)
expr_stmt|;
block|}
return|return
name|getRecordIfStored
argument_list|(
name|identifier
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error in adding record"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|DataStoreException
argument_list|(
literal|"Error in adding record "
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**      * In rare cases may include some duplicates in cases where async staged uploads complete      * during iteration.      *      * @return Iterator over all ids available      * @throws DataStoreException      */
annotation|@
name|Override
specifier|public
name|Iterator
argument_list|<
name|DataIdentifier
argument_list|>
name|getAllIdentifiers
parameter_list|()
throws|throws
name|DataStoreException
block|{
return|return
name|Iterators
operator|.
name|concat
argument_list|(
name|Iterators
operator|.
name|transform
argument_list|(
name|cache
operator|.
name|getStagingCache
argument_list|()
operator|.
name|getAllIdentifiers
argument_list|()
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|DataIdentifier
argument_list|>
argument_list|()
block|{
annotation|@
name|Nullable
annotation|@
name|Override
specifier|public
name|DataIdentifier
name|apply
parameter_list|(
annotation|@
name|Nullable
name|String
name|id
parameter_list|)
block|{
return|return
operator|new
name|DataIdentifier
argument_list|(
name|id
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|,
name|backend
operator|.
name|getAllIdentifiers
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|deleteRecord
parameter_list|(
name|DataIdentifier
name|dataIdentifier
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|cache
operator|.
name|invalidate
argument_list|(
name|dataIdentifier
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|backend
operator|.
name|deleteRecord
argument_list|(
name|dataIdentifier
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|DataStoreException
block|{
name|backend
operator|.
name|close
argument_list|()
expr_stmt|;
name|cache
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**      * DataRecord implementation fetching the stream from the cache.      */
specifier|static
class|class
name|FileCacheDataRecord
extends|extends
name|AbstractDataRecord
block|{
specifier|private
specifier|final
name|long
name|length
decl_stmt|;
specifier|private
specifier|final
name|long
name|lastModified
decl_stmt|;
specifier|private
specifier|final
name|AbstractSharedCachingDataStore
name|store
decl_stmt|;
specifier|public
name|FileCacheDataRecord
parameter_list|(
name|AbstractSharedCachingDataStore
name|store
parameter_list|,
name|AbstractSharedBackend
name|backend
parameter_list|,
name|DataIdentifier
name|identifier
parameter_list|,
name|long
name|length
parameter_list|,
name|long
name|lastModified
parameter_list|)
block|{
name|super
argument_list|(
name|backend
argument_list|,
name|identifier
argument_list|)
expr_stmt|;
name|this
operator|.
name|length
operator|=
name|length
expr_stmt|;
name|this
operator|.
name|lastModified
operator|=
name|lastModified
expr_stmt|;
name|this
operator|.
name|store
operator|=
name|store
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getLength
parameter_list|()
throws|throws
name|DataStoreException
block|{
return|return
name|length
return|;
block|}
annotation|@
name|Override
specifier|public
name|InputStream
name|getStream
parameter_list|()
throws|throws
name|DataStoreException
block|{
try|try
block|{
return|return
operator|new
name|FileInputStream
argument_list|(
name|store
operator|.
name|cache
operator|.
name|get
argument_list|(
name|getIdentifier
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
specifier|final
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|DataStoreException
argument_list|(
literal|"Error opening input stream for identifier "
operator|+
name|getIdentifier
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|long
name|getLastModified
parameter_list|()
block|{
return|return
name|lastModified
return|;
block|}
block|}
comment|/**      * Look in the backend for a record matching the given identifier.  Returns true      * if such a record exists.      *      * @param identifier - An identifier for the record.      * @return true if a record for the provided identifier can be found.      */
specifier|public
name|boolean
name|exists
parameter_list|(
specifier|final
name|DataIdentifier
name|identifier
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|identifier
operator|!=
literal|null
condition|)
block|{
return|return
name|backend
operator|.
name|exists
argument_list|(
name|identifier
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|DataStoreException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Data Store Exception caught checking for %s in pending uploads"
argument_list|,
name|identifier
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|List
argument_list|<
name|DataStoreCacheStatsMBean
argument_list|>
name|getStats
parameter_list|()
block|{
return|return
name|ImmutableList
operator|.
name|of
argument_list|(
name|cache
operator|.
name|getCacheStats
argument_list|()
argument_list|,
name|cache
operator|.
name|getStagingCacheStats
argument_list|()
argument_list|)
return|;
block|}
specifier|protected
name|CompositeDataStoreCache
name|getCache
parameter_list|()
block|{
return|return
name|cache
return|;
block|}
comment|/**------------------------- setters ----------------------------------------------**/
specifier|public
name|void
name|setPath
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
block|}
specifier|public
name|void
name|setCacheSize
parameter_list|(
name|long
name|cacheSize
parameter_list|)
block|{
name|this
operator|.
name|cacheSize
operator|=
name|cacheSize
expr_stmt|;
block|}
specifier|public
name|void
name|setStagingSplitPercentage
parameter_list|(
name|int
name|stagingSplitPercentage
parameter_list|)
block|{
name|this
operator|.
name|stagingSplitPercentage
operator|=
name|stagingSplitPercentage
expr_stmt|;
block|}
specifier|public
name|void
name|setUploadThreads
parameter_list|(
name|int
name|uploadThreads
parameter_list|)
block|{
name|this
operator|.
name|uploadThreads
operator|=
name|uploadThreads
expr_stmt|;
block|}
specifier|public
name|void
name|setStagingPurgeInterval
parameter_list|(
name|int
name|stagingPurgeInterval
parameter_list|)
block|{
name|this
operator|.
name|stagingPurgeInterval
operator|=
name|stagingPurgeInterval
expr_stmt|;
block|}
specifier|public
name|void
name|setStagingRetryInterval
parameter_list|(
name|int
name|stagingRetryInterval
parameter_list|)
block|{
name|this
operator|.
name|stagingRetryInterval
operator|=
name|stagingRetryInterval
expr_stmt|;
block|}
specifier|public
name|void
name|setStatisticsProvider
parameter_list|(
name|StatisticsProvider
name|statisticsProvider
parameter_list|)
block|{
name|this
operator|.
name|statisticsProvider
operator|=
name|statisticsProvider
expr_stmt|;
block|}
comment|/**------------------------ SharedDataStore methods -----------------------------------------**/
annotation|@
name|Override
specifier|public
name|void
name|addMetadataRecord
parameter_list|(
name|InputStream
name|stream
parameter_list|,
name|String
name|name
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|backend
operator|.
name|addMetadataRecord
argument_list|(
name|stream
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|addMetadataRecord
parameter_list|(
name|File
name|f
parameter_list|,
name|String
name|name
parameter_list|)
throws|throws
name|DataStoreException
block|{
name|backend
operator|.
name|addMetadataRecord
argument_list|(
name|f
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|DataRecord
name|getMetadataRecord
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|backend
operator|.
name|getMetadataRecord
argument_list|(
name|name
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|DataRecord
argument_list|>
name|getAllMetadataRecords
parameter_list|(
name|String
name|prefix
parameter_list|)
block|{
return|return
name|backend
operator|.
name|getAllMetadataRecords
argument_list|(
name|prefix
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|deleteMetadataRecord
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|backend
operator|.
name|deleteMetadataRecord
argument_list|(
name|name
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|deleteAllMetadataRecords
parameter_list|(
name|String
name|prefix
parameter_list|)
block|{
name|backend
operator|.
name|deleteAllMetadataRecords
argument_list|(
name|prefix
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Iterator
argument_list|<
name|DataRecord
argument_list|>
name|getAllRecords
parameter_list|()
throws|throws
name|DataStoreException
block|{
return|return
name|backend
operator|.
name|getAllRecords
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|DataRecord
name|getRecordForId
parameter_list|(
name|DataIdentifier
name|identifier
parameter_list|)
throws|throws
name|DataStoreException
block|{
return|return
name|backend
operator|.
name|getRecord
argument_list|(
name|identifier
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|SharedDataStore
operator|.
name|Type
name|getType
parameter_list|()
block|{
return|return
name|SharedDataStore
operator|.
name|Type
operator|.
name|SHARED
return|;
block|}
annotation|@
name|Override
specifier|protected
name|byte
index|[]
name|getOrCreateReferenceKey
parameter_list|()
throws|throws
name|DataStoreException
block|{
return|return
name|backend
operator|.
name|getOrCreateReferenceKey
argument_list|()
return|;
block|}
comment|/**------------------------ unimplemented methods -------------------------------------------**/
annotation|@
name|Override
specifier|public
name|void
name|clearInUse
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Operation not supported"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|updateModifiedDateOnAccess
parameter_list|(
name|long
name|l
parameter_list|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Operation not supported"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|deleteAllOlderThan
parameter_list|(
name|long
name|l
parameter_list|)
throws|throws
name|DataStoreException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Operation not supported"
argument_list|)
throw|;
block|}
block|}
end_class

end_unit

