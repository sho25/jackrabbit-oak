begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|ref
operator|.
name|WeakReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|CheckForNull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nonnull
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|mk
operator|.
name|api
operator|.
name|MicroKernelException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|api
operator|.
name|Blob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|api
operator|.
name|CommitFailedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|CacheStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|PathUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|util
operator|.
name|LoggingDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|util
operator|.
name|TimingDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|mongomk
operator|.
name|util
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|CommitHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|PostCommitHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|Cache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkNotNull
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkState
import|;
end_import

begin_comment
comment|/**  * Implementation of a NodeStore on MongoDB.  */
end_comment

begin_class
specifier|public
specifier|final
class|class
name|MongoNodeStore
implements|implements
name|NodeStore
implements|,
name|RevisionContext
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MongoNodeStore
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Do not cache more than this number of children for a document.      */
specifier|private
specifier|static
specifier|final
name|int
name|NUM_CHILDREN_CACHE_LIMIT
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.childrenCacheLimit"
argument_list|,
literal|16
operator|*
literal|1024
argument_list|)
decl_stmt|;
comment|/**      * When trying to access revisions that are older than this many      * milliseconds, a warning is logged. The default is one minute.      */
specifier|private
specifier|static
specifier|final
name|int
name|WARN_REVISION_AGE
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.revisionAge"
argument_list|,
literal|60
operator|*
literal|1000
argument_list|)
decl_stmt|;
comment|/**      * Enable background operations      */
specifier|private
specifier|static
specifier|final
name|boolean
name|ENABLE_BACKGROUND_OPS
init|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"oak.mongoMK.backgroundOps"
argument_list|,
literal|"true"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * How long to remember the relative order of old revision of all cluster      * nodes, in milliseconds. The default is one hour.      */
specifier|private
specifier|static
specifier|final
name|int
name|REMEMBER_REVISION_ORDER_MILLIS
init|=
literal|60
operator|*
literal|60
operator|*
literal|1000
decl_stmt|;
comment|/**      * The MongoDB store (might be used by multiple MongoMKs).      */
specifier|protected
specifier|final
name|DocumentStore
name|store
decl_stmt|;
comment|/**      * Whether this instance is disposed.      */
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
comment|/**      * The delay for asynchronous operations (delayed commit propagation and      * cache update).      */
specifier|protected
name|int
name|asyncDelay
init|=
literal|1000
decl_stmt|;
comment|/**      * The cluster instance info.      */
specifier|private
specifier|final
name|ClusterNodeInfo
name|clusterNodeInfo
decl_stmt|;
comment|/**      * The unique cluster id, similar to the unique machine id in MongoDB.      */
specifier|private
specifier|final
name|int
name|clusterId
decl_stmt|;
comment|/**      * The comparator for revisions.      */
specifier|private
specifier|final
name|Revision
operator|.
name|RevisionComparator
name|revisionComparator
decl_stmt|;
comment|/**      * Unmerged branches of this MongoNodeStore instance.      */
comment|// TODO at some point, open (unmerged) branches
comment|// need to be garbage collected (in-memory and on disk)
specifier|private
specifier|final
name|UnmergedBranches
name|branches
decl_stmt|;
comment|/**      * The unsaved last revisions. This contains the parents of all changed      * nodes, once those nodes are committed but the parent node itself wasn't      * committed yet. The parents are not immediately persisted as this would      * cause each commit to change all parents (including the root node), which      * would limit write scalability.      *      * Key: path, value: revision.      */
specifier|private
specifier|final
name|UnsavedModifications
name|unsavedLastRevisions
init|=
operator|new
name|UnsavedModifications
argument_list|()
decl_stmt|;
comment|/**      * Set of IDs for documents that may need to be split.      */
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|splitCandidates
init|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
comment|/**      * The splitting point in milliseconds. If a document is split, revisions      * older than this number of milliseconds are moved to a different document.      * The default is 0, meaning documents are never split. Revisions that are      * newer than this are kept in the newest document.      */
specifier|private
specifier|final
name|long
name|splitDocumentAgeMillis
decl_stmt|;
comment|/**      * The last known revision for each cluster instance.      *      * Key: the machine id, value: revision.      */
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastKnownRevision
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
argument_list|()
decl_stmt|;
comment|/**      * The last known head revision. This is the last-known revision.      */
specifier|private
specifier|volatile
name|Revision
name|headRevision
decl_stmt|;
specifier|private
name|Thread
name|backgroundThread
decl_stmt|;
comment|/**      * Enable using simple revisions (just a counter). This feature is useful      * for testing.      */
specifier|private
name|AtomicInteger
name|simpleRevisionCounter
decl_stmt|;
specifier|private
name|boolean
name|stopBackground
decl_stmt|;
comment|/**      * The node cache.      *      * Key: path@rev, value: node      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|Node
argument_list|>
name|nodeCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeCacheStats
decl_stmt|;
comment|/**      * Child node cache.      *      * Key: path@rev, value: children      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|Node
operator|.
name|Children
argument_list|>
name|nodeChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeChildrenCacheStats
decl_stmt|;
comment|/**      * Child doc cache.      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|String
argument_list|,
name|NodeDocument
operator|.
name|Children
argument_list|>
name|docChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|docChildrenCacheStats
decl_stmt|;
specifier|public
name|MongoNodeStore
parameter_list|(
name|MongoMK
operator|.
name|Builder
name|builder
parameter_list|)
block|{
if|if
condition|(
name|builder
operator|.
name|isUseSimpleRevision
argument_list|()
condition|)
block|{
name|this
operator|.
name|simpleRevisionCounter
operator|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|DocumentStore
name|s
init|=
name|builder
operator|.
name|getDocumentStore
argument_list|()
decl_stmt|;
if|if
condition|(
name|builder
operator|.
name|getTiming
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|TimingDocumentStoreWrapper
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|builder
operator|.
name|getLogging
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|LoggingDocumentStoreWrapper
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|store
operator|=
name|s
expr_stmt|;
name|int
name|cid
init|=
name|builder
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
name|cid
operator|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.mongoMK.clusterId"
argument_list|,
name|cid
argument_list|)
expr_stmt|;
if|if
condition|(
name|cid
operator|==
literal|0
condition|)
block|{
name|clusterNodeInfo
operator|=
name|ClusterNodeInfo
operator|.
name|getInstance
argument_list|(
name|store
argument_list|)
expr_stmt|;
comment|// TODO we should ensure revisions generated from now on
comment|// are never "older" than revisions already in the repository for
comment|// this cluster id
name|cid
operator|=
name|clusterNodeInfo
operator|.
name|getId
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|clusterNodeInfo
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|clusterId
operator|=
name|cid
expr_stmt|;
name|this
operator|.
name|revisionComparator
operator|=
operator|new
name|Revision
operator|.
name|RevisionComparator
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
name|this
operator|.
name|branches
operator|=
operator|new
name|UnmergedBranches
argument_list|(
name|getRevisionComparator
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|splitDocumentAgeMillis
operator|=
name|builder
operator|.
name|getSplitDocumentAgeMillis
argument_list|()
expr_stmt|;
name|this
operator|.
name|asyncDelay
operator|=
name|builder
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
comment|//TODO Make stats collection configurable as it add slight overhead
name|nodeCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getNodeCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeCache
argument_list|,
literal|"MongoMk-Node"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getNodeCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeChildrenCache
argument_list|,
literal|"MongoMk-NodeChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|=
name|builder
operator|.
name|buildCache
argument_list|(
name|builder
operator|.
name|getDocChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|docChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|docChildrenCache
argument_list|,
literal|"MongoMk-DocChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getDocChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|init
argument_list|()
expr_stmt|;
comment|// initial reading of the revisions of other cluster nodes
name|backgroundRead
argument_list|()
expr_stmt|;
name|getRevisionComparator
argument_list|()
operator|.
name|add
argument_list|(
name|headRevision
argument_list|,
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
name|headRevision
operator|=
name|newRevision
argument_list|()
expr_stmt|;
block|}
name|void
name|init
parameter_list|()
block|{
name|headRevision
operator|=
name|newRevision
argument_list|()
expr_stmt|;
name|Node
name|n
init|=
name|readNode
argument_list|(
literal|"/"
argument_list|,
name|headRevision
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
comment|// root node is missing: repository is not initialized
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
literal|null
argument_list|,
name|headRevision
argument_list|)
decl_stmt|;
name|n
operator|=
operator|new
name|Node
argument_list|(
literal|"/"
argument_list|,
name|headRevision
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|n
argument_list|)
expr_stmt|;
name|commit
operator|.
name|applyToDocumentStore
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// initialize branchCommits
name|branches
operator|.
name|init
argument_list|(
name|store
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
name|backgroundThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|BackgroundOperation
argument_list|(
name|this
argument_list|,
name|isDisposed
argument_list|)
argument_list|,
literal|"MongoMK background thread"
argument_list|)
expr_stmt|;
name|backgroundThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|backgroundThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|void
name|dispose
parameter_list|()
block|{
comment|// force background write (with asyncDelay> 0, the root wouldn't be written)
comment|// TODO make this more obvious / explicit
comment|// TODO tests should also work if this is not done
name|asyncDelay
operator|=
literal|0
expr_stmt|;
name|runBackgroundOperations
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|isDisposed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
name|isDisposed
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|backgroundThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
if|if
condition|(
name|clusterNodeInfo
operator|!=
literal|null
condition|)
block|{
name|clusterNodeInfo
operator|.
name|dispose
argument_list|()
expr_stmt|;
block|}
name|store
operator|.
name|dispose
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Disposed MongoMK with clusterNodeId: {}"
argument_list|,
name|clusterId
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|stopBackground
parameter_list|()
block|{
name|stopBackground
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Nonnull
name|Revision
name|getHeadRevision
parameter_list|()
block|{
return|return
name|headRevision
return|;
block|}
name|Revision
name|setHeadRevision
parameter_list|(
name|Revision
name|newHead
parameter_list|)
block|{
name|Revision
name|previous
init|=
name|headRevision
decl_stmt|;
name|headRevision
operator|=
name|newHead
expr_stmt|;
return|return
name|previous
return|;
block|}
annotation|@
name|Nonnull
name|DocumentStore
name|getDocumentStore
parameter_list|()
block|{
return|return
name|store
return|;
block|}
comment|/**      * Create a new revision.      *      * @return the revision      */
annotation|@
name|Nonnull
name|Revision
name|newRevision
parameter_list|()
block|{
if|if
condition|(
name|simpleRevisionCounter
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|Revision
argument_list|(
name|simpleRevisionCounter
operator|.
name|getAndIncrement
argument_list|()
argument_list|,
literal|0
argument_list|,
name|clusterId
argument_list|)
return|;
block|}
return|return
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
return|;
block|}
specifier|public
name|void
name|setAsyncDelay
parameter_list|(
name|int
name|delay
parameter_list|)
block|{
name|this
operator|.
name|asyncDelay
operator|=
name|delay
expr_stmt|;
block|}
specifier|public
name|int
name|getAsyncDelay
parameter_list|()
block|{
return|return
name|asyncDelay
return|;
block|}
specifier|public
name|ClusterNodeInfo
name|getClusterInfo
parameter_list|()
block|{
return|return
name|clusterNodeInfo
return|;
block|}
specifier|public
name|CacheStats
name|getNodeCacheStats
parameter_list|()
block|{
return|return
name|nodeCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getNodeChildrenCacheStats
parameter_list|()
block|{
return|return
name|nodeChildrenCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getDocChildrenCacheStats
parameter_list|()
block|{
return|return
name|docChildrenCacheStats
return|;
block|}
specifier|public
name|int
name|getPendingWriteCount
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
name|long
name|getSplitDocumentAgeMillis
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitDocumentAgeMillis
return|;
block|}
comment|/**      * Checks that revision x is newer than another revision.      *      * @param x the revision to check      * @param previous the presumed earlier revision      * @return true if x is newer      */
name|boolean
name|isRevisionNewer
parameter_list|(
annotation|@
name|Nonnull
name|Revision
name|x
parameter_list|,
annotation|@
name|Nonnull
name|Revision
name|previous
parameter_list|)
block|{
return|return
name|getRevisionComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|x
argument_list|,
name|previous
argument_list|)
operator|>
literal|0
return|;
block|}
comment|/**      * Enqueue the document with the given id as a split candidate.      *      * @param id the id of the document to check if it needs to be split.      */
name|void
name|addSplitCandidate
parameter_list|(
name|String
name|id
parameter_list|)
block|{
name|splitCandidates
operator|.
name|put
argument_list|(
name|id
argument_list|,
name|id
argument_list|)
expr_stmt|;
block|}
name|void
name|copyNode
parameter_list|(
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|false
argument_list|,
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
name|void
name|moveNode
parameter_list|(
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|true
argument_list|,
name|sourcePath
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
name|void
name|markAsDeleted
parameter_list|(
name|String
name|path
parameter_list|,
name|Commit
name|commit
parameter_list|,
name|boolean
name|subTreeAlso
parameter_list|)
block|{
name|Revision
name|rev
init|=
name|commit
operator|.
name|getBaseRevision
argument_list|()
decl_stmt|;
name|checkState
argument_list|(
name|rev
operator|!=
literal|null
argument_list|,
literal|"Base revision of commit must not be null"
argument_list|)
expr_stmt|;
name|commit
operator|.
name|removeNode
argument_list|(
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
name|subTreeAlso
condition|)
block|{
comment|// recurse down the tree
comment|// TODO causes issue with large number of children
name|Node
name|n
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|!=
literal|null
condition|)
block|{
name|Node
operator|.
name|Children
name|c
init|=
name|getChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|childPath
range|:
name|c
operator|.
name|children
control|)
block|{
name|markAsDeleted
argument_list|(
name|childPath
argument_list|,
name|commit
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**      * Get the node for the given path and revision. The returned object might      * not be modified directly.      *      * @param path the path of the node.      * @param rev the read revision.      * @return the node or<code>null</code> if the node does not exist at the      *          given revision.      */
annotation|@
name|CheckForNull
name|Node
name|getNode
parameter_list|(
specifier|final
annotation|@
name|Nonnull
name|String
name|path
parameter_list|,
specifier|final
annotation|@
name|Nonnull
name|Revision
name|rev
parameter_list|)
block|{
name|checkRevisionAge
argument_list|(
name|checkNotNull
argument_list|(
name|rev
argument_list|)
argument_list|,
name|checkNotNull
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Node
name|node
init|=
name|nodeCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|Node
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Node
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|Node
name|n
init|=
name|readNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
name|n
operator|=
name|Node
operator|.
name|MISSING
expr_stmt|;
block|}
return|return
name|n
return|;
block|}
block|}
argument_list|)
decl_stmt|;
return|return
name|node
operator|==
name|Node
operator|.
name|MISSING
condition|?
literal|null
else|:
name|node
return|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|Node
operator|.
name|Children
name|getChildren
parameter_list|(
specifier|final
name|String
name|path
parameter_list|,
specifier|final
name|Revision
name|rev
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|)
throws|throws
name|MicroKernelException
block|{
name|checkRevisionAge
argument_list|(
name|rev
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Node
operator|.
name|Children
name|children
decl_stmt|;
try|try
block|{
name|children
operator|=
name|nodeChildrenCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|Node
operator|.
name|Children
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Node
operator|.
name|Children
name|call
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|readChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|limit
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MicroKernelException
argument_list|(
literal|"Error occurred while fetching children nodes for path "
operator|+
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|//In case the limit> cached children size and there are more child nodes
comment|//available then refresh the cache
if|if
condition|(
name|children
operator|.
name|hasMore
condition|)
block|{
if|if
condition|(
name|limit
operator|>
name|children
operator|.
name|children
operator|.
name|size
argument_list|()
condition|)
block|{
name|children
operator|=
name|readChildren
argument_list|(
name|path
argument_list|,
name|rev
argument_list|,
name|limit
argument_list|)
expr_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|children
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|children
return|;
block|}
name|Node
operator|.
name|Children
name|readChildren
parameter_list|(
name|String
name|path
parameter_list|,
name|Revision
name|rev
parameter_list|,
name|int
name|limit
parameter_list|)
block|{
comment|// TODO use offset, to avoid O(n^2) and running out of memory
comment|// to do that, use the *name* of the last entry of the previous batch of children
comment|// as the starting point
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|docs
decl_stmt|;
name|Node
operator|.
name|Children
name|c
init|=
operator|new
name|Node
operator|.
name|Children
argument_list|()
decl_stmt|;
name|int
name|rawLimit
init|=
name|limit
decl_stmt|;
name|Set
argument_list|<
name|Revision
argument_list|>
name|validRevisions
init|=
operator|new
name|HashSet
argument_list|<
name|Revision
argument_list|>
argument_list|()
decl_stmt|;
do|do
block|{
name|c
operator|.
name|children
operator|.
name|clear
argument_list|()
expr_stmt|;
name|c
operator|.
name|hasMore
operator|=
literal|true
expr_stmt|;
name|docs
operator|=
name|readChildren
argument_list|(
name|path
argument_list|,
name|rawLimit
argument_list|)
expr_stmt|;
name|int
name|numReturned
init|=
literal|0
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|numReturned
operator|++
expr_stmt|;
comment|// filter out deleted children
if|if
condition|(
name|doc
operator|.
name|isDeleted
argument_list|(
name|this
argument_list|,
name|rev
argument_list|,
name|validRevisions
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|doc
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
condition|)
block|{
comment|// add to children until limit is reached
name|c
operator|.
name|children
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|numReturned
operator|<
name|rawLimit
condition|)
block|{
comment|// fewer documents returned than requested
comment|// -> no more documents
name|c
operator|.
name|hasMore
operator|=
literal|false
expr_stmt|;
block|}
comment|// double rawLimit for next round
name|rawLimit
operator|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
operator|(
operator|(
name|long
operator|)
name|rawLimit
operator|)
operator|*
literal|2
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
name|c
operator|.
name|hasMore
condition|)
do|;
return|return
name|c
return|;
block|}
annotation|@
name|Nonnull
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|readChildren
parameter_list|(
specifier|final
name|String
name|path
parameter_list|,
name|int
name|limit
parameter_list|)
block|{
name|String
name|from
init|=
name|Utils
operator|.
name|getKeyLowerLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|to
init|=
name|Utils
operator|.
name|getKeyUpperLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|limit
operator|>
name|NUM_CHILDREN_CACHE_LIMIT
condition|)
block|{
comment|// do not use cache
return|return
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
return|;
block|}
comment|// check cache
name|NodeDocument
operator|.
name|Children
name|c
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|c
operator|==
literal|null
condition|)
block|{
name|c
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|docs
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|doc
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
name|c
operator|.
name|childNames
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|c
operator|.
name|isComplete
operator|=
name|docs
operator|.
name|size
argument_list|()
operator|<
name|limit
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
operator|!
name|c
operator|.
name|isComplete
condition|)
block|{
comment|// fetch more and update cache
name|String
name|lastName
init|=
name|c
operator|.
name|childNames
operator|.
name|get
argument_list|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|String
name|lastPath
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|path
argument_list|,
name|lastName
argument_list|)
decl_stmt|;
name|from
operator|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|lastPath
argument_list|)
expr_stmt|;
name|int
name|remainingLimit
init|=
name|limit
operator|-
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|docs
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|remainingLimit
argument_list|)
decl_stmt|;
name|NodeDocument
operator|.
name|Children
name|clone
init|=
name|c
operator|.
name|clone
argument_list|()
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|String
name|p
init|=
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|doc
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
name|clone
operator|.
name|childNames
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|clone
operator|.
name|isComplete
operator|=
name|docs
operator|.
name|size
argument_list|()
operator|<
name|remainingLimit
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|clone
argument_list|)
expr_stmt|;
name|c
operator|=
name|clone
expr_stmt|;
block|}
return|return
name|Iterables
operator|.
name|transform
argument_list|(
name|c
operator|.
name|childNames
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|NodeDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|NodeDocument
name|apply
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|String
name|p
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|path
argument_list|,
name|name
argument_list|)
decl_stmt|;
return|return
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|p
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
annotation|@
name|CheckForNull
specifier|private
name|Node
name|readNode
parameter_list|(
name|String
name|path
parameter_list|,
name|Revision
name|readRevision
parameter_list|)
block|{
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|Revision
name|lastRevision
init|=
name|getPendingModifications
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|doc
operator|.
name|getNodeAtRevision
argument_list|(
name|this
argument_list|,
name|readRevision
argument_list|,
name|lastRevision
argument_list|)
return|;
block|}
comment|/**      * Apply the changes of a node to the cache.      *      * @param rev the revision      * @param path the path      * @param isNew whether this is a new node      * @param isDelete whether the node is deleted      * @param isWritten whether the MongoDB documented was added / updated      * @param isBranchCommit whether this is from a branch commit      * @param added the list of added child nodes      * @param removed the list of removed child nodes      *      */
specifier|public
name|void
name|applyChanges
parameter_list|(
name|Revision
name|rev
parameter_list|,
name|String
name|path
parameter_list|,
name|boolean
name|isNew
parameter_list|,
name|boolean
name|isDelete
parameter_list|,
name|boolean
name|isWritten
parameter_list|,
name|boolean
name|isBranchCommit
parameter_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
name|added
parameter_list|,
name|ArrayList
argument_list|<
name|String
argument_list|>
name|removed
parameter_list|)
block|{
name|UnsavedModifications
name|unsaved
init|=
name|unsavedLastRevisions
decl_stmt|;
if|if
condition|(
name|isBranchCommit
condition|)
block|{
name|Revision
name|branchRev
init|=
name|rev
operator|.
name|asBranchRevision
argument_list|()
decl_stmt|;
name|unsaved
operator|=
name|branches
operator|.
name|getBranch
argument_list|(
name|branchRev
argument_list|)
operator|.
name|getModifications
argument_list|(
name|branchRev
argument_list|)
expr_stmt|;
block|}
comment|// track unsaved modifications of nodes that were not
comment|// written in the commit (implicitly modified parent)
comment|// or any modification if this is a branch commit
if|if
condition|(
operator|!
name|isWritten
operator|||
name|isBranchCommit
condition|)
block|{
name|Revision
name|prev
init|=
name|unsaved
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|prev
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|isRevisionNewer
argument_list|(
name|prev
argument_list|,
name|rev
argument_list|)
condition|)
block|{
comment|// revert
name|unsaved
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|prev
argument_list|)
expr_stmt|;
name|String
name|msg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Attempt to update "
operator|+
literal|"unsavedLastRevision for %s with %s, which is "
operator|+
literal|"older than current %s."
argument_list|,
name|path
argument_list|,
name|rev
argument_list|,
name|prev
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|MicroKernelException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
else|else
block|{
comment|// the document was updated:
comment|// we no longer need to update it in a background process
name|unsaved
operator|.
name|remove
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
name|String
name|key
init|=
name|path
operator|+
literal|"@"
operator|+
name|rev
decl_stmt|;
name|Node
operator|.
name|Children
name|c
init|=
name|nodeChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|isNew
operator|||
operator|(
operator|!
name|isDelete
operator|&&
name|c
operator|!=
literal|null
operator|)
condition|)
block|{
name|Node
operator|.
name|Children
name|c2
init|=
operator|new
name|Node
operator|.
name|Children
argument_list|()
decl_stmt|;
name|TreeSet
argument_list|<
name|String
argument_list|>
name|set
init|=
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|c
operator|!=
literal|null
condition|)
block|{
name|set
operator|.
name|addAll
argument_list|(
name|c
operator|.
name|children
argument_list|)
expr_stmt|;
block|}
name|set
operator|.
name|removeAll
argument_list|(
name|removed
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|name
range|:
name|added
control|)
block|{
comment|// make sure the name string does not contain
comment|// unnecessary baggage
name|set
operator|.
name|add
argument_list|(
operator|new
name|String
argument_list|(
name|name
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|c2
operator|.
name|children
operator|.
name|addAll
argument_list|(
name|set
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|c2
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|added
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|NodeDocument
operator|.
name|Children
name|docChildren
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|docChildren
operator|!=
literal|null
condition|)
block|{
name|int
name|currentSize
init|=
name|docChildren
operator|.
name|childNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|TreeSet
argument_list|<
name|String
argument_list|>
name|names
init|=
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|docChildren
operator|.
name|childNames
argument_list|)
decl_stmt|;
comment|// incomplete cache entries must not be updated with
comment|// names at the end of the list because there might be
comment|// a next name in MongoDB smaller than the one added
if|if
condition|(
operator|!
name|docChildren
operator|.
name|isComplete
condition|)
block|{
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
name|String
name|name
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|higher
argument_list|(
name|name
argument_list|)
operator|!=
literal|null
condition|)
block|{
comment|// make sure the name string does not contain
comment|// unnecessary baggage
name|names
operator|.
name|add
argument_list|(
operator|new
name|String
argument_list|(
name|name
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// add all
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
comment|// make sure the name string does not contain
comment|// unnecessary baggage
name|names
operator|.
name|add
argument_list|(
operator|new
name|String
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// any changes?
if|if
condition|(
name|names
operator|.
name|size
argument_list|()
operator|!=
name|currentSize
condition|)
block|{
comment|// create new cache entry with updated names
name|boolean
name|complete
init|=
name|docChildren
operator|.
name|isComplete
decl_stmt|;
name|docChildren
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|docChildren
operator|.
name|isComplete
operator|=
name|complete
expr_stmt|;
name|docChildren
operator|.
name|childNames
operator|.
name|addAll
argument_list|(
name|names
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|docChildren
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//-------------------------< NodeStore>------------------------------------
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|NodeState
name|getRoot
parameter_list|()
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|NodeState
name|merge
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|,
annotation|@
name|Nonnull
name|CommitHook
name|commitHook
parameter_list|,
name|PostCommitHook
name|committed
parameter_list|)
throws|throws
name|CommitFailedException
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|NodeState
name|rebase
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|)
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|NodeState
name|reset
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|)
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Blob
name|createBlob
parameter_list|(
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|String
name|checkpoint
parameter_list|(
name|long
name|lifetime
parameter_list|)
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
annotation|@
name|CheckForNull
annotation|@
name|Override
specifier|public
name|NodeState
name|retrieve
parameter_list|(
annotation|@
name|Nonnull
name|String
name|checkpoint
parameter_list|)
block|{
comment|// TODO: implement
return|return
literal|null
return|;
block|}
comment|//------------------------< RevisionContext>-------------------------------
annotation|@
name|Override
specifier|public
name|UnmergedBranches
name|getBranches
parameter_list|()
block|{
return|return
name|branches
return|;
block|}
annotation|@
name|Override
specifier|public
name|UnsavedModifications
name|getPendingModifications
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
return|;
block|}
annotation|@
name|Override
specifier|public
name|Revision
operator|.
name|RevisionComparator
name|getRevisionComparator
parameter_list|()
block|{
return|return
name|revisionComparator
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|publishRevision
parameter_list|(
name|Revision
name|foreignRevision
parameter_list|,
name|Revision
name|changeRevision
parameter_list|)
block|{
name|Revision
operator|.
name|RevisionComparator
name|revisionComparator
init|=
name|getRevisionComparator
argument_list|()
decl_stmt|;
if|if
condition|(
name|revisionComparator
operator|.
name|compare
argument_list|(
name|headRevision
argument_list|,
name|foreignRevision
argument_list|)
operator|>=
literal|0
condition|)
block|{
comment|// already visible
return|return;
block|}
name|int
name|clusterNodeId
init|=
name|foreignRevision
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
if|if
condition|(
name|clusterNodeId
operator|==
name|this
operator|.
name|clusterId
condition|)
block|{
return|return;
block|}
comment|// the (old) head occurred first
name|Revision
name|headSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// then we saw this new revision (from another cluster node)
name|Revision
name|otherSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// and after that, the current change
name|Revision
name|changeSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|foreignRevision
argument_list|,
name|otherSeen
argument_list|)
expr_stmt|;
comment|// TODO invalidating the whole cache is not really needed,
comment|// but how to ensure we invalidate the right part of the cache?
comment|// possibly simply wait for the background thread to pick
comment|// up the changes, but this depends on how often this method is called
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
comment|// the latest revisions of the current cluster node
comment|// happened before the latest revisions of other cluster nodes
name|revisionComparator
operator|.
name|add
argument_list|(
name|headRevision
argument_list|,
name|headSeen
argument_list|)
expr_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|changeRevision
argument_list|,
name|changeSeen
argument_list|)
expr_stmt|;
comment|// the head revision is after other revisions
name|headRevision
operator|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
comment|//----------------------< background operations>---------------------------
name|void
name|runBackgroundOperations
parameter_list|()
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|backgroundRenewClusterIdLease
argument_list|()
expr_stmt|;
if|if
condition|(
name|simpleRevisionCounter
operator|!=
literal|null
condition|)
block|{
comment|// only when using timestamp
return|return;
block|}
if|if
condition|(
operator|!
name|ENABLE_BACKGROUND_OPS
operator|||
name|stopBackground
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
try|try
block|{
name|backgroundSplit
argument_list|()
expr_stmt|;
name|backgroundWrite
argument_list|()
expr_stmt|;
name|backgroundRead
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Background operation failed: "
operator|+
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|backgroundRenewClusterIdLease
parameter_list|()
block|{
if|if
condition|(
name|clusterNodeInfo
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|clusterNodeInfo
operator|.
name|renewLease
argument_list|(
name|asyncDelay
argument_list|)
expr_stmt|;
block|}
name|void
name|backgroundRead
parameter_list|()
block|{
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|,
name|asyncDelay
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastRevMap
init|=
name|doc
operator|.
name|getLastRev
argument_list|()
decl_stmt|;
name|Revision
operator|.
name|RevisionComparator
name|revisionComparator
init|=
name|getRevisionComparator
argument_list|()
decl_stmt|;
name|boolean
name|hasNewRevisions
init|=
literal|false
decl_stmt|;
comment|// the (old) head occurred first
name|Revision
name|headSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// then we saw this new revision (from another cluster node)
name|Revision
name|otherSeen
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|e
range|:
name|lastRevMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|machineId
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|machineId
operator|==
name|clusterId
condition|)
block|{
continue|continue;
block|}
name|Revision
name|r
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Revision
name|last
init|=
name|lastKnownRevision
operator|.
name|get
argument_list|(
name|machineId
argument_list|)
decl_stmt|;
if|if
condition|(
name|last
operator|==
literal|null
operator|||
name|r
operator|.
name|compareRevisionTime
argument_list|(
name|last
argument_list|)
operator|>
literal|0
condition|)
block|{
name|lastKnownRevision
operator|.
name|put
argument_list|(
name|machineId
argument_list|,
name|r
argument_list|)
expr_stmt|;
name|hasNewRevisions
operator|=
literal|true
expr_stmt|;
name|revisionComparator
operator|.
name|add
argument_list|(
name|r
argument_list|,
name|otherSeen
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|hasNewRevisions
condition|)
block|{
comment|// TODO invalidating the whole cache is not really needed,
comment|// instead only those children that are cached could be checked
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
comment|// TODO only invalidate affected items
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
comment|// add a new revision, so that changes are visible
name|Revision
name|r
init|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
decl_stmt|;
comment|// the latest revisions of the current cluster node
comment|// happened before the latest revisions of other cluster nodes
name|revisionComparator
operator|.
name|add
argument_list|(
name|r
argument_list|,
name|headSeen
argument_list|)
expr_stmt|;
comment|// the head revision is after other revisions
name|headRevision
operator|=
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
block|}
name|revisionComparator
operator|.
name|purge
argument_list|(
name|Revision
operator|.
name|getCurrentTimestamp
argument_list|()
operator|-
name|REMEMBER_REVISION_ORDER_MILLIS
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|backgroundSplit
parameter_list|()
block|{
for|for
control|(
name|Iterator
argument_list|<
name|String
argument_list|>
name|it
init|=
name|splitCandidates
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|String
name|id
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|UpdateOp
name|op
range|:
name|doc
operator|.
name|split
argument_list|(
name|this
argument_list|)
control|)
block|{
name|NodeDocument
name|before
init|=
name|store
operator|.
name|createOrUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
decl_stmt|;
if|if
condition|(
name|before
operator|!=
literal|null
condition|)
block|{
name|NodeDocument
name|after
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|after
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Split operation on {}. Size before: {}, after: {}"
argument_list|,
operator|new
name|Object
index|[]
block|{
name|id
block|,
name|before
operator|.
name|getMemory
argument_list|()
block|,
name|after
operator|.
name|getMemory
argument_list|()
block|}
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
name|void
name|backgroundWrite
parameter_list|()
block|{
if|if
condition|(
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|ArrayList
argument_list|<
name|String
argument_list|>
name|paths
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
argument_list|)
decl_stmt|;
comment|// sort by depth (high depth first), then path
name|Collections
operator|.
name|sort
argument_list|(
name|paths
argument_list|,
operator|new
name|Comparator
argument_list|<
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|String
name|o1
parameter_list|,
name|String
name|o2
parameter_list|)
block|{
name|int
name|d1
init|=
name|Utils
operator|.
name|pathDepth
argument_list|(
name|o1
argument_list|)
decl_stmt|;
name|int
name|d2
init|=
name|Utils
operator|.
name|pathDepth
argument_list|(
name|o1
argument_list|)
decl_stmt|;
if|if
condition|(
name|d1
operator|!=
name|d2
condition|)
block|{
return|return
name|Integer
operator|.
name|signum
argument_list|(
name|d1
operator|-
name|d2
argument_list|)
return|;
block|}
return|return
name|o1
operator|.
name|compareTo
argument_list|(
name|o2
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|long
name|now
init|=
name|Revision
operator|.
name|getCurrentTimestamp
argument_list|()
decl_stmt|;
name|UpdateOp
name|updateOp
init|=
literal|null
decl_stmt|;
name|Revision
name|lastRev
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|ids
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|paths
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|String
name|p
init|=
name|paths
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Revision
name|r
init|=
name|unsavedLastRevisions
operator|.
name|get
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
comment|// FIXME: with below code fragment the root (and other nodes
comment|// 'close' to the root) will not be updated in MongoDB when there
comment|// are frequent changes.
if|if
condition|(
name|Revision
operator|.
name|getTimestampDifference
argument_list|(
name|now
argument_list|,
name|r
operator|.
name|getTimestamp
argument_list|()
argument_list|)
operator|<
name|asyncDelay
condition|)
block|{
continue|continue;
block|}
name|int
name|size
init|=
name|ids
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|updateOp
operator|==
literal|null
condition|)
block|{
comment|// create UpdateOp
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
literal|null
argument_list|,
name|r
argument_list|)
decl_stmt|;
name|commit
operator|.
name|touchNode
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|updateOp
operator|=
name|commit
operator|.
name|getUpdateOperationForNode
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|lastRev
operator|=
name|r
expr_stmt|;
name|ids
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|r
operator|.
name|equals
argument_list|(
name|lastRev
argument_list|)
condition|)
block|{
comment|// use multi update when possible
name|ids
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// update if this is the last path or
comment|// revision is not equal to last revision
if|if
condition|(
name|i
operator|+
literal|1
operator|>=
name|paths
operator|.
name|size
argument_list|()
operator|||
name|size
operator|==
name|ids
operator|.
name|size
argument_list|()
condition|)
block|{
name|store
operator|.
name|update
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|ids
argument_list|,
name|updateOp
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|id
range|:
name|ids
control|)
block|{
name|unsavedLastRevisions
operator|.
name|remove
argument_list|(
name|Utils
operator|.
name|getPathFromId
argument_list|(
name|id
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ids
operator|.
name|clear
argument_list|()
expr_stmt|;
name|updateOp
operator|=
literal|null
expr_stmt|;
name|lastRev
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|//-----------------------------< internal>---------------------------------
specifier|private
name|void
name|moveOrCopyNode
parameter_list|(
name|boolean
name|move
parameter_list|,
name|String
name|sourcePath
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
comment|// TODO Optimize - Move logic would not work well with very move of very large subtrees
comment|// At minimum we can optimize by traversing breadth wise and collect node id
comment|// and fetch them via '$in' queries
comment|// TODO Transient Node - Current logic does not account for operations which are part
comment|// of this commit i.e. transient nodes. If its required it would need to be looked
comment|// into
name|Node
name|n
init|=
name|getNode
argument_list|(
name|sourcePath
argument_list|,
name|commit
operator|.
name|getBaseRevision
argument_list|()
argument_list|)
decl_stmt|;
comment|// Node might be deleted already
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|Node
name|newNode
init|=
operator|new
name|Node
argument_list|(
name|targetPath
argument_list|,
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
decl_stmt|;
name|n
operator|.
name|copyTo
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|move
condition|)
block|{
name|markAsDeleted
argument_list|(
name|sourcePath
argument_list|,
name|commit
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|Node
operator|.
name|Children
name|c
init|=
name|getChildren
argument_list|(
name|sourcePath
argument_list|,
name|commit
operator|.
name|getBaseRevision
argument_list|()
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|srcChildPath
range|:
name|c
operator|.
name|children
control|)
block|{
name|String
name|childName
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|srcChildPath
argument_list|)
decl_stmt|;
name|String
name|destChildPath
init|=
name|PathUtils
operator|.
name|concat
argument_list|(
name|targetPath
argument_list|,
name|childName
argument_list|)
decl_stmt|;
name|moveOrCopyNode
argument_list|(
name|move
argument_list|,
name|srcChildPath
argument_list|,
name|destChildPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|checkRevisionAge
parameter_list|(
name|Revision
name|r
parameter_list|,
name|String
name|path
parameter_list|)
block|{
comment|// TODO only log if there are new revisions available for the given node
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|headRevision
operator|.
name|getTimestamp
argument_list|()
operator|-
name|r
operator|.
name|getTimestamp
argument_list|()
operator|>
name|WARN_REVISION_AGE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Requesting an old revision for path "
operator|+
name|path
operator|+
literal|", "
operator|+
operator|(
operator|(
name|headRevision
operator|.
name|getTimestamp
argument_list|()
operator|-
name|r
operator|.
name|getTimestamp
argument_list|()
operator|)
operator|/
literal|1000
operator|)
operator|+
literal|" seconds old"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * A background thread.      */
specifier|static
class|class
name|BackgroundOperation
implements|implements
name|Runnable
block|{
specifier|final
name|WeakReference
argument_list|<
name|MongoNodeStore
argument_list|>
name|ref
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
decl_stmt|;
specifier|private
name|int
name|delay
decl_stmt|;
name|BackgroundOperation
parameter_list|(
name|MongoNodeStore
name|nodeStore
parameter_list|,
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|ref
operator|=
operator|new
name|WeakReference
argument_list|<
name|MongoNodeStore
argument_list|>
argument_list|(
name|nodeStore
argument_list|)
expr_stmt|;
name|delay
operator|=
name|nodeStore
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
name|this
operator|.
name|isDisposed
operator|=
name|isDisposed
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|delay
operator|!=
literal|0
operator|&&
operator|!
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
try|try
block|{
name|isDisposed
operator|.
name|wait
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
block|}
name|MongoNodeStore
name|nodeStore
init|=
name|ref
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|nodeStore
operator|!=
literal|null
condition|)
block|{
name|nodeStore
operator|.
name|runBackgroundOperations
argument_list|()
expr_stmt|;
name|delay
operator|=
name|nodeStore
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
end_class

end_unit

