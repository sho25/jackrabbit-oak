begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
package|;
end_package

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkArgument
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkNotNull
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkState
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
operator|.
name|filter
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
operator|.
name|toArray
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
operator|.
name|transform
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
operator|.
name|newArrayList
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
operator|.
name|reverse
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|util
operator|.
name|Collections
operator|.
name|singletonList
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|PathUtils
operator|.
name|concat
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|Collection
operator|.
name|CLUSTER_NODES
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|Collection
operator|.
name|JOURNAL
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|Collection
operator|.
name|NODES
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|DocumentMK
operator|.
name|FAST_DIFF
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|DocumentMK
operator|.
name|MANY_CHILDREN_THRESHOLD
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|JournalEntry
operator|.
name|fillExternalChanges
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|UpdateOp
operator|.
name|Key
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|UpdateOp
operator|.
name|Operation
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|Utils
operator|.
name|asStringValueIterable
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|Utils
operator|.
name|getIdFromPath
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|Utils
operator|.
name|pathToId
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|ref
operator|.
name|WeakReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TimeZone
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|CheckForNull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nonnull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|jcr
operator|.
name|PropertyType
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|management
operator|.
name|NotCompliantMBeanException
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|management
operator|.
name|openmbean
operator|.
name|CompositeData
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Predicates
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Supplier
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Suppliers
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|Cache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Iterables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|UncheckedExecutionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|api
operator|.
name|stats
operator|.
name|TimeSeries
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|jmx
operator|.
name|AnnotatedStandardMBean
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|blob
operator|.
name|BlobStoreBlob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|blob
operator|.
name|MarkSweepGarbageCollector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|blob
operator|.
name|ReferencedBlob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|Branch
operator|.
name|BranchCommit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|persistentCache
operator|.
name|PersistentCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|persistentCache
operator|.
name|broadcast
operator|.
name|DynamicBroadcastConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|ReadOnlyDocumentStoreWrapperFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|BlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|json
operator|.
name|JsopStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|json
operator|.
name|JsopWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|sort
operator|.
name|StringSort
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|api
operator|.
name|Blob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|api
operator|.
name|CommitFailedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|cache
operator|.
name|CacheStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|commons
operator|.
name|PathUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|json
operator|.
name|BlobSerializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|LeaseCheckDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|LoggingDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|StringValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|TimingDocumentStoreWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
operator|.
name|util
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|blob
operator|.
name|GarbageCollectableBlobStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|ChangeDispatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|Observable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|CommitHook
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|CommitInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|commit
operator|.
name|Observer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|AbstractNodeState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|Clusterable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeStateDiff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|spi
operator|.
name|state
operator|.
name|NodeStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|stats
operator|.
name|Clock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|stats
operator|.
name|StatisticsProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|util
operator|.
name|PerfLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|stats
operator|.
name|TimeSeriesStatsUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Implementation of a NodeStore on {@link DocumentStore}.  */
end_comment

begin_class
specifier|public
specifier|final
class|class
name|DocumentNodeStore
implements|implements
name|NodeStore
implements|,
name|RevisionContext
implements|,
name|Observable
implements|,
name|Clusterable
implements|,
name|NodeStateDiffer
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DocumentNodeStore
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|PerfLogger
name|PERFLOG
init|=
operator|new
name|PerfLogger
argument_list|(
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DocumentNodeStore
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|".perf"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Do not cache more than this number of children for a document.      */
specifier|static
specifier|final
name|int
name|NUM_CHILDREN_CACHE_LIMIT
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.documentMK.childrenCacheLimit"
argument_list|,
literal|16
operator|*
literal|1024
argument_list|)
decl_stmt|;
comment|/**      * Feature flag to enable concurrent add/remove operations of hidden empty      * nodes. See OAK-2673.      */
specifier|private
name|boolean
name|enableConcurrentAddRemove
init|=
name|Boolean
operator|.
name|getBoolean
argument_list|(
literal|"oak.enableConcurrentAddRemove"
argument_list|)
decl_stmt|;
comment|/**      * Use fair mode for background operation lock.      */
specifier|private
name|boolean
name|fairBackgroundOperationLock
init|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"oak.fairBackgroundOperationLock"
argument_list|,
literal|"true"
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * The timeout in milliseconds to wait for the recovery performed by      * another cluster node.      */
specifier|private
name|long
name|recoveryWaitTimeoutMS
init|=
name|Long
operator|.
name|getLong
argument_list|(
literal|"oak.recoveryWaitTimeoutMS"
argument_list|,
literal|60000
argument_list|)
decl_stmt|;
comment|/**      * The document store (might be used by multiple node stores).      */
specifier|protected
specifier|final
name|DocumentStore
name|store
decl_stmt|;
comment|/**      * Marker node, indicating a node does not exist at a given revision.      */
specifier|protected
specifier|final
name|DocumentNodeState
name|missing
decl_stmt|;
comment|/**      * The commit queue to coordinate the commits.      */
specifier|protected
specifier|final
name|CommitQueue
name|commitQueue
decl_stmt|;
comment|/**      * Commit queue for batch updates.      */
specifier|protected
specifier|final
name|BatchCommitQueue
name|batchCommitQueue
decl_stmt|;
comment|/**      * The change dispatcher for this node store.      */
specifier|protected
specifier|final
name|ChangeDispatcher
name|dispatcher
decl_stmt|;
comment|/**      * The delay for asynchronous operations (delayed commit propagation and      * cache update).      */
specifier|protected
name|int
name|asyncDelay
init|=
literal|1000
decl_stmt|;
comment|/**      * The maximum back off time in milliseconds when merges are retried. The      * default value is twice the {@link #asyncDelay}.      */
specifier|protected
name|int
name|maxBackOffMillis
init|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.maxBackOffMS"
argument_list|,
name|asyncDelay
operator|*
literal|2
argument_list|)
decl_stmt|;
comment|/**      * Whether this instance is disposed.      */
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
comment|/**      * The cluster instance info.      */
annotation|@
name|Nonnull
specifier|private
specifier|final
name|ClusterNodeInfo
name|clusterNodeInfo
decl_stmt|;
comment|/**      * The unique cluster id, similar to the unique machine id in MongoDB.      */
specifier|private
specifier|final
name|int
name|clusterId
decl_stmt|;
comment|/**      * Map of known cluster nodes and the last known state updated      * by {@link #updateClusterState()}.      * Key: clusterId, value: ClusterNodeInfoDocument      */
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|Integer
argument_list|,
name|ClusterNodeInfoDocument
argument_list|>
name|clusterNodes
init|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
comment|/**      * Unmerged branches of this DocumentNodeStore instance.      */
specifier|private
specifier|final
name|UnmergedBranches
name|branches
decl_stmt|;
comment|/**      * The unsaved last revisions. This contains the parents of all changed      * nodes, once those nodes are committed but the parent node itself wasn't      * committed yet. The parents are not immediately persisted as this would      * cause each commit to change all parents (including the root node), which      * would limit write scalability.      *      * Key: path, value: revision.      */
specifier|private
specifier|final
name|UnsavedModifications
name|unsavedLastRevisions
init|=
operator|new
name|UnsavedModifications
argument_list|()
decl_stmt|;
comment|/**      * Set of IDs for documents that may need to be split.      */
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|splitCandidates
init|=
name|Maps
operator|.
name|newConcurrentMap
argument_list|()
decl_stmt|;
comment|/**      * Summary of changes done by this cluster node to persist by the background      * update thread.      */
specifier|private
name|JournalEntry
name|changes
decl_stmt|;
comment|/**      * The current root node state.      */
specifier|private
specifier|volatile
name|DocumentNodeState
name|root
decl_stmt|;
specifier|private
name|Thread
name|backgroundReadThread
decl_stmt|;
comment|/**      * Monitor object to synchronize background reads.      */
specifier|private
specifier|final
name|Object
name|backgroundReadMonitor
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
name|Thread
name|backgroundUpdateThread
decl_stmt|;
comment|/**      * Monitor object to synchronize background writes.      */
specifier|private
specifier|final
name|Object
name|backgroundWriteMonitor
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**      * Background thread performing the clusterId lease renew.      */
annotation|@
name|Nonnull
specifier|private
name|Thread
name|leaseUpdateThread
decl_stmt|;
comment|/**      * Read/Write lock for background operations. Regular commits will acquire      * a shared lock, while a background write acquires an exclusive lock.      */
specifier|private
specifier|final
name|ReadWriteLock
name|backgroundOperationLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|(
name|fairBackgroundOperationLock
argument_list|)
decl_stmt|;
comment|/**      * Read/Write lock to coordinate merges. In most cases merges acquire a      * shared read lock and can proceed concurrently. An exclusive write lock      * is acquired when the merge fails even after some retries and a final      * retry cycle is done.      * See {@link DocumentNodeStoreBranch#merge(CommitHook, CommitInfo)}.      */
specifier|private
specifier|final
name|ReadWriteLock
name|mergeLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|/**      * Enable using simple revisions (just a counter). This feature is useful      * for testing.      */
specifier|private
name|AtomicInteger
name|simpleRevisionCounter
decl_stmt|;
comment|/**      * The node cache.      *      * Key: PathRev, value: DocumentNodeState      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|PathRev
argument_list|,
name|DocumentNodeState
argument_list|>
name|nodeCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeCacheStats
decl_stmt|;
comment|/**      * Child node cache.      *      * Key: PathRev, value: Children      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|PathRev
argument_list|,
name|DocumentNodeState
operator|.
name|Children
argument_list|>
name|nodeChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|nodeChildrenCacheStats
decl_stmt|;
comment|/**      * Child doc cache.      *      * Key: StringValue, value: Children      */
specifier|private
specifier|final
name|Cache
argument_list|<
name|StringValue
argument_list|,
name|NodeDocument
operator|.
name|Children
argument_list|>
name|docChildrenCache
decl_stmt|;
specifier|private
specifier|final
name|CacheStats
name|docChildrenCacheStats
decl_stmt|;
comment|/**      * The change log to keep track of commits for diff operations.      */
specifier|private
specifier|final
name|DiffCache
name|diffCache
decl_stmt|;
comment|/**      * The blob store.      */
specifier|private
specifier|final
name|BlobStore
name|blobStore
decl_stmt|;
comment|/**      * The clusterStateChangeListener is invoked on any noticed change in the      * clusterNodes collection.      *<p>      * Note that there is no synchronization between setting this one and using      * it, but arguably that is not necessary since it will be set at startup      * time and then never be changed.      */
specifier|private
name|ClusterStateChangeListener
name|clusterStateChangeListener
decl_stmt|;
comment|/**      * The BlobSerializer.      */
specifier|private
specifier|final
name|BlobSerializer
name|blobSerializer
init|=
operator|new
name|BlobSerializer
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|serialize
parameter_list|(
name|Blob
name|blob
parameter_list|)
block|{
if|if
condition|(
name|blob
operator|instanceof
name|BlobStoreBlob
condition|)
block|{
name|BlobStoreBlob
name|bsb
init|=
operator|(
name|BlobStoreBlob
operator|)
name|blob
decl_stmt|;
name|BlobStore
name|bsbBlobStore
init|=
name|bsb
operator|.
name|getBlobStore
argument_list|()
decl_stmt|;
comment|//see if the blob has been created from another store
if|if
condition|(
name|bsbBlobStore
operator|!=
literal|null
operator|&&
name|bsbBlobStore
operator|.
name|equals
argument_list|(
name|blobStore
argument_list|)
condition|)
block|{
return|return
name|bsb
operator|.
name|getBlobId
argument_list|()
return|;
block|}
block|}
name|String
name|id
decl_stmt|;
name|String
name|reference
init|=
name|blob
operator|.
name|getReference
argument_list|()
decl_stmt|;
if|if
condition|(
name|reference
operator|!=
literal|null
condition|)
block|{
name|id
operator|=
name|blobStore
operator|.
name|getBlobId
argument_list|(
name|reference
argument_list|)
expr_stmt|;
if|if
condition|(
name|id
operator|!=
literal|null
condition|)
block|{
return|return
name|id
return|;
block|}
block|}
try|try
block|{
name|id
operator|=
name|createBlob
argument_list|(
name|blob
operator|.
name|getNewStream
argument_list|()
argument_list|)
operator|.
name|getBlobId
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
name|id
return|;
block|}
block|}
decl_stmt|;
comment|/**      * A predicate, which takes a String and returns {@code true} if the String      * is a serialized binary value of a {@link DocumentPropertyState}. The      * apply method will throw an IllegalArgumentException if the String is      * malformed.      */
specifier|private
specifier|final
name|Predicate
argument_list|<
name|String
argument_list|>
name|isBinary
init|=
operator|new
name|Predicate
argument_list|<
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
annotation|@
name|Nullable
name|String
name|input
parameter_list|)
block|{
if|if
condition|(
name|input
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|new
name|DocumentPropertyState
argument_list|(
name|DocumentNodeStore
operator|.
name|this
argument_list|,
literal|"p"
argument_list|,
name|input
argument_list|)
operator|.
name|getType
argument_list|()
operator|.
name|tag
argument_list|()
operator|==
name|PropertyType
operator|.
name|BINARY
return|;
block|}
block|}
decl_stmt|;
specifier|private
specifier|final
name|Clock
name|clock
decl_stmt|;
specifier|private
specifier|final
name|Checkpoints
name|checkpoints
decl_stmt|;
specifier|private
specifier|final
name|VersionGarbageCollector
name|versionGarbageCollector
decl_stmt|;
specifier|private
specifier|final
name|JournalGarbageCollector
name|journalGarbageCollector
decl_stmt|;
specifier|private
specifier|final
name|Iterable
argument_list|<
name|ReferencedBlob
argument_list|>
name|referencedBlobs
decl_stmt|;
specifier|private
specifier|final
name|Executor
name|executor
decl_stmt|;
specifier|private
specifier|final
name|LastRevRecoveryAgent
name|lastRevRecoveryAgent
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|disableBranches
decl_stmt|;
specifier|private
name|PersistentCache
name|persistentCache
decl_stmt|;
specifier|private
specifier|final
name|DocumentNodeStoreMBean
name|mbean
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|readOnlyMode
decl_stmt|;
specifier|private
name|DocumentNodeStateCache
name|nodeStateCache
init|=
name|DocumentNodeStateCache
operator|.
name|NOOP
decl_stmt|;
specifier|private
specifier|final
name|DocumentNodeStoreStatsCollector
name|nodeStoreStatsCollector
decl_stmt|;
specifier|private
specifier|final
name|StatisticsProvider
name|statisticsProvider
decl_stmt|;
specifier|public
name|DocumentNodeStore
parameter_list|(
name|DocumentMK
operator|.
name|Builder
name|builder
parameter_list|)
block|{
name|this
operator|.
name|blobStore
operator|=
name|builder
operator|.
name|getBlobStore
argument_list|()
expr_stmt|;
name|this
operator|.
name|statisticsProvider
operator|=
name|builder
operator|.
name|getStatisticsProvider
argument_list|()
expr_stmt|;
name|this
operator|.
name|nodeStoreStatsCollector
operator|=
name|builder
operator|.
name|getNodeStoreStatsCollector
argument_list|()
expr_stmt|;
if|if
condition|(
name|builder
operator|.
name|isUseSimpleRevision
argument_list|()
condition|)
block|{
name|this
operator|.
name|simpleRevisionCounter
operator|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|DocumentStore
name|s
init|=
name|builder
operator|.
name|getDocumentStore
argument_list|()
decl_stmt|;
if|if
condition|(
name|builder
operator|.
name|getTiming
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|TimingDocumentStoreWrapper
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|builder
operator|.
name|getLogging
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|LoggingDocumentStoreWrapper
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|builder
operator|.
name|getReadOnlyMode
argument_list|()
condition|)
block|{
name|s
operator|=
name|ReadOnlyDocumentStoreWrapperFactory
operator|.
name|getInstance
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|readOnlyMode
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|readOnlyMode
operator|=
literal|false
expr_stmt|;
block|}
name|this
operator|.
name|changes
operator|=
name|Collection
operator|.
name|JOURNAL
operator|.
name|newDocument
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|this
operator|.
name|executor
operator|=
name|builder
operator|.
name|getExecutor
argument_list|()
expr_stmt|;
name|this
operator|.
name|clock
operator|=
name|builder
operator|.
name|getClock
argument_list|()
expr_stmt|;
name|int
name|cid
init|=
name|builder
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
name|cid
operator|=
name|Integer
operator|.
name|getInteger
argument_list|(
literal|"oak.documentMK.clusterId"
argument_list|,
name|cid
argument_list|)
expr_stmt|;
if|if
condition|(
name|readOnlyMode
condition|)
block|{
name|clusterNodeInfo
operator|=
name|ClusterNodeInfo
operator|.
name|getReadOnlyInstance
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|clusterNodeInfo
operator|=
name|ClusterNodeInfo
operator|.
name|getInstance
argument_list|(
name|s
argument_list|,
name|cid
argument_list|)
expr_stmt|;
block|}
comment|// TODO we should ensure revisions generated from now on
comment|// are never "older" than revisions already in the repository for
comment|// this cluster id
name|cid
operator|=
name|clusterNodeInfo
operator|.
name|getId
argument_list|()
expr_stmt|;
if|if
condition|(
name|builder
operator|.
name|getLeaseCheck
argument_list|()
condition|)
block|{
name|s
operator|=
operator|new
name|LeaseCheckDocumentStoreWrapper
argument_list|(
name|s
argument_list|,
name|clusterNodeInfo
argument_list|)
expr_stmt|;
name|clusterNodeInfo
operator|.
name|setLeaseFailureHandler
argument_list|(
name|builder
operator|.
name|getLeaseFailureHandler
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|store
operator|=
name|s
expr_stmt|;
name|this
operator|.
name|clusterId
operator|=
name|cid
expr_stmt|;
name|this
operator|.
name|branches
operator|=
operator|new
name|UnmergedBranches
argument_list|()
expr_stmt|;
name|this
operator|.
name|asyncDelay
operator|=
name|builder
operator|.
name|getAsyncDelay
argument_list|()
expr_stmt|;
name|this
operator|.
name|versionGarbageCollector
operator|=
operator|new
name|VersionGarbageCollector
argument_list|(
name|this
argument_list|,
name|builder
operator|.
name|createVersionGCSupport
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|journalGarbageCollector
operator|=
operator|new
name|JournalGarbageCollector
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|referencedBlobs
operator|=
name|builder
operator|.
name|createReferencedBlobs
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastRevRecoveryAgent
operator|=
operator|new
name|LastRevRecoveryAgent
argument_list|(
name|this
argument_list|,
name|builder
operator|.
name|createMissingLastRevSeeker
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|disableBranches
operator|=
name|builder
operator|.
name|isDisableBranches
argument_list|()
expr_stmt|;
name|this
operator|.
name|missing
operator|=
operator|new
name|DocumentNodeState
argument_list|(
name|this
argument_list|,
literal|"MISSING"
argument_list|,
operator|new
name|RevisionVector
argument_list|(
operator|new
name|Revision
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
argument_list|)
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|int
name|getMemory
parameter_list|()
block|{
return|return
literal|8
return|;
block|}
block|}
expr_stmt|;
comment|//TODO Make stats collection configurable as it add slight overhead
name|nodeCache
operator|=
name|builder
operator|.
name|buildNodeCache
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|nodeCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeCache
argument_list|,
literal|"Document-NodeState"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getNodeCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|=
name|builder
operator|.
name|buildChildrenCache
argument_list|()
expr_stmt|;
name|nodeChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|nodeChildrenCache
argument_list|,
literal|"Document-NodeChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|=
name|builder
operator|.
name|buildDocChildrenCache
argument_list|()
expr_stmt|;
name|docChildrenCacheStats
operator|=
operator|new
name|CacheStats
argument_list|(
name|docChildrenCache
argument_list|,
literal|"Document-DocChildren"
argument_list|,
name|builder
operator|.
name|getWeigher
argument_list|()
argument_list|,
name|builder
operator|.
name|getDocChildrenCacheSize
argument_list|()
argument_list|)
expr_stmt|;
name|diffCache
operator|=
name|builder
operator|.
name|getDiffCache
argument_list|()
expr_stmt|;
name|checkpoints
operator|=
operator|new
name|Checkpoints
argument_list|(
name|this
argument_list|)
expr_stmt|;
comment|// check if root node exists
name|NodeDocument
name|rootDoc
init|=
name|store
operator|.
name|find
argument_list|(
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|rootDoc
operator|==
literal|null
condition|)
block|{
comment|// root node is missing: repository is not initialized
name|Revision
name|commitRev
init|=
name|newRevision
argument_list|()
decl_stmt|;
name|Commit
name|commit
init|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
name|commitRev
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|RevisionVector
name|head
init|=
operator|new
name|RevisionVector
argument_list|(
name|commitRev
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|n
init|=
operator|new
name|DocumentNodeState
argument_list|(
name|this
argument_list|,
literal|"/"
argument_list|,
name|head
argument_list|)
decl_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|n
argument_list|)
expr_stmt|;
name|commit
operator|.
name|applyToDocumentStore
argument_list|()
expr_stmt|;
name|unsavedLastRevisions
operator|.
name|put
argument_list|(
literal|"/"
argument_list|,
name|commitRev
argument_list|)
expr_stmt|;
name|setRoot
argument_list|(
name|head
argument_list|)
expr_stmt|;
comment|// make sure _lastRev is written back to store
name|backgroundWrite
argument_list|()
expr_stmt|;
name|rootDoc
operator|=
name|store
operator|.
name|find
argument_list|(
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|)
expr_stmt|;
comment|// at this point the root document must exist
if|if
condition|(
name|rootDoc
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Root document does not exist"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|readOnlyMode
condition|)
block|{
name|checkLastRevRecovery
argument_list|()
expr_stmt|;
block|}
name|initializeRootState
argument_list|(
name|rootDoc
argument_list|)
expr_stmt|;
comment|// check if _lastRev for our clusterId exists
if|if
condition|(
operator|!
name|rootDoc
operator|.
name|getLastRev
argument_list|()
operator|.
name|containsKey
argument_list|(
name|clusterId
argument_list|)
condition|)
block|{
name|unsavedLastRevisions
operator|.
name|put
argument_list|(
literal|"/"
argument_list|,
name|getRoot
argument_list|()
operator|.
name|getRevision
argument_list|()
operator|.
name|getRevision
argument_list|(
name|clusterId
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|readOnlyMode
condition|)
block|{
name|backgroundWrite
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// Renew the lease because it may have been stale
name|renewClusterIdLease
argument_list|()
expr_stmt|;
comment|// initialize branchCommits
name|branches
operator|.
name|init
argument_list|(
name|store
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|dispatcher
operator|=
operator|new
name|ChangeDispatcher
argument_list|(
name|getRoot
argument_list|()
argument_list|)
expr_stmt|;
name|commitQueue
operator|=
operator|new
name|CommitQueue
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|String
name|threadNamePostfix
init|=
literal|"("
operator|+
name|clusterId
operator|+
literal|")"
decl_stmt|;
name|batchCommitQueue
operator|=
operator|new
name|BatchCommitQueue
argument_list|(
name|store
argument_list|)
expr_stmt|;
name|backgroundReadThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|BackgroundReadOperation
argument_list|(
name|this
argument_list|,
name|isDisposed
argument_list|)
argument_list|,
literal|"DocumentNodeStore background read thread "
operator|+
name|threadNamePostfix
argument_list|)
expr_stmt|;
name|backgroundReadThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|backgroundUpdateThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|BackgroundOperation
argument_list|(
name|this
argument_list|,
name|isDisposed
argument_list|)
argument_list|,
literal|"DocumentNodeStore background update thread "
operator|+
name|threadNamePostfix
argument_list|)
expr_stmt|;
name|backgroundUpdateThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|backgroundReadThread
operator|.
name|start
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|readOnlyMode
condition|)
block|{
name|backgroundUpdateThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|leaseUpdateThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|BackgroundLeaseUpdate
argument_list|(
name|this
argument_list|,
name|isDisposed
argument_list|)
argument_list|,
literal|"DocumentNodeStore lease update thread "
operator|+
name|threadNamePostfix
argument_list|)
expr_stmt|;
name|leaseUpdateThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// OAK-3398 : make lease updating more robust by ensuring it
comment|// has higher likelihood of succeeding than other threads
comment|// on a very busy machine - so as to prevent lease timeout.
name|leaseUpdateThread
operator|.
name|setPriority
argument_list|(
name|Thread
operator|.
name|MAX_PRIORITY
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|readOnlyMode
condition|)
block|{
name|leaseUpdateThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|PersistentCache
name|pc
init|=
name|builder
operator|.
name|getPersistentCache
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|readOnlyMode
operator|&&
name|pc
operator|!=
literal|null
condition|)
block|{
name|DynamicBroadcastConfig
name|broadcastConfig
init|=
operator|new
name|DocumentBroadcastConfig
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|pc
operator|.
name|setBroadcastConfig
argument_list|(
name|broadcastConfig
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|mbean
operator|=
name|createMBean
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Initialized DocumentNodeStore with clusterNodeId: {} ({})"
argument_list|,
name|clusterId
argument_list|,
name|getClusterNodeInfoDisplayString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**      * Recover _lastRev recovery if needed.      *      * @throws DocumentStoreException if recovery did not finish within      *          {@link #recoveryWaitTimeoutMS}.      */
specifier|private
name|void
name|checkLastRevRecovery
parameter_list|()
throws|throws
name|DocumentStoreException
block|{
name|long
name|timeout
init|=
name|clock
operator|.
name|getTime
argument_list|()
operator|+
name|recoveryWaitTimeoutMS
decl_stmt|;
name|int
name|numRecovered
init|=
name|lastRevRecoveryAgent
operator|.
name|recover
argument_list|(
name|clusterId
argument_list|,
name|timeout
argument_list|)
decl_stmt|;
if|if
condition|(
name|numRecovered
operator|==
operator|-
literal|1
condition|)
block|{
name|ClusterNodeInfoDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|CLUSTER_NODES
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|clusterId
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|otherId
init|=
literal|"n/a"
decl_stmt|;
if|if
condition|(
name|doc
operator|!=
literal|null
condition|)
block|{
name|otherId
operator|=
name|String
operator|.
name|valueOf
argument_list|(
name|doc
operator|.
name|get
argument_list|(
name|ClusterNodeInfo
operator|.
name|REV_RECOVERY_BY
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|String
name|msg
init|=
literal|"This cluster node ("
operator|+
name|clusterId
operator|+
literal|") requires "
operator|+
literal|"_lastRev recovery which is currently performed by "
operator|+
literal|"another cluster node ("
operator|+
name|otherId
operator|+
literal|"). Recovery is "
operator|+
literal|"still ongoing after "
operator|+
name|recoveryWaitTimeoutMS
operator|+
literal|" ms. "
operator|+
literal|"Failing startup of this DocumentNodeStore now!"
decl_stmt|;
throw|throw
operator|new
name|DocumentStoreException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|dispose
parameter_list|()
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting disposal of DocumentNodeStore with clusterNodeId: {} ({})"
argument_list|,
name|clusterId
argument_list|,
name|getClusterNodeInfoDisplayString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isDisposed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
comment|// only dispose once
return|return;
block|}
comment|// notify background threads waiting on isDisposed
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
name|isDisposed
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|backgroundReadThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
try|try
block|{
name|backgroundUpdateThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
comment|// do a final round of background operations after
comment|// the background thread stopped
if|if
condition|(
operator|!
name|readOnlyMode
condition|)
block|{
try|try
block|{
name|internalRunBackgroundUpdateOperations
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AssertionError
name|ae
parameter_list|)
block|{
comment|// OAK-3250 : when a lease check fails, subsequent modifying requests
comment|// to the DocumentStore will throw an AssertionError. Since as a result
comment|// of a failing lease check a bundle.stop is done and thus a dispose of the
comment|// DocumentNodeStore happens, it is very likely that in that case
comment|// you run into an AssertionError. We should still continue with disposing
comment|// though - thus catching and logging..
name|LOG
operator|.
name|error
argument_list|(
literal|"dispose: an AssertionError happened during dispose's last background ops: "
operator|+
name|ae
argument_list|,
name|ae
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|leaseUpdateThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
comment|// now mark this cluster node as inactive by
comment|// disposing the clusterNodeInfo
name|clusterNodeInfo
operator|.
name|dispose
argument_list|()
expr_stmt|;
name|store
operator|.
name|dispose
argument_list|()
expr_stmt|;
if|if
condition|(
name|blobStore
operator|instanceof
name|Closeable
condition|)
block|{
try|try
block|{
operator|(
operator|(
name|Closeable
operator|)
name|blobStore
operator|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Error closing blob store "
operator|+
name|blobStore
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|persistentCache
operator|!=
literal|null
condition|)
block|{
name|persistentCache
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Disposed DocumentNodeStore with clusterNodeId: {}"
argument_list|,
name|clusterId
argument_list|)
expr_stmt|;
block|}
specifier|private
name|String
name|getClusterNodeInfoDisplayString
parameter_list|()
block|{
return|return
operator|(
name|readOnlyMode
condition|?
literal|"readOnly:true, "
else|:
literal|""
operator|)
operator|+
name|clusterNodeInfo
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"[\r\n\t]"
argument_list|,
literal|" "
argument_list|)
operator|.
name|trim
argument_list|()
return|;
block|}
name|void
name|setRoot
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|newHead
parameter_list|)
block|{
name|checkArgument
argument_list|(
operator|!
name|newHead
operator|.
name|isBranch
argument_list|()
argument_list|)
expr_stmt|;
name|root
operator|=
name|getRoot
argument_list|(
name|newHead
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Nonnull
specifier|public
name|DocumentStore
name|getDocumentStore
parameter_list|()
block|{
return|return
name|store
return|;
block|}
comment|/**      * Creates a new commit. The caller must acknowledge the commit either with      * {@link #done(Commit, boolean, CommitInfo)} or {@link #canceled(Commit)},      * depending on the result of the commit.      *      * @param base the base revision for the commit or<code>null</code> if the      *             commit should use the current head revision as base.      * @param branch the branch instance if this is a branch commit. The life      *               time of this branch commit is controlled by the      *               reachability of this parameter. Once {@code branch} is      *               weakly reachable, the document store implementation is      *               free to remove the commits associated with the branch.      * @return a new commit.      */
annotation|@
name|Nonnull
name|Commit
name|newCommit
parameter_list|(
annotation|@
name|Nullable
name|RevisionVector
name|base
parameter_list|,
annotation|@
name|Nullable
name|DocumentNodeStoreBranch
name|branch
parameter_list|)
block|{
if|if
condition|(
name|base
operator|==
literal|null
condition|)
block|{
name|base
operator|=
name|getHeadRevision
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|base
operator|.
name|isBranch
argument_list|()
condition|)
block|{
return|return
name|newBranchCommit
argument_list|(
name|base
argument_list|,
name|branch
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|newTrunkCommit
argument_list|(
name|base
argument_list|)
return|;
block|}
block|}
comment|/**      * Creates a new merge commit. The caller must acknowledge the commit either with      * {@link #done(Commit, boolean, CommitInfo)} or {@link #canceled(Commit)},      * depending on the result of the commit.      *      * @param base the base revision for the commit or<code>null</code> if the      *             commit should use the current head revision as base.      * @param numBranchCommits the number of branch commits to merge.      * @return a new merge commit.      */
annotation|@
name|Nonnull
name|MergeCommit
name|newMergeCommit
parameter_list|(
annotation|@
name|Nullable
name|RevisionVector
name|base
parameter_list|,
name|int
name|numBranchCommits
parameter_list|)
block|{
if|if
condition|(
name|base
operator|==
literal|null
condition|)
block|{
name|base
operator|=
name|getHeadRevision
argument_list|()
expr_stmt|;
block|}
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|MergeCommit
name|c
decl_stmt|;
try|try
block|{
name|checkOpen
argument_list|()
expr_stmt|;
name|c
operator|=
operator|new
name|MergeCommit
argument_list|(
name|this
argument_list|,
name|base
argument_list|,
name|commitQueue
operator|.
name|createRevisions
argument_list|(
name|numBranchCommits
argument_list|)
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|c
return|;
block|}
name|RevisionVector
name|done
parameter_list|(
specifier|final
annotation|@
name|Nonnull
name|Commit
name|c
parameter_list|,
name|boolean
name|isBranch
parameter_list|,
specifier|final
annotation|@
name|Nullable
name|CommitInfo
name|info
parameter_list|)
block|{
if|if
condition|(
name|commitQueue
operator|.
name|contains
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
argument_list|)
condition|)
block|{
try|try
block|{
specifier|final
name|RevisionVector
index|[]
name|newHead
init|=
operator|new
name|RevisionVector
index|[
literal|1
index|]
decl_stmt|;
name|commitQueue
operator|.
name|done
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
argument_list|,
operator|new
name|CommitQueue
operator|.
name|Callback
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|headOfQueue
parameter_list|(
annotation|@
name|Nonnull
name|Revision
name|revision
parameter_list|)
block|{
comment|// remember before revision
name|RevisionVector
name|before
init|=
name|getHeadRevision
argument_list|()
decl_stmt|;
comment|// apply changes to cache based on before revision
name|c
operator|.
name|applyToCache
argument_list|(
name|before
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// track modified paths
name|changes
operator|.
name|modified
argument_list|(
name|c
operator|.
name|getModifiedPaths
argument_list|()
argument_list|)
expr_stmt|;
comment|// update head revision
name|newHead
index|[
literal|0
index|]
operator|=
name|before
operator|.
name|update
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
argument_list|)
expr_stmt|;
name|setRoot
argument_list|(
name|newHead
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|commitQueue
operator|.
name|headRevisionChanged
argument_list|()
expr_stmt|;
name|dispatcher
operator|.
name|contentChanged
argument_list|(
name|getRoot
argument_list|()
argument_list|,
name|info
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|newHead
index|[
literal|0
index|]
return|;
block|}
finally|finally
block|{
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// branch commit
name|c
operator|.
name|applyToCache
argument_list|(
name|c
operator|.
name|getBaseRevision
argument_list|()
argument_list|,
name|isBranch
argument_list|)
expr_stmt|;
return|return
name|c
operator|.
name|getBaseRevision
argument_list|()
operator|.
name|update
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
operator|.
name|asBranchRevision
argument_list|()
argument_list|)
return|;
block|}
block|}
name|void
name|canceled
parameter_list|(
name|Commit
name|c
parameter_list|)
block|{
if|if
condition|(
name|commitQueue
operator|.
name|contains
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
argument_list|)
condition|)
block|{
try|try
block|{
name|commitQueue
operator|.
name|canceled
argument_list|(
name|c
operator|.
name|getRevision
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|setAsyncDelay
parameter_list|(
name|int
name|delay
parameter_list|)
block|{
name|this
operator|.
name|asyncDelay
operator|=
name|delay
expr_stmt|;
block|}
specifier|public
name|int
name|getAsyncDelay
parameter_list|()
block|{
return|return
name|asyncDelay
return|;
block|}
specifier|public
name|void
name|setMaxBackOffMillis
parameter_list|(
name|int
name|time
parameter_list|)
block|{
name|maxBackOffMillis
operator|=
name|time
expr_stmt|;
block|}
specifier|public
name|int
name|getMaxBackOffMillis
parameter_list|()
block|{
return|return
name|maxBackOffMillis
return|;
block|}
name|void
name|setEnableConcurrentAddRemove
parameter_list|(
name|boolean
name|b
parameter_list|)
block|{
name|enableConcurrentAddRemove
operator|=
name|b
expr_stmt|;
block|}
name|boolean
name|getEnableConcurrentAddRemove
parameter_list|()
block|{
return|return
name|enableConcurrentAddRemove
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|ClusterNodeInfo
name|getClusterInfo
parameter_list|()
block|{
return|return
name|clusterNodeInfo
return|;
block|}
specifier|public
name|CacheStats
name|getNodeCacheStats
parameter_list|()
block|{
return|return
name|nodeCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getNodeChildrenCacheStats
parameter_list|()
block|{
return|return
name|nodeChildrenCacheStats
return|;
block|}
specifier|public
name|CacheStats
name|getDocChildrenCacheStats
parameter_list|()
block|{
return|return
name|docChildrenCacheStats
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|Iterable
argument_list|<
name|CacheStats
argument_list|>
name|getDiffCacheStats
parameter_list|()
block|{
return|return
name|diffCache
operator|.
name|getStats
argument_list|()
return|;
block|}
name|void
name|invalidateDocChildrenCache
parameter_list|()
block|{
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
block|}
name|void
name|invalidateNodeChildrenCache
parameter_list|()
block|{
name|nodeChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
block|}
name|void
name|invalidateNodeCache
parameter_list|(
name|String
name|path
parameter_list|,
name|RevisionVector
name|revision
parameter_list|)
block|{
name|nodeCache
operator|.
name|invalidate
argument_list|(
operator|new
name|PathRev
argument_list|(
name|path
argument_list|,
name|revision
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|public
name|int
name|getPendingWriteCount
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
operator|.
name|getPaths
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
name|boolean
name|isDisableBranches
parameter_list|()
block|{
return|return
name|disableBranches
return|;
block|}
comment|/**      * Enqueue the document with the given id as a split candidate.      *      * @param id the id of the document to check if it needs to be split.      */
name|void
name|addSplitCandidate
parameter_list|(
name|String
name|id
parameter_list|)
block|{
name|splitCandidates
operator|.
name|put
argument_list|(
name|id
argument_list|,
name|id
argument_list|)
expr_stmt|;
block|}
name|void
name|copyNode
parameter_list|(
name|DocumentNodeState
name|source
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|false
argument_list|,
name|source
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
name|void
name|moveNode
parameter_list|(
name|DocumentNodeState
name|source
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
name|moveOrCopyNode
argument_list|(
literal|true
argument_list|,
name|source
argument_list|,
name|targetPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
name|void
name|markAsDeleted
parameter_list|(
name|DocumentNodeState
name|node
parameter_list|,
name|Commit
name|commit
parameter_list|,
name|boolean
name|subTreeAlso
parameter_list|)
block|{
name|commit
operator|.
name|removeNode
argument_list|(
name|node
operator|.
name|getPath
argument_list|()
argument_list|,
name|node
argument_list|)
expr_stmt|;
if|if
condition|(
name|subTreeAlso
condition|)
block|{
comment|// recurse down the tree
comment|// TODO causes issue with large number of children
for|for
control|(
name|DocumentNodeState
name|child
range|:
name|getChildNodes
argument_list|(
name|node
argument_list|,
literal|null
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
control|)
block|{
name|markAsDeleted
argument_list|(
name|child
argument_list|,
name|commit
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|CheckForNull
name|AbstractDocumentNodeState
name|getSecondaryNodeState
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|String
name|path
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|RevisionVector
name|rootRevision
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|RevisionVector
name|rev
parameter_list|)
block|{
comment|//Check secondary cache first
return|return
name|nodeStateCache
operator|.
name|getDocumentNodeState
argument_list|(
name|path
argument_list|,
name|rootRevision
argument_list|,
name|rev
argument_list|)
return|;
block|}
comment|/**      * Get the node for the given path and revision. The returned object might      * not be modified directly.      *      * @param path the path of the node.      * @param rev the read revision.      * @return the node or<code>null</code> if the node does not exist at the      *          given revision.      */
annotation|@
name|CheckForNull
name|DocumentNodeState
name|getNode
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|String
name|path
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|RevisionVector
name|rev
parameter_list|)
block|{
name|checkNotNull
argument_list|(
name|rev
argument_list|)
expr_stmt|;
name|checkNotNull
argument_list|(
name|path
argument_list|)
expr_stmt|;
specifier|final
name|long
name|start
init|=
name|PERFLOG
operator|.
name|start
argument_list|()
decl_stmt|;
try|try
block|{
name|PathRev
name|key
init|=
operator|new
name|PathRev
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|node
init|=
name|nodeCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|DocumentNodeState
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DocumentNodeState
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|boolean
name|nodeDoesNotExist
init|=
name|checkNodeNotExistsFromChildrenCache
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|nodeDoesNotExist
condition|)
block|{
return|return
name|missing
return|;
block|}
name|DocumentNodeState
name|n
init|=
name|readNode
argument_list|(
name|path
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|==
literal|null
condition|)
block|{
name|n
operator|=
name|missing
expr_stmt|;
block|}
return|return
name|n
return|;
block|}
block|}
argument_list|)
decl_stmt|;
specifier|final
name|DocumentNodeState
name|result
init|=
name|node
operator|==
name|missing
operator|||
name|node
operator|.
name|equals
argument_list|(
name|missing
argument_list|)
condition|?
literal|null
else|:
name|node
decl_stmt|;
name|PERFLOG
operator|.
name|end
argument_list|(
name|start
argument_list|,
literal|1
argument_list|,
literal|"getNode: path={}, rev={}"
argument_list|,
name|path
argument_list|,
name|rev
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|UncheckedExecutionException
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|DocumentNodeState
operator|.
name|Children
name|getChildren
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|AbstractDocumentNodeState
name|parent
parameter_list|,
annotation|@
name|Nullable
specifier|final
name|String
name|name
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|)
throws|throws
name|DocumentStoreException
block|{
if|if
condition|(
name|checkNotNull
argument_list|(
name|parent
argument_list|)
operator|.
name|hasNoChildren
argument_list|()
condition|)
block|{
return|return
name|DocumentNodeState
operator|.
name|NO_CHILDREN
return|;
block|}
specifier|final
name|String
name|path
init|=
name|checkNotNull
argument_list|(
name|parent
argument_list|)
operator|.
name|getPath
argument_list|()
decl_stmt|;
specifier|final
name|RevisionVector
name|readRevision
init|=
name|parent
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
try|try
block|{
name|PathRev
name|key
init|=
name|childNodeCacheKey
argument_list|(
name|path
argument_list|,
name|readRevision
argument_list|,
name|name
argument_list|)
decl_stmt|;
name|DocumentNodeState
operator|.
name|Children
name|children
init|=
name|nodeChildrenCache
operator|.
name|get
argument_list|(
name|key
argument_list|,
operator|new
name|Callable
argument_list|<
name|DocumentNodeState
operator|.
name|Children
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DocumentNodeState
operator|.
name|Children
name|call
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|readChildren
argument_list|(
name|parent
argument_list|,
name|name
argument_list|,
name|limit
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
if|if
condition|(
name|children
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
name|children
operator|.
name|hasMore
condition|)
block|{
comment|// not enough children loaded - load more,
comment|// and put that in the cache
comment|// (not using nodeChildrenCache.invalidate, because
comment|// the generational persistent cache doesn't support that)
name|children
operator|=
name|readChildren
argument_list|(
name|parent
argument_list|,
name|name
argument_list|,
name|limit
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|children
argument_list|)
expr_stmt|;
block|}
return|return
name|children
return|;
block|}
catch|catch
parameter_list|(
name|UncheckedExecutionException
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|,
literal|"Error occurred while fetching children for path "
operator|+
name|path
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|,
literal|"Error occurred while fetching children for path "
operator|+
name|path
argument_list|)
throw|;
block|}
block|}
comment|/**      * Read the children of the given parent node state starting at the child      * node with {@code name}. The given {@code name} is exclusive and will not      * appear in the list of children. The returned children are sorted in      * ascending order.      *      * @param parent the parent node.      * @param name the name of the lower bound child node (exclusive) or      *              {@code null} if no lower bound is given.      * @param limit the maximum number of child nodes to return.      * @return the children of {@code parent}.      */
name|DocumentNodeState
operator|.
name|Children
name|readChildren
parameter_list|(
name|AbstractDocumentNodeState
name|parent
parameter_list|,
name|String
name|name
parameter_list|,
name|int
name|limit
parameter_list|)
block|{
name|String
name|queriedName
init|=
name|name
decl_stmt|;
name|String
name|path
init|=
name|parent
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|RevisionVector
name|rev
init|=
name|parent
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Reading children for [{}] at rev [{}]"
argument_list|,
name|path
argument_list|,
name|rev
argument_list|)
expr_stmt|;
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|docs
decl_stmt|;
name|DocumentNodeState
operator|.
name|Children
name|c
init|=
operator|new
name|DocumentNodeState
operator|.
name|Children
argument_list|()
decl_stmt|;
comment|// add one to the requested limit for the raw limit
comment|// this gives us a chance to detect whether there are more
comment|// child nodes than requested.
name|int
name|rawLimit
init|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|,
operator|(
operator|(
name|long
operator|)
name|limit
operator|)
operator|+
literal|1
argument_list|)
decl_stmt|;
for|for
control|(
init|;
condition|;
control|)
block|{
name|docs
operator|=
name|readChildDocs
argument_list|(
name|path
argument_list|,
name|name
argument_list|,
name|rawLimit
argument_list|)
expr_stmt|;
name|int
name|numReturned
init|=
literal|0
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|numReturned
operator|++
expr_stmt|;
name|String
name|p
init|=
name|doc
operator|.
name|getPath
argument_list|()
decl_stmt|;
comment|// remember name of last returned document for
comment|// potential next round of readChildDocs()
name|name
operator|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
expr_stmt|;
comment|// filter out deleted children
name|DocumentNodeState
name|child
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|rev
argument_list|)
decl_stmt|;
if|if
condition|(
name|child
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<
name|limit
condition|)
block|{
comment|// add to children until limit is reached
name|c
operator|.
name|children
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|unshareString
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// enough collected and we know there are more
name|c
operator|.
name|hasMore
operator|=
literal|true
expr_stmt|;
return|return
name|c
return|;
block|}
block|}
comment|// if we get here we have less than or equal the requested children
if|if
condition|(
name|numReturned
operator|<
name|rawLimit
condition|)
block|{
comment|// fewer documents returned than requested
comment|// -> no more documents
name|c
operator|.
name|hasMore
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|queriedName
operator|==
literal|null
condition|)
block|{
comment|//we've got to the end of list and we started from the top
comment|//This list is complete and can be sorted
name|Collections
operator|.
name|sort
argument_list|(
name|c
operator|.
name|children
argument_list|)
expr_stmt|;
block|}
return|return
name|c
return|;
block|}
block|}
block|}
comment|/**      * Returns the child documents at the given {@code path} and returns up to      * {@code limit} documents. The returned child documents are sorted in      * ascending child node name order. If a {@code name} is passed, the first      * child document returned is after the given name. That is, the name is the      * lower exclusive bound.      *      * @param path the path of the parent document.      * @param name the lower exclusive bound or {@code null}.      * @param limit the maximum number of child documents to return.      * @return the child documents.      */
annotation|@
name|Nonnull
specifier|private
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|readChildDocs
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|String
name|path
parameter_list|,
annotation|@
name|Nullable
name|String
name|name
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|)
block|{
specifier|final
name|String
name|to
init|=
name|Utils
operator|.
name|getKeyUpperLimit
argument_list|(
name|checkNotNull
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|String
name|from
decl_stmt|;
if|if
condition|(
name|name
operator|!=
literal|null
condition|)
block|{
name|from
operator|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|concat
argument_list|(
name|path
argument_list|,
name|name
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|from
operator|=
name|Utils
operator|.
name|getKeyLowerLimit
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|name
operator|!=
literal|null
operator|||
name|limit
operator|>
name|NUM_CHILDREN_CACHE_LIMIT
condition|)
block|{
comment|// do not use cache when there is a lower bound name
comment|// or more than 16k child docs are requested
return|return
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
return|;
block|}
specifier|final
name|StringValue
name|key
init|=
operator|new
name|StringValue
argument_list|(
name|path
argument_list|)
decl_stmt|;
comment|// check cache
name|NodeDocument
operator|.
name|Children
name|c
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|c
operator|==
literal|null
condition|)
block|{
name|c
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|docs
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|from
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|String
name|p
init|=
name|doc
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|c
operator|.
name|childNames
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|c
operator|.
name|isComplete
operator|=
name|docs
operator|.
name|size
argument_list|()
operator|<
name|limit
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|c
argument_list|)
expr_stmt|;
return|return
name|docs
return|;
block|}
elseif|else
if|if
condition|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|<
name|limit
operator|&&
operator|!
name|c
operator|.
name|isComplete
condition|)
block|{
comment|// fetch more and update cache
name|String
name|lastName
init|=
name|c
operator|.
name|childNames
operator|.
name|get
argument_list|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|String
name|lastPath
init|=
name|concat
argument_list|(
name|path
argument_list|,
name|lastName
argument_list|)
decl_stmt|;
name|String
name|low
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|lastPath
argument_list|)
decl_stmt|;
name|int
name|remainingLimit
init|=
name|limit
operator|-
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|NodeDocument
argument_list|>
name|docs
init|=
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|low
argument_list|,
name|to
argument_list|,
name|remainingLimit
argument_list|)
decl_stmt|;
name|NodeDocument
operator|.
name|Children
name|clone
init|=
name|c
operator|.
name|clone
argument_list|()
decl_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|docs
control|)
block|{
name|String
name|p
init|=
name|doc
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|clone
operator|.
name|childNames
operator|.
name|add
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|clone
operator|.
name|isComplete
operator|=
name|docs
operator|.
name|size
argument_list|()
operator|<
name|remainingLimit
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|clone
argument_list|)
expr_stmt|;
name|c
operator|=
name|clone
expr_stmt|;
block|}
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|head
init|=
name|filter
argument_list|(
name|transform
argument_list|(
name|c
operator|.
name|childNames
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|NodeDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|NodeDocument
name|apply
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|String
name|p
init|=
name|concat
argument_list|(
name|path
argument_list|,
name|name
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|p
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
name|docChildrenCache
operator|.
name|invalidate
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
return|return
name|doc
return|;
block|}
block|}
argument_list|)
argument_list|,
name|Predicates
operator|.
name|notNull
argument_list|()
argument_list|)
decl_stmt|;
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|it
decl_stmt|;
if|if
condition|(
name|c
operator|.
name|isComplete
condition|)
block|{
name|it
operator|=
name|head
expr_stmt|;
block|}
else|else
block|{
comment|// OAK-2420: 'head' may have null documents when documents are
comment|// concurrently removed from the store. concat 'tail' to fetch
comment|// more documents if necessary
specifier|final
name|String
name|last
init|=
name|getIdFromPath
argument_list|(
name|concat
argument_list|(
name|path
argument_list|,
name|c
operator|.
name|childNames
operator|.
name|get
argument_list|(
name|c
operator|.
name|childNames
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
name|tail
init|=
operator|new
name|Iterable
argument_list|<
name|NodeDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Iterator
argument_list|<
name|NodeDocument
argument_list|>
name|iterator
parameter_list|()
block|{
return|return
name|store
operator|.
name|query
argument_list|(
name|NODES
argument_list|,
name|last
argument_list|,
name|to
argument_list|,
name|limit
argument_list|)
operator|.
name|iterator
argument_list|()
return|;
block|}
block|}
decl_stmt|;
name|it
operator|=
name|Iterables
operator|.
name|concat
argument_list|(
name|head
argument_list|,
name|tail
argument_list|)
expr_stmt|;
block|}
return|return
name|Iterables
operator|.
name|limit
argument_list|(
name|it
argument_list|,
name|limit
argument_list|)
return|;
block|}
comment|/**      * Returns up to {@code limit} child nodes, starting at the given      * {@code name} (exclusive).      *      * @param parent the parent node.      * @param name the name of the lower bound child node (exclusive) or      *             {@code null}, if the method should start with the first known      *             child node.      * @param limit the maximum number of child nodes to return.      * @return the child nodes.      */
annotation|@
name|Nonnull
name|Iterable
argument_list|<
name|DocumentNodeState
argument_list|>
name|getChildNodes
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|DocumentNodeState
name|parent
parameter_list|,
annotation|@
name|Nullable
specifier|final
name|String
name|name
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|)
block|{
comment|// Preemptive check. If we know there are no children then
comment|// return straight away
if|if
condition|(
name|checkNotNull
argument_list|(
name|parent
argument_list|)
operator|.
name|hasNoChildren
argument_list|()
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
specifier|final
name|RevisionVector
name|readRevision
init|=
name|parent
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
return|return
name|transform
argument_list|(
name|getChildren
argument_list|(
name|parent
argument_list|,
name|name
argument_list|,
name|limit
argument_list|)
operator|.
name|children
argument_list|,
operator|new
name|Function
argument_list|<
name|String
argument_list|,
name|DocumentNodeState
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DocumentNodeState
name|apply
parameter_list|(
name|String
name|input
parameter_list|)
block|{
name|String
name|p
init|=
name|concat
argument_list|(
name|parent
operator|.
name|getPath
argument_list|()
argument_list|,
name|input
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|result
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|readRevision
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|DocumentStoreException
argument_list|(
literal|"DocumentNodeState is null for revision "
operator|+
name|readRevision
operator|+
literal|" of "
operator|+
name|p
operator|+
literal|" (aborting getChildNodes())"
argument_list|)
throw|;
block|}
return|return
name|result
return|;
block|}
block|}
argument_list|)
return|;
block|}
annotation|@
name|CheckForNull
name|DocumentNodeState
name|readNode
parameter_list|(
name|String
name|path
parameter_list|,
name|RevisionVector
name|readRevision
parameter_list|)
block|{
specifier|final
name|long
name|start
init|=
name|PERFLOG
operator|.
name|start
argument_list|()
decl_stmt|;
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|Revision
name|lastRevision
init|=
name|getPendingModifications
argument_list|()
operator|.
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
name|PERFLOG
operator|.
name|end
argument_list|(
name|start
argument_list|,
literal|1
argument_list|,
literal|"readNode: (document not found) path={}, readRevision={}"
argument_list|,
name|path
argument_list|,
name|readRevision
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
specifier|final
name|DocumentNodeState
name|result
init|=
name|doc
operator|.
name|getNodeAtRevision
argument_list|(
name|this
argument_list|,
name|readRevision
argument_list|,
name|lastRevision
argument_list|)
decl_stmt|;
name|PERFLOG
operator|.
name|end
argument_list|(
name|start
argument_list|,
literal|1
argument_list|,
literal|"readNode: path={}, readRevision={}"
argument_list|,
name|path
argument_list|,
name|readRevision
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**      * Apply the changes of a node to the cache.      *      * @param before the before revision (old head)      * @param after the after revision (new head)      * @param rev the commit revision      * @param path the path      * @param isNew whether this is a new node      * @param added the list of added child nodes      * @param removed the list of removed child nodes      * @param changed the list of changed child nodes      *      */
name|void
name|applyChanges
parameter_list|(
name|RevisionVector
name|before
parameter_list|,
name|RevisionVector
name|after
parameter_list|,
name|Revision
name|rev
parameter_list|,
name|String
name|path
parameter_list|,
name|boolean
name|isNew
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|added
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|removed
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|changed
parameter_list|,
name|DiffCache
operator|.
name|Entry
name|cacheEntry
parameter_list|)
block|{
if|if
condition|(
name|isNew
condition|)
block|{
if|if
condition|(
name|added
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// this is a leaf node.
comment|// check if it has the children flag set
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|NODES
argument_list|,
name|getIdFromPath
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|!=
literal|null
operator|&&
name|doc
operator|.
name|hasChildren
argument_list|()
condition|)
block|{
name|PathRev
name|key
init|=
name|childNodeCacheKey
argument_list|(
name|path
argument_list|,
name|after
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"nodeChildrenCache.put({},{})"
argument_list|,
name|key
argument_list|,
literal|"NO_CHILDREN"
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|DocumentNodeState
operator|.
name|NO_CHILDREN
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|DocumentNodeState
operator|.
name|Children
name|c
init|=
operator|new
name|DocumentNodeState
operator|.
name|Children
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|set
init|=
name|Sets
operator|.
name|newTreeSet
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|added
control|)
block|{
name|set
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|unshareString
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|c
operator|.
name|children
operator|.
name|addAll
argument_list|(
name|set
argument_list|)
expr_stmt|;
name|PathRev
name|key
init|=
name|childNodeCacheKey
argument_list|(
name|path
argument_list|,
name|after
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"nodeChildrenCache.put({},{})"
argument_list|,
name|key
argument_list|,
name|c
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// existed before
name|DocumentNodeState
name|beforeState
init|=
name|getRoot
argument_list|(
name|before
argument_list|)
decl_stmt|;
comment|// do we have a cached before state that can be used
comment|// to calculate the new children?
name|int
name|depth
init|=
name|PathUtils
operator|.
name|getDepth
argument_list|(
name|path
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|depth
operator|&&
name|beforeState
operator|!=
literal|null
condition|;
name|i
operator|++
control|)
block|{
name|String
name|p
init|=
name|PathUtils
operator|.
name|getAncestorPath
argument_list|(
name|path
argument_list|,
name|depth
operator|-
name|i
argument_list|)
decl_stmt|;
name|PathRev
name|key
init|=
operator|new
name|PathRev
argument_list|(
name|p
argument_list|,
name|beforeState
operator|.
name|getLastRevision
argument_list|()
argument_list|)
decl_stmt|;
name|beforeState
operator|=
name|nodeCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
name|DocumentNodeState
operator|.
name|Children
name|children
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|beforeState
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|beforeState
operator|.
name|hasNoChildren
argument_list|()
condition|)
block|{
name|children
operator|=
name|DocumentNodeState
operator|.
name|NO_CHILDREN
expr_stmt|;
block|}
else|else
block|{
name|PathRev
name|key
init|=
name|childNodeCacheKey
argument_list|(
name|path
argument_list|,
name|beforeState
operator|.
name|getLastRevision
argument_list|()
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|children
operator|=
name|nodeChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|PathRev
name|afterKey
init|=
operator|new
name|PathRev
argument_list|(
name|path
argument_list|,
name|before
operator|.
name|update
argument_list|(
name|rev
argument_list|)
argument_list|)
decl_stmt|;
comment|// are there any added or removed children?
if|if
condition|(
name|added
operator|.
name|isEmpty
argument_list|()
operator|&&
name|removed
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// simply use the same list
name|LOG
operator|.
name|debug
argument_list|(
literal|"nodeChildrenCache.put({},{})"
argument_list|,
name|afterKey
argument_list|,
name|children
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|afterKey
argument_list|,
name|children
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|children
operator|.
name|hasMore
condition|)
block|{
comment|// list is complete. use before children as basis
name|Set
argument_list|<
name|String
argument_list|>
name|afterChildren
init|=
name|Sets
operator|.
name|newTreeSet
argument_list|(
name|children
operator|.
name|children
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|added
control|)
block|{
name|afterChildren
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|unshareString
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|p
range|:
name|removed
control|)
block|{
name|afterChildren
operator|.
name|remove
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|DocumentNodeState
operator|.
name|Children
name|c
init|=
operator|new
name|DocumentNodeState
operator|.
name|Children
argument_list|()
decl_stmt|;
name|c
operator|.
name|children
operator|.
name|addAll
argument_list|(
name|afterChildren
argument_list|)
expr_stmt|;
if|if
condition|(
name|c
operator|.
name|children
operator|.
name|size
argument_list|()
operator|<=
name|DocumentNodeState
operator|.
name|MAX_FETCH_SIZE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"nodeChildrenCache.put({},{})"
argument_list|,
name|afterKey
argument_list|,
name|c
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|afterKey
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"not caching more than {} child names for {}"
argument_list|,
name|DocumentNodeState
operator|.
name|MAX_FETCH_SIZE
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|added
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// incomplete list, but we only removed nodes
comment|// use linked hash set to retain order
name|Set
argument_list|<
name|String
argument_list|>
name|afterChildren
init|=
name|Sets
operator|.
name|newLinkedHashSet
argument_list|(
name|children
operator|.
name|children
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|removed
control|)
block|{
name|afterChildren
operator|.
name|remove
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|DocumentNodeState
operator|.
name|Children
name|c
init|=
operator|new
name|DocumentNodeState
operator|.
name|Children
argument_list|()
decl_stmt|;
name|c
operator|.
name|children
operator|.
name|addAll
argument_list|(
name|afterChildren
argument_list|)
expr_stmt|;
name|c
operator|.
name|hasMore
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"nodeChildrenCache.put({},{})"
argument_list|,
name|afterKey
argument_list|,
name|c
argument_list|)
expr_stmt|;
name|nodeChildrenCache
operator|.
name|put
argument_list|(
name|afterKey
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// update diff cache
name|JsopWriter
name|w
init|=
operator|new
name|JsopStream
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|p
range|:
name|added
control|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'+'
argument_list|)
operator|.
name|key
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
for|for
control|(
name|String
name|p
range|:
name|removed
control|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'-'
argument_list|)
operator|.
name|value
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|p
range|:
name|changed
control|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
name|cacheEntry
operator|.
name|append
argument_list|(
name|path
argument_list|,
name|w
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// update docChildrenCache
if|if
condition|(
operator|!
name|added
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|StringValue
name|docChildrenKey
init|=
operator|new
name|StringValue
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|NodeDocument
operator|.
name|Children
name|docChildren
init|=
name|docChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|docChildrenKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|docChildren
operator|!=
literal|null
condition|)
block|{
name|int
name|currentSize
init|=
name|docChildren
operator|.
name|childNames
operator|.
name|size
argument_list|()
decl_stmt|;
name|NavigableSet
argument_list|<
name|String
argument_list|>
name|names
init|=
name|Sets
operator|.
name|newTreeSet
argument_list|(
name|docChildren
operator|.
name|childNames
argument_list|)
decl_stmt|;
comment|// incomplete cache entries must not be updated with
comment|// names at the end of the list because there might be
comment|// a next name in DocumentStore smaller than the one added
if|if
condition|(
operator|!
name|docChildren
operator|.
name|isComplete
condition|)
block|{
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
name|String
name|name
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|names
operator|.
name|higher
argument_list|(
name|name
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|names
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|unshareString
argument_list|(
name|name
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// add all
for|for
control|(
name|String
name|childPath
range|:
name|added
control|)
block|{
name|names
operator|.
name|add
argument_list|(
name|Utils
operator|.
name|unshareString
argument_list|(
name|PathUtils
operator|.
name|getName
argument_list|(
name|childPath
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// any changes?
if|if
condition|(
name|names
operator|.
name|size
argument_list|()
operator|!=
name|currentSize
condition|)
block|{
comment|// create new cache entry with updated names
name|boolean
name|complete
init|=
name|docChildren
operator|.
name|isComplete
decl_stmt|;
name|docChildren
operator|=
operator|new
name|NodeDocument
operator|.
name|Children
argument_list|()
expr_stmt|;
name|docChildren
operator|.
name|isComplete
operator|=
name|complete
expr_stmt|;
name|docChildren
operator|.
name|childNames
operator|.
name|addAll
argument_list|(
name|names
argument_list|)
expr_stmt|;
name|docChildrenCache
operator|.
name|put
argument_list|(
name|docChildrenKey
argument_list|,
name|docChildren
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**      * Called when a branch is merged.      *      * @param revisions the revisions of the merged branch commits.      */
name|void
name|revisionsMerged
parameter_list|(
annotation|@
name|Nonnull
name|Iterable
argument_list|<
name|Revision
argument_list|>
name|revisions
parameter_list|)
block|{
name|changes
operator|.
name|branchCommit
argument_list|(
name|revisions
argument_list|)
expr_stmt|;
block|}
comment|/**      * Updates a commit root document.      *      * @param commit the updates to apply on the commit root document.      * @param commitRev the commit revision.      * @return the document before the update was applied or<code>null</code>      *          if the update failed because of a collision.      * @throws DocumentStoreException if the update fails with an error.      */
annotation|@
name|CheckForNull
name|NodeDocument
name|updateCommitRoot
parameter_list|(
name|UpdateOp
name|commit
parameter_list|,
name|Revision
name|commitRev
parameter_list|)
throws|throws
name|DocumentStoreException
block|{
comment|// use batch commit when there are only revision and modified updates
name|boolean
name|batch
init|=
literal|true
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Key
argument_list|,
name|Operation
argument_list|>
name|op
range|:
name|commit
operator|.
name|getChanges
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|name
init|=
name|op
operator|.
name|getKey
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|NodeDocument
operator|.
name|isRevisionsEntry
argument_list|(
name|name
argument_list|)
operator|||
name|NodeDocument
operator|.
name|MODIFIED_IN_SECS
operator|.
name|equals
argument_list|(
name|name
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|batch
operator|=
literal|false
expr_stmt|;
break|break;
block|}
try|try
block|{
if|if
condition|(
name|batch
condition|)
block|{
return|return
name|batchUpdateCommitRoot
argument_list|(
name|commit
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|store
operator|.
name|findAndUpdate
argument_list|(
name|NODES
argument_list|,
name|commit
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|DocumentStoreException
name|e
parameter_list|)
block|{
return|return
name|verifyCommitRootUpdateApplied
argument_list|(
name|commit
argument_list|,
name|commitRev
argument_list|,
name|e
argument_list|)
return|;
block|}
block|}
comment|/**      * Verifies if the {@code commit} update on the commit root was applied by      * reading the affected document and checks if the {@code commitRev} is      * set in the revisions map.      *      * @param commit the update operation on the commit root document.      * @param commitRev the commit revision.      * @param e the exception that will be thrown when this method determines      *          that the update was not applied.      * @return the before document.      * @throws DocumentStoreException the exception passed to this document      *      in case the commit update was not applied.      */
specifier|private
name|NodeDocument
name|verifyCommitRootUpdateApplied
parameter_list|(
name|UpdateOp
name|commit
parameter_list|,
name|Revision
name|commitRev
parameter_list|,
name|DocumentStoreException
name|e
parameter_list|)
throws|throws
name|DocumentStoreException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Update of commit root failed with exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|int
name|numRetries
init|=
literal|10
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numRetries
condition|;
name|i
operator|++
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Checking if change made it to the DocumentStore anyway {}/{} ..."
argument_list|,
name|i
operator|+
literal|1
argument_list|,
name|numRetries
argument_list|)
expr_stmt|;
name|NodeDocument
name|commitRootDoc
decl_stmt|;
try|try
block|{
name|commitRootDoc
operator|=
name|store
operator|.
name|find
argument_list|(
name|NODES
argument_list|,
name|commit
operator|.
name|getId
argument_list|()
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to read commit root document"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|commitRootDoc
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Commit root document missing for {}"
argument_list|,
name|commit
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|commitRootDoc
operator|.
name|getLocalRevisions
argument_list|()
operator|.
name|containsKey
argument_list|(
name|commitRev
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Update made it to the store even though the call "
operator|+
literal|"failed with an exception. Previous exception will "
operator|+
literal|"be suppressed. {}"
argument_list|,
name|commit
argument_list|)
expr_stmt|;
name|NodeDocument
name|before
init|=
name|NODES
operator|.
name|newDocument
argument_list|(
name|store
argument_list|)
decl_stmt|;
name|commitRootDoc
operator|.
name|deepCopy
argument_list|(
name|before
argument_list|)
expr_stmt|;
name|UpdateUtils
operator|.
name|applyChanges
argument_list|(
name|before
argument_list|,
name|commit
operator|.
name|getReverseOperation
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|before
return|;
block|}
break|break;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Update didn't make it to the store. Re-throwing the exception"
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
specifier|private
name|NodeDocument
name|batchUpdateCommitRoot
parameter_list|(
name|UpdateOp
name|commit
parameter_list|)
throws|throws
name|DocumentStoreException
block|{
try|try
block|{
return|return
name|batchCommitQueue
operator|.
name|updateDocument
argument_list|(
name|commit
argument_list|)
operator|.
name|call
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
argument_list|,
literal|"Interrupted while updating commit root document"
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
name|DocumentStoreException
operator|.
name|convert
argument_list|(
name|e
argument_list|,
literal|"Update of commit root document failed"
argument_list|)
throw|;
block|}
block|}
comment|/**      * Returns the root node state at the given revision.      *      * @param revision a revision.      * @return the root node state at the given revision.      */
annotation|@
name|Nonnull
name|DocumentNodeState
name|getRoot
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|revision
parameter_list|)
block|{
name|DocumentNodeState
name|root
init|=
name|getNode
argument_list|(
literal|"/"
argument_list|,
name|revision
argument_list|)
decl_stmt|;
if|if
condition|(
name|root
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"root node does not exist at revision "
operator|+
name|revision
argument_list|)
throw|;
block|}
return|return
name|root
return|;
block|}
annotation|@
name|Nonnull
name|DocumentNodeStoreBranch
name|createBranch
parameter_list|(
name|DocumentNodeState
name|base
parameter_list|)
block|{
name|DocumentNodeStoreBranch
name|b
init|=
name|DocumentNodeStoreBranch
operator|.
name|getCurrentBranch
argument_list|()
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
return|return
name|b
return|;
block|}
return|return
operator|new
name|DocumentNodeStoreBranch
argument_list|(
name|this
argument_list|,
name|base
argument_list|,
name|mergeLock
argument_list|)
return|;
block|}
annotation|@
name|Nonnull
name|RevisionVector
name|rebase
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|branchHead
parameter_list|,
annotation|@
name|Nonnull
name|RevisionVector
name|base
parameter_list|)
block|{
name|checkNotNull
argument_list|(
name|branchHead
argument_list|)
expr_stmt|;
name|checkNotNull
argument_list|(
name|base
argument_list|)
expr_stmt|;
if|if
condition|(
name|disableBranches
condition|)
block|{
return|return
name|branchHead
return|;
block|}
comment|// TODO conflict handling
name|Branch
name|b
init|=
name|getBranches
argument_list|()
operator|.
name|getBranch
argument_list|(
name|branchHead
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|==
literal|null
condition|)
block|{
comment|// empty branch
return|return
name|base
operator|.
name|asBranchRevision
argument_list|(
name|getClusterId
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|b
operator|.
name|getBase
argument_list|(
name|branchHead
operator|.
name|getBranchRevision
argument_list|()
argument_list|)
operator|.
name|equals
argument_list|(
name|base
argument_list|)
condition|)
block|{
return|return
name|branchHead
return|;
block|}
comment|// add a pseudo commit to make sure current head of branch
comment|// has a higher revision than base of branch
name|Revision
name|head
init|=
name|newRevision
argument_list|()
operator|.
name|asBranchRevision
argument_list|()
decl_stmt|;
name|b
operator|.
name|rebase
argument_list|(
name|head
argument_list|,
name|base
argument_list|)
expr_stmt|;
return|return
name|base
operator|.
name|update
argument_list|(
name|head
argument_list|)
return|;
block|}
annotation|@
name|Nonnull
name|RevisionVector
name|reset
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|branchHead
parameter_list|,
annotation|@
name|Nonnull
name|RevisionVector
name|ancestor
parameter_list|)
block|{
name|checkNotNull
argument_list|(
name|branchHead
argument_list|)
expr_stmt|;
name|checkNotNull
argument_list|(
name|ancestor
argument_list|)
expr_stmt|;
name|Branch
name|b
init|=
name|getBranches
argument_list|()
operator|.
name|getBranch
argument_list|(
name|branchHead
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|DocumentStoreException
argument_list|(
literal|"Empty branch cannot be reset"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|b
operator|.
name|getCommits
argument_list|()
operator|.
name|last
argument_list|()
operator|.
name|equals
argument_list|(
name|branchHead
operator|.
name|getRevision
argument_list|(
name|getClusterId
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|DocumentStoreException
argument_list|(
name|branchHead
operator|+
literal|" is not the head "
operator|+
literal|"of a branch"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|b
operator|.
name|containsCommit
argument_list|(
name|ancestor
operator|.
name|getBranchRevision
argument_list|()
argument_list|)
operator|&&
operator|!
name|b
operator|.
name|getBase
argument_list|()
operator|.
name|asBranchRevision
argument_list|(
name|getClusterId
argument_list|()
argument_list|)
operator|.
name|equals
argument_list|(
name|ancestor
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|DocumentStoreException
argument_list|(
name|ancestor
operator|+
literal|" is not "
operator|+
literal|"an ancestor revision of "
operator|+
name|branchHead
argument_list|)
throw|;
block|}
comment|// tailSet is inclusive -> use an ancestorRev with a
comment|// counter incremented by one to make the call exclusive
name|Revision
name|ancestorRev
init|=
name|ancestor
operator|.
name|getBranchRevision
argument_list|()
decl_stmt|;
name|ancestorRev
operator|=
operator|new
name|Revision
argument_list|(
name|ancestorRev
operator|.
name|getTimestamp
argument_list|()
argument_list|,
name|ancestorRev
operator|.
name|getCounter
argument_list|()
operator|+
literal|1
argument_list|,
name|ancestorRev
operator|.
name|getClusterId
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Revision
argument_list|>
name|revs
init|=
name|newArrayList
argument_list|(
name|b
operator|.
name|getCommits
argument_list|()
operator|.
name|tailSet
argument_list|(
name|ancestorRev
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|revs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// trivial
return|return
name|branchHead
return|;
block|}
name|UpdateOp
name|rootOp
init|=
operator|new
name|UpdateOp
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// reset each branch commit in reverse order
name|Map
argument_list|<
name|String
argument_list|,
name|UpdateOp
argument_list|>
name|operations
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
for|for
control|(
name|Revision
name|r
range|:
name|reverse
argument_list|(
name|revs
argument_list|)
control|)
block|{
name|NodeDocument
operator|.
name|removeCollision
argument_list|(
name|rootOp
argument_list|,
name|r
operator|.
name|asTrunkRevision
argument_list|()
argument_list|)
expr_stmt|;
name|NodeDocument
operator|.
name|removeRevision
argument_list|(
name|rootOp
argument_list|,
name|r
operator|.
name|asTrunkRevision
argument_list|()
argument_list|)
expr_stmt|;
name|operations
operator|.
name|clear
argument_list|()
expr_stmt|;
name|BranchCommit
name|bc
init|=
name|b
operator|.
name|getCommit
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|bc
operator|.
name|isRebase
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|getRoot
argument_list|(
name|bc
operator|.
name|getBase
argument_list|()
operator|.
name|update
argument_list|(
name|r
argument_list|)
argument_list|)
operator|.
name|compareAgainstBaseState
argument_list|(
name|getRoot
argument_list|(
name|bc
operator|.
name|getBase
argument_list|()
argument_list|)
argument_list|,
operator|new
name|ResetDiff
argument_list|(
name|r
operator|.
name|asTrunkRevision
argument_list|()
argument_list|,
name|operations
argument_list|)
argument_list|)
expr_stmt|;
comment|// apply reset operations
for|for
control|(
name|UpdateOp
name|op
range|:
name|operations
operator|.
name|values
argument_list|()
control|)
block|{
name|store
operator|.
name|findAndUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
block|}
name|store
operator|.
name|findAndUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|rootOp
argument_list|)
expr_stmt|;
comment|// clean up in-memory branch data
for|for
control|(
name|Revision
name|r
range|:
name|revs
control|)
block|{
name|b
operator|.
name|removeCommit
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
return|return
name|ancestor
return|;
block|}
annotation|@
name|Nonnull
name|RevisionVector
name|merge
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|branchHead
parameter_list|,
annotation|@
name|Nullable
name|CommitInfo
name|info
parameter_list|)
throws|throws
name|CommitFailedException
block|{
name|Branch
name|b
init|=
name|getBranches
argument_list|()
operator|.
name|getBranch
argument_list|(
name|branchHead
argument_list|)
decl_stmt|;
name|RevisionVector
name|base
init|=
name|branchHead
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|base
operator|=
name|b
operator|.
name|getBase
argument_list|(
name|branchHead
operator|.
name|getBranchRevision
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|int
name|numBranchCommits
init|=
name|b
operator|!=
literal|null
condition|?
name|b
operator|.
name|getCommits
argument_list|()
operator|.
name|size
argument_list|()
else|:
literal|1
decl_stmt|;
name|RevisionVector
name|newHead
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|MergeCommit
name|commit
init|=
name|newMergeCommit
argument_list|(
name|base
argument_list|,
name|numBranchCommits
argument_list|)
decl_stmt|;
try|try
block|{
comment|// make branch commits visible
name|UpdateOp
name|op
init|=
operator|new
name|UpdateOp
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|NodeDocument
operator|.
name|setModified
argument_list|(
name|op
argument_list|,
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|commit
operator|.
name|addBranchCommits
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|Iterator
argument_list|<
name|Revision
argument_list|>
name|mergeCommits
init|=
name|commit
operator|.
name|getMergeRevisions
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
for|for
control|(
name|Revision
name|rev
range|:
name|b
operator|.
name|getCommits
argument_list|()
control|)
block|{
name|rev
operator|=
name|rev
operator|.
name|asTrunkRevision
argument_list|()
expr_stmt|;
name|String
name|commitTag
init|=
literal|"c-"
operator|+
name|mergeCommits
operator|.
name|next
argument_list|()
decl_stmt|;
name|NodeDocument
operator|.
name|setRevision
argument_list|(
name|op
argument_list|,
name|rev
argument_list|,
name|commitTag
argument_list|)
expr_stmt|;
name|op
operator|.
name|containsMapEntry
argument_list|(
name|NodeDocument
operator|.
name|COLLISIONS
argument_list|,
name|rev
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|store
operator|.
name|findAndUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
operator|!=
literal|null
condition|)
block|{
comment|// remove from branchCommits map after successful update
name|b
operator|.
name|applyTo
argument_list|(
name|getPendingModifications
argument_list|()
argument_list|,
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
expr_stmt|;
name|getBranches
argument_list|()
operator|.
name|remove
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|NodeDocument
name|root
init|=
name|Utils
operator|.
name|getRootDocument
argument_list|(
name|store
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|Revision
argument_list|>
name|conflictRevs
init|=
name|root
operator|.
name|getConflictsFor
argument_list|(
name|b
operator|.
name|getCommits
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|msg
init|=
literal|"Conflicting concurrent change. Update operation failed: "
operator|+
name|op
decl_stmt|;
throw|throw
operator|new
name|ConflictException
argument_list|(
name|msg
argument_list|,
name|conflictRevs
argument_list|)
operator|.
name|asCommitFailedException
argument_list|()
throw|;
block|}
block|}
else|else
block|{
comment|// no commits in this branch -> do nothing
block|}
name|newHead
operator|=
name|done
argument_list|(
name|commit
argument_list|,
literal|false
argument_list|,
name|info
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|canceled
argument_list|(
name|commit
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|newHead
return|;
block|}
comment|/**      * Compares the given {@code node} against the {@code base} state and      * reports the differences to the {@link NodeStateDiff}.      *      * @param node the node to compare.      * @param base the base node to compare against.      * @param diff handler of node state differences      * @return {@code true} if the full diff was performed, or      *         {@code false} if it was aborted as requested by the handler      *         (see the {@link NodeStateDiff} contract for more details)      */
annotation|@
name|Override
specifier|public
name|boolean
name|compare
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|AbstractDocumentNodeState
name|node
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|AbstractDocumentNodeState
name|base
parameter_list|,
annotation|@
name|Nonnull
name|NodeStateDiff
name|diff
parameter_list|)
block|{
if|if
condition|(
operator|!
name|AbstractNodeState
operator|.
name|comparePropertiesAgainstBaseState
argument_list|(
name|node
argument_list|,
name|base
argument_list|,
name|diff
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|node
operator|.
name|hasNoChildren
argument_list|()
operator|&&
name|base
operator|.
name|hasNoChildren
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
name|dispatch
argument_list|(
name|diffCache
operator|.
name|getChanges
argument_list|(
name|base
operator|.
name|getRootRevision
argument_list|()
argument_list|,
name|node
operator|.
name|getRootRevision
argument_list|()
argument_list|,
name|node
operator|.
name|getPath
argument_list|()
argument_list|,
operator|new
name|DiffCache
operator|.
name|Loader
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|call
parameter_list|()
block|{
return|return
name|diffImpl
argument_list|(
name|base
argument_list|,
name|node
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|,
name|node
argument_list|,
name|base
argument_list|,
name|diff
argument_list|)
return|;
block|}
comment|/**      * Creates a tracker for the given commit revision.      *      * @param r a commit revision.      * @param isBranchCommit whether this is a branch commit.      * @return a _lastRev tracker for the given commit revision.      */
name|LastRevTracker
name|createTracker
parameter_list|(
specifier|final
annotation|@
name|Nonnull
name|Revision
name|r
parameter_list|,
specifier|final
name|boolean
name|isBranchCommit
parameter_list|)
block|{
if|if
condition|(
name|isBranchCommit
operator|&&
operator|!
name|disableBranches
condition|)
block|{
name|Revision
name|branchRev
init|=
name|r
operator|.
name|asBranchRevision
argument_list|()
decl_stmt|;
return|return
name|branches
operator|.
name|getBranchCommit
argument_list|(
name|branchRev
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|LastRevTracker
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|track
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|unsavedLastRevisions
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|r
argument_list|)
expr_stmt|;
block|}
block|}
return|;
block|}
block|}
comment|/**      * Suspends until all given revisions are either visible from the current      * headRevision or canceled from the commit queue.      *      * Only revisions from the local cluster node will be considered if the async      * delay is set to 0.      *      * @param conflictRevisions the revision to become visible.      */
name|void
name|suspendUntilAll
parameter_list|(
annotation|@
name|Nonnull
name|Set
argument_list|<
name|Revision
argument_list|>
name|conflictRevisions
parameter_list|)
block|{
comment|// do not suspend if revision is from another cluster node
comment|// and background read is disabled
if|if
condition|(
name|getAsyncDelay
argument_list|()
operator|==
literal|0
condition|)
block|{
name|Set
argument_list|<
name|Revision
argument_list|>
name|onlyLocal
init|=
operator|new
name|HashSet
argument_list|<
name|Revision
argument_list|>
argument_list|(
name|conflictRevisions
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Revision
name|r
range|:
name|conflictRevisions
control|)
block|{
if|if
condition|(
name|r
operator|.
name|getClusterId
argument_list|()
operator|==
name|getClusterId
argument_list|()
condition|)
block|{
name|onlyLocal
operator|.
name|add
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
block|}
name|commitQueue
operator|.
name|suspendUntilAll
argument_list|(
name|onlyLocal
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|commitQueue
operator|.
name|suspendUntilAll
argument_list|(
name|conflictRevisions
argument_list|)
expr_stmt|;
block|}
block|}
comment|//------------------------< Observable>------------------------------------
annotation|@
name|Override
specifier|public
name|Closeable
name|addObserver
parameter_list|(
name|Observer
name|observer
parameter_list|)
block|{
return|return
name|dispatcher
operator|.
name|addObserver
argument_list|(
name|observer
argument_list|)
return|;
block|}
comment|//-------------------------< NodeStore>------------------------------------
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|DocumentNodeState
name|getRoot
parameter_list|()
block|{
return|return
name|root
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|NodeState
name|merge
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|,
annotation|@
name|Nonnull
name|CommitHook
name|commitHook
parameter_list|,
annotation|@
name|Nonnull
name|CommitInfo
name|info
parameter_list|)
throws|throws
name|CommitFailedException
block|{
return|return
name|asDocumentRootBuilder
argument_list|(
name|builder
argument_list|)
operator|.
name|merge
argument_list|(
name|commitHook
argument_list|,
name|info
argument_list|)
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|NodeState
name|rebase
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|)
block|{
return|return
name|asDocumentRootBuilder
argument_list|(
name|builder
argument_list|)
operator|.
name|rebase
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|NodeState
name|reset
parameter_list|(
annotation|@
name|Nonnull
name|NodeBuilder
name|builder
parameter_list|)
block|{
return|return
name|asDocumentRootBuilder
argument_list|(
name|builder
argument_list|)
operator|.
name|reset
argument_list|()
return|;
block|}
annotation|@
name|Override
annotation|@
name|Nonnull
specifier|public
name|BlobStoreBlob
name|createBlob
parameter_list|(
name|InputStream
name|inputStream
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|BlobStoreBlob
argument_list|(
name|blobStore
argument_list|,
name|blobStore
operator|.
name|writeBlob
argument_list|(
name|inputStream
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Returns the {@link Blob} with the given reference. Note that this method is meant to      * be used with secure reference obtained from Blob#reference which is different from blobId      *      * @param reference the reference of the blob.      * @return the blob.      */
annotation|@
name|Override
specifier|public
name|Blob
name|getBlob
parameter_list|(
annotation|@
name|Nonnull
name|String
name|reference
parameter_list|)
block|{
name|String
name|blobId
init|=
name|blobStore
operator|.
name|getBlobId
argument_list|(
name|reference
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobId
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|BlobStoreBlob
argument_list|(
name|blobStore
argument_list|,
name|blobId
argument_list|)
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"No blobId found matching reference [{}]"
argument_list|,
name|reference
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|/**      * Returns the {@link Blob} with the given blobId.      *      * @param blobId the blobId of the blob.      * @return the blob.      */
specifier|public
name|Blob
name|getBlobFromBlobId
parameter_list|(
name|String
name|blobId
parameter_list|)
block|{
return|return
operator|new
name|BlobStoreBlob
argument_list|(
name|blobStore
argument_list|,
name|blobId
argument_list|)
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|String
name|checkpoint
parameter_list|(
name|long
name|lifetime
parameter_list|,
annotation|@
name|Nonnull
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|properties
parameter_list|)
block|{
return|return
name|checkpoints
operator|.
name|create
argument_list|(
name|lifetime
argument_list|,
name|properties
argument_list|)
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|String
name|checkpoint
parameter_list|(
name|long
name|lifetime
parameter_list|)
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|empty
init|=
name|Collections
operator|.
name|emptyMap
argument_list|()
decl_stmt|;
return|return
name|checkpoint
argument_list|(
name|lifetime
argument_list|,
name|empty
argument_list|)
return|;
block|}
annotation|@
name|Nonnull
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|checkpointInfo
parameter_list|(
annotation|@
name|Nonnull
name|String
name|checkpoint
parameter_list|)
block|{
name|Revision
name|r
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|checkpoint
argument_list|)
decl_stmt|;
name|Checkpoints
operator|.
name|Info
name|info
init|=
name|checkpoints
operator|.
name|getCheckpoints
argument_list|()
operator|.
name|get
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
comment|// checkpoint does not exist
return|return
name|Collections
operator|.
name|emptyMap
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|info
operator|.
name|get
argument_list|()
return|;
block|}
block|}
annotation|@
name|CheckForNull
annotation|@
name|Override
specifier|public
name|NodeState
name|retrieve
parameter_list|(
annotation|@
name|Nonnull
name|String
name|checkpoint
parameter_list|)
block|{
name|RevisionVector
name|rv
init|=
name|getCheckpoints
argument_list|()
operator|.
name|retrieve
argument_list|(
name|checkpoint
argument_list|)
decl_stmt|;
if|if
condition|(
name|rv
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// make sure all changes up to checkpoint are visible
name|suspendUntilAll
argument_list|(
name|Sets
operator|.
name|newHashSet
argument_list|(
name|rv
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|getRoot
argument_list|(
name|rv
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|release
parameter_list|(
annotation|@
name|Nonnull
name|String
name|checkpoint
parameter_list|)
block|{
name|checkpoints
operator|.
name|release
argument_list|(
name|checkpoint
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|//------------------------< RevisionContext>-------------------------------
annotation|@
name|Override
specifier|public
name|UnmergedBranches
name|getBranches
parameter_list|()
block|{
return|return
name|branches
return|;
block|}
annotation|@
name|Override
specifier|public
name|UnsavedModifications
name|getPendingModifications
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|RevisionVector
name|getHeadRevision
parameter_list|()
block|{
return|return
name|root
operator|.
name|getRevision
argument_list|()
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|Revision
name|newRevision
parameter_list|()
block|{
if|if
condition|(
name|simpleRevisionCounter
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|Revision
argument_list|(
name|simpleRevisionCounter
operator|.
name|getAndIncrement
argument_list|()
argument_list|,
literal|0
argument_list|,
name|clusterId
argument_list|)
return|;
block|}
return|return
name|Revision
operator|.
name|newRevision
argument_list|(
name|clusterId
argument_list|)
return|;
block|}
comment|//----------------------< background operations>---------------------------
comment|/** Used for testing only */
specifier|public
name|void
name|runBackgroundOperations
parameter_list|()
block|{
name|runBackgroundUpdateOperations
argument_list|()
expr_stmt|;
name|runBackgroundReadOperations
argument_list|()
expr_stmt|;
block|}
comment|/** Note: made package-protected for testing purpose, would otherwise be private **/
name|void
name|runBackgroundUpdateOperations
parameter_list|()
block|{
if|if
condition|(
name|readOnlyMode
operator|||
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
try|try
block|{
name|internalRunBackgroundUpdateOperations
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Background update operation failed (will be retried with next run): "
operator|+
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
throw|throw
name|e
throw|;
block|}
block|}
specifier|private
name|void
name|internalRunBackgroundUpdateOperations
parameter_list|()
block|{
name|BackgroundWriteStats
name|stats
init|=
literal|null
decl_stmt|;
synchronized|synchronized
init|(
name|backgroundWriteMonitor
init|)
block|{
name|long
name|start
init|=
name|clock
operator|.
name|getTime
argument_list|()
decl_stmt|;
name|long
name|time
init|=
name|start
decl_stmt|;
comment|// clean orphaned branches and collisions
name|cleanOrphanedBranches
argument_list|()
expr_stmt|;
name|cleanCollisions
argument_list|()
expr_stmt|;
name|long
name|cleanTime
init|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
decl_stmt|;
name|time
operator|=
name|clock
operator|.
name|getTime
argument_list|()
expr_stmt|;
comment|// split documents (does not create new revisions)
name|backgroundSplit
argument_list|()
expr_stmt|;
name|long
name|splitTime
init|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
decl_stmt|;
comment|// write back pending updates to _lastRev
name|stats
operator|=
name|backgroundWrite
argument_list|()
expr_stmt|;
name|stats
operator|.
name|split
operator|=
name|splitTime
expr_stmt|;
name|stats
operator|.
name|clean
operator|=
name|cleanTime
expr_stmt|;
name|stats
operator|.
name|totalWriteTime
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|start
expr_stmt|;
name|String
name|msg
init|=
literal|"Background operations stats ({})"
decl_stmt|;
if|if
condition|(
name|stats
operator|.
name|totalWriteTime
operator|>
name|TimeUnit
operator|.
name|SECONDS
operator|.
name|toMillis
argument_list|(
literal|10
argument_list|)
condition|)
block|{
comment|// log as info if it took more than 10 seconds
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|stats
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|,
name|stats
argument_list|)
expr_stmt|;
block|}
block|}
comment|//Push stats outside of sync block
name|nodeStoreStatsCollector
operator|.
name|doneBackgroundUpdate
argument_list|(
name|stats
argument_list|)
expr_stmt|;
block|}
comment|//----------------------< background read operations>----------------------
comment|/** Note: made package-protected for testing purpose, would otherwise be private **/
name|void
name|runBackgroundReadOperations
parameter_list|()
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
try|try
block|{
name|internalRunBackgroundReadOperations
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Background read operation failed: "
operator|+
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
throw|throw
name|e
throw|;
block|}
block|}
comment|/** OAK-2624 : background read operations are split from background update ops */
specifier|private
name|void
name|internalRunBackgroundReadOperations
parameter_list|()
block|{
name|BackgroundReadStats
name|readStats
init|=
literal|null
decl_stmt|;
synchronized|synchronized
init|(
name|backgroundReadMonitor
init|)
block|{
name|long
name|start
init|=
name|clock
operator|.
name|getTime
argument_list|()
decl_stmt|;
comment|// pull in changes from other cluster nodes
name|readStats
operator|=
name|backgroundRead
argument_list|()
expr_stmt|;
name|readStats
operator|.
name|totalReadTime
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|start
expr_stmt|;
name|String
name|msg
init|=
literal|"Background read operations stats (read:{} {})"
decl_stmt|;
if|if
condition|(
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|start
operator|>
name|TimeUnit
operator|.
name|SECONDS
operator|.
name|toMillis
argument_list|(
literal|10
argument_list|)
condition|)
block|{
comment|// log as info if it took more than 10 seconds
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|readStats
operator|.
name|totalReadTime
argument_list|,
name|readStats
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|,
name|readStats
operator|.
name|totalReadTime
argument_list|,
name|readStats
argument_list|)
expr_stmt|;
block|}
block|}
name|nodeStoreStatsCollector
operator|.
name|doneBackgroundRead
argument_list|(
name|readStats
argument_list|)
expr_stmt|;
block|}
comment|/**      * Renews the cluster lease if necessary.      *      * @return {@code true} if the lease was renewed; {@code false} otherwise.      */
name|boolean
name|renewClusterIdLease
parameter_list|()
block|{
return|return
name|clusterNodeInfo
operator|.
name|renewLease
argument_list|()
return|;
block|}
comment|/**      * Updates the state about cluster nodes in {@link #clusterNodes}.      *      * @return true if the cluster state has changed, false if the cluster state      * remained unchanged      */
name|boolean
name|updateClusterState
parameter_list|()
block|{
name|boolean
name|hasChanged
init|=
literal|false
decl_stmt|;
name|Set
argument_list|<
name|Integer
argument_list|>
name|clusterIds
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
for|for
control|(
name|ClusterNodeInfoDocument
name|doc
range|:
name|ClusterNodeInfoDocument
operator|.
name|all
argument_list|(
name|store
argument_list|)
control|)
block|{
name|int
name|cId
init|=
name|doc
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
name|clusterIds
operator|.
name|add
argument_list|(
name|cId
argument_list|)
expr_stmt|;
name|ClusterNodeInfoDocument
name|old
init|=
name|clusterNodes
operator|.
name|get
argument_list|(
name|cId
argument_list|)
decl_stmt|;
comment|// do not replace document for inactive cluster node
comment|// in order to keep the created timestamp of the document
comment|// for the time when the cluster node was first seen inactive
if|if
condition|(
name|old
operator|!=
literal|null
operator|&&
operator|!
name|old
operator|.
name|isActive
argument_list|()
operator|&&
operator|!
name|doc
operator|.
name|isActive
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|clusterNodes
operator|.
name|put
argument_list|(
name|cId
argument_list|,
name|doc
argument_list|)
expr_stmt|;
if|if
condition|(
name|old
operator|==
literal|null
operator|||
name|old
operator|.
name|isActive
argument_list|()
operator|!=
name|doc
operator|.
name|isActive
argument_list|()
condition|)
block|{
name|hasChanged
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|hasChanged
operator||=
name|clusterNodes
operator|.
name|keySet
argument_list|()
operator|.
name|retainAll
argument_list|(
name|clusterIds
argument_list|)
expr_stmt|;
return|return
name|hasChanged
return|;
block|}
comment|/**      * @return the minimum revisions of foreign cluster nodes since they were      *          started. The revision is derived from the start time of the      *          cluster node.      */
annotation|@
name|Nonnull
name|RevisionVector
name|getMinExternalRevisions
parameter_list|()
block|{
return|return
operator|new
name|RevisionVector
argument_list|(
name|transform
argument_list|(
name|filter
argument_list|(
name|clusterNodes
operator|.
name|values
argument_list|()
argument_list|,
operator|new
name|Predicate
argument_list|<
name|ClusterNodeInfoDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|getClusterId
argument_list|()
operator|!=
name|getClusterId
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
operator|new
name|Function
argument_list|<
name|ClusterNodeInfoDocument
argument_list|,
name|Revision
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Revision
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
operator|new
name|Revision
argument_list|(
name|input
operator|.
name|getStartTime
argument_list|()
argument_list|,
literal|0
argument_list|,
name|input
operator|.
name|getClusterId
argument_list|()
argument_list|)
return|;
block|}
block|}
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Perform a background read and make external changes visible.      */
name|BackgroundReadStats
name|backgroundRead
parameter_list|()
block|{
name|BackgroundReadStats
name|stats
init|=
operator|new
name|BackgroundReadStats
argument_list|()
decl_stmt|;
name|long
name|time
init|=
name|clock
operator|.
name|getTime
argument_list|()
decl_stmt|;
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|,
name|asyncDelay
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
return|return
name|stats
return|;
block|}
name|alignWithExternalRevisions
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|StringSort
name|externalSort
init|=
name|JournalEntry
operator|.
name|newSorter
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastRevMap
init|=
name|doc
operator|.
name|getLastRev
argument_list|()
decl_stmt|;
try|try
block|{
name|RevisionVector
name|headRevision
init|=
name|getHeadRevision
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|Revision
argument_list|>
name|externalChanges
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|e
range|:
name|lastRevMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|int
name|machineId
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|machineId
operator|==
name|clusterId
condition|)
block|{
comment|// ignore own lastRev
continue|continue;
block|}
name|Revision
name|r
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Revision
name|last
init|=
name|headRevision
operator|.
name|getRevision
argument_list|(
name|machineId
argument_list|)
decl_stmt|;
if|if
condition|(
name|last
operator|==
literal|null
condition|)
block|{
comment|// make sure we see all changes when a cluster node joins
name|last
operator|=
operator|new
name|Revision
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|machineId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|r
operator|.
name|compareRevisionTime
argument_list|(
name|last
argument_list|)
operator|>
literal|0
condition|)
block|{
comment|// OAK-2345
comment|// only consider as external change if
comment|// the revision changed for the machineId
name|externalChanges
operator|.
name|add
argument_list|(
name|r
argument_list|)
expr_stmt|;
comment|// collect external changes
if|if
condition|(
name|externalSort
operator|!=
literal|null
condition|)
block|{
comment|// add changes for this particular clusterId to the externalSort
try|try
block|{
name|fillExternalChanges
argument_list|(
name|externalSort
argument_list|,
name|last
argument_list|,
name|r
argument_list|,
name|store
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"backgroundRead: Exception while reading external changes from journal: "
operator|+
name|e1
argument_list|,
name|e1
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|externalSort
argument_list|)
expr_stmt|;
name|externalSort
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
block|}
name|stats
operator|.
name|readHead
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
expr_stmt|;
name|time
operator|=
name|clock
operator|.
name|getTime
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|externalChanges
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// invalidate caches
if|if
condition|(
name|externalSort
operator|==
literal|null
condition|)
block|{
comment|// if no externalSort available, then invalidate the classic way: everything
name|stats
operator|.
name|cacheStats
operator|=
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|externalSort
operator|.
name|sort
argument_list|()
expr_stmt|;
name|stats
operator|.
name|numExternalChanges
operator|=
name|externalSort
operator|.
name|getSize
argument_list|()
expr_stmt|;
name|stats
operator|.
name|cacheStats
operator|=
name|store
operator|.
name|invalidateCache
argument_list|(
name|pathToId
argument_list|(
name|externalSort
argument_list|)
argument_list|)
expr_stmt|;
comment|// OAK-3002: only invalidate affected items (using journal)
name|long
name|origSize
init|=
name|docChildrenCache
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|origSize
operator|==
literal|0
condition|)
block|{
comment|// if docChildrenCache is empty, don't bother
comment|// calling invalidateAll either way
comment|// (esp calling invalidateAll(Iterable) will
comment|// potentially iterate over all keys even though
comment|// there's nothing to be deleted)
name|LOG
operator|.
name|trace
argument_list|(
literal|"backgroundRead: docChildrenCache nothing to invalidate"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// however, if the docChildrenCache is not empty,
comment|// use the invalidateAll(Iterable) variant,
comment|// passing it a Iterable<StringValue>, as that's
comment|// what is contained in the cache
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|(
name|asStringValueIterable
argument_list|(
name|externalSort
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|newSize
init|=
name|docChildrenCache
operator|.
name|size
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"backgroundRead: docChildrenCache invalidation result: orig: {}, new: {} "
argument_list|,
name|origSize
argument_list|,
name|newSize
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"backgroundRead: got IOException during external sorting/cache invalidation (as a result, invalidating entire cache): "
operator|+
name|ioe
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|stats
operator|.
name|cacheStats
operator|=
name|store
operator|.
name|invalidateCache
argument_list|()
expr_stmt|;
name|docChildrenCache
operator|.
name|invalidateAll
argument_list|()
expr_stmt|;
block|}
block|}
name|stats
operator|.
name|cacheInvalidationTime
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
expr_stmt|;
name|time
operator|=
name|clock
operator|.
name|getTime
argument_list|()
expr_stmt|;
comment|// make sure no local commit is in progress
name|backgroundOperationLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|stats
operator|.
name|lock
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
expr_stmt|;
name|RevisionVector
name|oldHead
init|=
name|getHeadRevision
argument_list|()
decl_stmt|;
name|RevisionVector
name|newHead
init|=
name|oldHead
decl_stmt|;
for|for
control|(
name|Revision
name|r
range|:
name|externalChanges
control|)
block|{
name|newHead
operator|=
name|newHead
operator|.
name|update
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
name|setRoot
argument_list|(
name|newHead
argument_list|)
expr_stmt|;
name|commitQueue
operator|.
name|headRevisionChanged
argument_list|()
expr_stmt|;
name|time
operator|=
name|clock
operator|.
name|getTime
argument_list|()
expr_stmt|;
if|if
condition|(
name|externalSort
operator|!=
literal|null
condition|)
block|{
comment|// then there were external changes and reading them
comment|// was successful -> apply them to the diff cache
try|try
block|{
name|JournalEntry
operator|.
name|applyTo
argument_list|(
name|externalSort
argument_list|,
name|diffCache
argument_list|,
name|oldHead
argument_list|,
name|newHead
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"backgroundRead: Exception while processing external changes from journal: {}"
argument_list|,
name|e1
argument_list|,
name|e1
argument_list|)
expr_stmt|;
block|}
block|}
name|stats
operator|.
name|populateDiffCache
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
expr_stmt|;
name|time
operator|=
name|clock
operator|.
name|getTime
argument_list|()
expr_stmt|;
name|dispatcher
operator|.
name|contentChanged
argument_list|(
name|getRoot
argument_list|()
operator|.
name|fromExternalChange
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backgroundOperationLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|stats
operator|.
name|dispatchChanges
operator|=
name|clock
operator|.
name|getTime
argument_list|()
operator|-
name|time
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|externalSort
argument_list|)
expr_stmt|;
block|}
return|return
name|stats
return|;
block|}
specifier|private
name|void
name|cleanOrphanedBranches
parameter_list|()
block|{
name|Branch
name|b
decl_stmt|;
while|while
condition|(
operator|(
name|b
operator|=
name|branches
operator|.
name|pollOrphanedBranch
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaning up orphaned branch with base revision: {}, "
operator|+
literal|"commits: {}"
argument_list|,
name|b
operator|.
name|getBase
argument_list|()
argument_list|,
name|b
operator|.
name|getCommits
argument_list|()
argument_list|)
expr_stmt|;
name|UpdateOp
name|op
init|=
operator|new
name|UpdateOp
argument_list|(
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
argument_list|,
literal|false
argument_list|)
decl_stmt|;
for|for
control|(
name|Revision
name|r
range|:
name|b
operator|.
name|getCommits
argument_list|()
control|)
block|{
name|r
operator|=
name|r
operator|.
name|asTrunkRevision
argument_list|()
expr_stmt|;
name|NodeDocument
operator|.
name|removeRevision
argument_list|(
name|op
argument_list|,
name|r
argument_list|)
expr_stmt|;
block|}
name|store
operator|.
name|findAndUpdate
argument_list|(
name|NODES
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|cleanCollisions
parameter_list|()
block|{
name|String
name|id
init|=
name|Utils
operator|.
name|getIdFromPath
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|NodeDocument
name|root
init|=
name|store
operator|.
name|find
argument_list|(
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|root
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|RevisionVector
name|head
init|=
name|getHeadRevision
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|Revision
argument_list|,
name|String
argument_list|>
name|map
init|=
name|root
operator|.
name|getLocalMap
argument_list|(
name|NodeDocument
operator|.
name|COLLISIONS
argument_list|)
decl_stmt|;
name|UpdateOp
name|op
init|=
operator|new
name|UpdateOp
argument_list|(
name|id
argument_list|,
literal|false
argument_list|)
decl_stmt|;
for|for
control|(
name|Revision
name|r
range|:
name|map
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|r
operator|.
name|getClusterId
argument_list|()
operator|==
name|clusterId
condition|)
block|{
comment|// remove collision if there is no active branch with
comment|// this revision and the revision is before the current
comment|// head. That is, the collision cannot be related to commit
comment|// which is progress.
if|if
condition|(
name|branches
operator|.
name|getBranchCommit
argument_list|(
name|r
argument_list|)
operator|==
literal|null
operator|&&
operator|!
name|head
operator|.
name|isRevisionNewer
argument_list|(
name|r
argument_list|)
condition|)
block|{
name|NodeDocument
operator|.
name|removeCollision
argument_list|(
name|op
argument_list|,
name|r
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|op
operator|.
name|hasChanges
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Removing collisions {}"
argument_list|,
name|op
operator|.
name|getChanges
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|store
operator|.
name|findAndUpdate
argument_list|(
name|NODES
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|backgroundSplit
parameter_list|()
block|{
name|RevisionVector
name|head
init|=
name|getHeadRevision
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|String
argument_list|>
name|it
init|=
name|splitCandidates
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|String
name|id
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|NodeDocument
name|doc
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|UpdateOp
name|op
range|:
name|doc
operator|.
name|split
argument_list|(
name|this
argument_list|,
name|head
argument_list|,
name|isBinary
argument_list|)
control|)
block|{
name|NodeDocument
name|before
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|op
operator|.
name|isNew
argument_list|()
operator|||
operator|!
name|store
operator|.
name|create
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|Collections
operator|.
name|singletonList
argument_list|(
name|op
argument_list|)
argument_list|)
condition|)
block|{
name|before
operator|=
name|store
operator|.
name|createOrUpdate
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|before
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|NodeDocument
name|after
init|=
name|store
operator|.
name|find
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|op
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|after
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Split operation on {}. Size before: {}, after: {}"
argument_list|,
name|id
argument_list|,
name|before
operator|.
name|getMemory
argument_list|()
argument_list|,
name|after
operator|.
name|getMemory
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Split operation created {}"
argument_list|,
name|op
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Nonnull
name|Set
argument_list|<
name|String
argument_list|>
name|getSplitCandidates
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableSet
argument_list|(
name|splitCandidates
operator|.
name|keySet
argument_list|()
argument_list|)
return|;
block|}
name|BackgroundWriteStats
name|backgroundWrite
parameter_list|()
block|{
return|return
name|unsavedLastRevisions
operator|.
name|persist
argument_list|(
name|this
argument_list|,
operator|new
name|UnsavedModifications
operator|.
name|Snapshot
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|acquiring
parameter_list|(
name|Revision
name|mostRecent
parameter_list|)
block|{
if|if
condition|(
name|store
operator|.
name|create
argument_list|(
name|JOURNAL
argument_list|,
name|singletonList
argument_list|(
name|changes
operator|.
name|asUpdateOp
argument_list|(
name|mostRecent
argument_list|)
argument_list|)
argument_list|)
condition|)
block|{
comment|// success: start with a new document
name|changes
operator|=
name|JOURNAL
operator|.
name|newDocument
argument_list|(
name|getDocumentStore
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// fail: log and keep the changes
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to write to journal, accumulating changes for future write (~"
operator|+
name|changes
operator|.
name|getMemory
argument_list|()
operator|+
literal|" bytes)."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|,
name|backgroundOperationLock
operator|.
name|writeLock
argument_list|()
argument_list|)
return|;
block|}
comment|//-----------------------------< internal>---------------------------------
comment|/**      * Performs an initial read of the _lastRevs on the root document and sets      * the root state.      *      * @param rootDoc the current root document.      */
specifier|private
name|void
name|initializeRootState
parameter_list|(
name|NodeDocument
name|rootDoc
parameter_list|)
block|{
name|checkState
argument_list|(
name|root
operator|==
literal|null
argument_list|)
expr_stmt|;
name|alignWithExternalRevisions
argument_list|(
name|rootDoc
argument_list|)
expr_stmt|;
name|RevisionVector
name|headRevision
init|=
operator|new
name|RevisionVector
argument_list|(
name|rootDoc
operator|.
name|getLastRev
argument_list|()
operator|.
name|values
argument_list|()
argument_list|)
operator|.
name|update
argument_list|(
name|newRevision
argument_list|()
argument_list|)
decl_stmt|;
name|setRoot
argument_list|(
name|headRevision
argument_list|)
expr_stmt|;
block|}
comment|/**      * Makes sure the current time is after the most recent external revision      * timestamp in the _lastRev map of the given root document. If necessary      * the current thread waits until {@link #clock} is after the external      * revision timestamp.      *      * @param rootDoc the root document.      */
specifier|private
name|void
name|alignWithExternalRevisions
parameter_list|(
annotation|@
name|Nonnull
name|NodeDocument
name|rootDoc
parameter_list|)
block|{
name|Map
argument_list|<
name|Integer
argument_list|,
name|Revision
argument_list|>
name|lastRevMap
init|=
name|checkNotNull
argument_list|(
name|rootDoc
argument_list|)
operator|.
name|getLastRev
argument_list|()
decl_stmt|;
try|try
block|{
name|long
name|externalTime
init|=
name|Utils
operator|.
name|getMaxExternalTimestamp
argument_list|(
name|lastRevMap
operator|.
name|values
argument_list|()
argument_list|,
name|clusterId
argument_list|)
decl_stmt|;
name|long
name|localTime
init|=
name|clock
operator|.
name|getTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|localTime
operator|<
name|externalTime
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Detected clock differences. Local time is '{}', "
operator|+
literal|"while most recent external time is '{}'. "
operator|+
literal|"Current _lastRev entries: {}"
argument_list|,
operator|new
name|Date
argument_list|(
name|localTime
argument_list|)
argument_list|,
operator|new
name|Date
argument_list|(
name|externalTime
argument_list|)
argument_list|,
name|lastRevMap
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
name|double
name|delay
init|=
operator|(
operator|(
name|double
operator|)
name|externalTime
operator|-
name|localTime
operator|)
operator|/
literal|1000d
decl_stmt|;
name|String
name|msg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Background read will be delayed by %.1f seconds. "
operator|+
literal|"Please check system time on cluster nodes."
argument_list|,
name|delay
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|clock
operator|.
name|waitUntil
argument_list|(
name|externalTime
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|localTime
operator|==
name|externalTime
condition|)
block|{
comment|// make sure local time is past external time
comment|// but only log at debug
name|LOG
operator|.
name|debug
argument_list|(
literal|"Local and external time are equal. Waiting until local"
operator|+
literal|"time is more recent than external reported time."
argument_list|)
expr_stmt|;
name|clock
operator|.
name|waitUntil
argument_list|(
name|externalTime
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Background read interrupted"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Nonnull
specifier|private
name|Commit
name|newTrunkCommit
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|base
parameter_list|)
block|{
name|checkArgument
argument_list|(
operator|!
name|checkNotNull
argument_list|(
name|base
argument_list|)
operator|.
name|isBranch
argument_list|()
argument_list|,
literal|"base must not be a branch revision: "
operator|+
name|base
argument_list|)
expr_stmt|;
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|Commit
name|c
decl_stmt|;
try|try
block|{
name|checkOpen
argument_list|()
expr_stmt|;
name|c
operator|=
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
name|commitQueue
operator|.
name|createRevision
argument_list|()
argument_list|,
name|base
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|backgroundOperationLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|c
return|;
block|}
annotation|@
name|Nonnull
specifier|private
name|Commit
name|newBranchCommit
parameter_list|(
annotation|@
name|Nonnull
name|RevisionVector
name|base
parameter_list|,
annotation|@
name|Nullable
name|DocumentNodeStoreBranch
name|branch
parameter_list|)
block|{
name|checkArgument
argument_list|(
name|checkNotNull
argument_list|(
name|base
argument_list|)
operator|.
name|isBranch
argument_list|()
argument_list|,
literal|"base must be a branch revision: "
operator|+
name|base
argument_list|)
expr_stmt|;
name|checkOpen
argument_list|()
expr_stmt|;
return|return
operator|new
name|Commit
argument_list|(
name|this
argument_list|,
name|newRevision
argument_list|()
argument_list|,
name|base
argument_list|,
name|branch
argument_list|)
return|;
block|}
comment|/**      * Checks if this store is still open and throws an      * {@link IllegalStateException} if it is already disposed (or a dispose      * is in progress).      *      * @throws IllegalStateException if this store is disposed.      */
specifier|private
name|void
name|checkOpen
parameter_list|()
throws|throws
name|IllegalStateException
block|{
if|if
condition|(
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"This DocumentNodeStore is disposed"
argument_list|)
throw|;
block|}
block|}
specifier|private
name|boolean
name|dispatch
parameter_list|(
annotation|@
name|Nonnull
specifier|final
name|String
name|jsonDiff
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|AbstractDocumentNodeState
name|node
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|AbstractDocumentNodeState
name|base
parameter_list|,
annotation|@
name|Nonnull
specifier|final
name|NodeStateDiff
name|diff
parameter_list|)
block|{
return|return
name|DiffCache
operator|.
name|parseJsopDiff
argument_list|(
name|jsonDiff
argument_list|,
operator|new
name|DiffCache
operator|.
name|Diff
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|childNodeAdded
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|diff
operator|.
name|childNodeAdded
argument_list|(
name|name
argument_list|,
name|node
operator|.
name|getChildNode
argument_list|(
name|name
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|childNodeChanged
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|boolean
name|continueComparison
init|=
literal|true
decl_stmt|;
name|NodeState
name|baseChild
init|=
name|base
operator|.
name|getChildNode
argument_list|(
name|name
argument_list|)
decl_stmt|;
name|NodeState
name|nodeChild
init|=
name|node
operator|.
name|getChildNode
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|baseChild
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
name|nodeChild
operator|.
name|exists
argument_list|()
condition|)
block|{
name|continueComparison
operator|=
name|diff
operator|.
name|childNodeChanged
argument_list|(
name|name
argument_list|,
name|baseChild
argument_list|,
name|nodeChild
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|continueComparison
operator|=
name|diff
operator|.
name|childNodeDeleted
argument_list|(
name|name
argument_list|,
name|baseChild
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|nodeChild
operator|.
name|exists
argument_list|()
condition|)
block|{
name|continueComparison
operator|=
name|diff
operator|.
name|childNodeAdded
argument_list|(
name|name
argument_list|,
name|nodeChild
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|continueComparison
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|childNodeDeleted
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|diff
operator|.
name|childNodeDeleted
argument_list|(
name|name
argument_list|,
name|base
operator|.
name|getChildNode
argument_list|(
name|name
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/**      * Search for presence of child node as denoted by path in the children cache of parent      *      * @param path      * @param rev revision at which check is performed      * @return<code>true</code> if and only if the children cache entry for parent path is complete      * and that list does not have the given child node. A<code>false</code> indicates that node<i>might</i>      * exist      */
specifier|private
name|boolean
name|checkNodeNotExistsFromChildrenCache
parameter_list|(
name|String
name|path
parameter_list|,
name|RevisionVector
name|rev
parameter_list|)
block|{
if|if
condition|(
name|PathUtils
operator|.
name|denotesRoot
argument_list|(
name|path
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
specifier|final
name|String
name|parentPath
init|=
name|PathUtils
operator|.
name|getParentPath
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|PathRev
name|key
init|=
name|childNodeCacheKey
argument_list|(
name|parentPath
argument_list|,
name|rev
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|//read first child cache entry
name|DocumentNodeState
operator|.
name|Children
name|children
init|=
name|nodeChildrenCache
operator|.
name|getIfPresent
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|String
name|lookupChildName
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|path
argument_list|)
decl_stmt|;
comment|//Does not know about children so cannot say for sure
if|if
condition|(
name|children
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|//List not complete so cannot say for sure
if|if
condition|(
name|children
operator|.
name|hasMore
condition|)
block|{
return|return
literal|false
return|;
block|}
name|int
name|childPosition
init|=
name|Collections
operator|.
name|binarySearch
argument_list|(
name|children
operator|.
name|children
argument_list|,
name|lookupChildName
argument_list|)
decl_stmt|;
if|if
condition|(
name|childPosition
operator|<
literal|0
condition|)
block|{
comment|//Node does not exist for sure
name|LOG
operator|.
name|trace
argument_list|(
literal|"Child node as per path {} does not exist at revision {}"
argument_list|,
name|path
argument_list|,
name|rev
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|String
name|diffImpl
parameter_list|(
name|AbstractDocumentNodeState
name|from
parameter_list|,
name|AbstractDocumentNodeState
name|to
parameter_list|)
throws|throws
name|DocumentStoreException
block|{
name|JsopWriter
name|w
init|=
operator|new
name|JsopStream
argument_list|()
decl_stmt|;
comment|// TODO this does not work well for large child node lists
comment|// use a document store index instead
name|int
name|max
init|=
name|MANY_CHILDREN_THRESHOLD
decl_stmt|;
specifier|final
name|boolean
name|debug
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
decl_stmt|;
specifier|final
name|long
name|start
init|=
name|debug
condition|?
name|now
argument_list|()
else|:
literal|0
decl_stmt|;
name|DocumentNodeState
operator|.
name|Children
name|fromChildren
decl_stmt|,
name|toChildren
decl_stmt|;
name|fromChildren
operator|=
name|getChildren
argument_list|(
name|from
argument_list|,
literal|null
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|toChildren
operator|=
name|getChildren
argument_list|(
name|to
argument_list|,
literal|null
argument_list|,
name|max
argument_list|)
expr_stmt|;
specifier|final
name|long
name|getChildrenDoneIn
init|=
name|debug
condition|?
name|now
argument_list|()
else|:
literal|0
decl_stmt|;
name|String
name|diffAlgo
decl_stmt|;
name|RevisionVector
name|fromRev
init|=
name|from
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
name|RevisionVector
name|toRev
init|=
name|to
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fromChildren
operator|.
name|hasMore
operator|&&
operator|!
name|toChildren
operator|.
name|hasMore
condition|)
block|{
name|diffAlgo
operator|=
literal|"diffFewChildren"
expr_stmt|;
name|diffFewChildren
argument_list|(
name|w
argument_list|,
name|from
operator|.
name|getPath
argument_list|()
argument_list|,
name|fromChildren
argument_list|,
name|fromRev
argument_list|,
name|toChildren
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|FAST_DIFF
condition|)
block|{
name|diffAlgo
operator|=
literal|"diffManyChildren"
expr_stmt|;
name|fromRev
operator|=
name|from
operator|.
name|getRootRevision
argument_list|()
expr_stmt|;
name|toRev
operator|=
name|to
operator|.
name|getRootRevision
argument_list|()
expr_stmt|;
name|diffManyChildren
argument_list|(
name|w
argument_list|,
name|from
operator|.
name|getPath
argument_list|()
argument_list|,
name|fromRev
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|diffAlgo
operator|=
literal|"diffAllChildren"
expr_stmt|;
name|max
operator|=
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
name|fromChildren
operator|=
name|getChildren
argument_list|(
name|from
argument_list|,
literal|null
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|toChildren
operator|=
name|getChildren
argument_list|(
name|to
argument_list|,
literal|null
argument_list|,
name|max
argument_list|)
expr_stmt|;
name|diffFewChildren
argument_list|(
name|w
argument_list|,
name|from
operator|.
name|getPath
argument_list|()
argument_list|,
name|fromChildren
argument_list|,
name|fromRev
argument_list|,
name|toChildren
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
block|}
block|}
name|String
name|diff
init|=
name|w
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|debug
condition|)
block|{
name|long
name|end
init|=
name|now
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Diff performed via '{}' at [{}] between revisions [{}] => [{}] took {} ms ({} ms), diff '{}', external '{}"
argument_list|,
name|diffAlgo
argument_list|,
name|from
operator|.
name|getPath
argument_list|()
argument_list|,
name|fromRev
argument_list|,
name|toRev
argument_list|,
name|end
operator|-
name|start
argument_list|,
name|getChildrenDoneIn
operator|-
name|start
argument_list|,
name|diff
argument_list|,
name|to
operator|.
name|isFromExternalChange
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|diff
return|;
block|}
specifier|private
name|void
name|diffManyChildren
parameter_list|(
name|JsopWriter
name|w
parameter_list|,
name|String
name|path
parameter_list|,
name|RevisionVector
name|fromRev
parameter_list|,
name|RevisionVector
name|toRev
parameter_list|)
block|{
name|long
name|minTimestamp
init|=
name|Utils
operator|.
name|getMinTimestampForDiff
argument_list|(
name|fromRev
argument_list|,
name|toRev
argument_list|,
name|getMinExternalRevisions
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|minValue
init|=
name|NodeDocument
operator|.
name|getModifiedInSecs
argument_list|(
name|minTimestamp
argument_list|)
decl_stmt|;
name|String
name|fromKey
init|=
name|Utils
operator|.
name|getKeyLowerLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|toKey
init|=
name|Utils
operator|.
name|getKeyUpperLimit
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|paths
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"diffManyChildren: path: {}, fromRev: {}, toRev: {}"
argument_list|,
name|path
argument_list|,
name|fromRev
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
for|for
control|(
name|NodeDocument
name|doc
range|:
name|store
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|NODES
argument_list|,
name|fromKey
argument_list|,
name|toKey
argument_list|,
name|NodeDocument
operator|.
name|MODIFIED_IN_SECS
argument_list|,
name|minValue
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
control|)
block|{
name|paths
operator|.
name|add
argument_list|(
name|doc
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"diffManyChildren: Affected paths: {}"
argument_list|,
name|paths
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// also consider nodes with not yet stored modifications (OAK-1107)
name|Revision
name|minRev
init|=
operator|new
name|Revision
argument_list|(
name|minTimestamp
argument_list|,
literal|0
argument_list|,
name|getClusterId
argument_list|()
argument_list|)
decl_stmt|;
name|addPathsForDiff
argument_list|(
name|path
argument_list|,
name|paths
argument_list|,
name|getPendingModifications
argument_list|()
operator|.
name|getPaths
argument_list|(
name|minRev
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|RevisionVector
name|rv
range|:
operator|new
name|RevisionVector
index|[]
block|{
name|fromRev
block|,
name|toRev
block|}
control|)
block|{
if|if
condition|(
name|rv
operator|.
name|isBranch
argument_list|()
condition|)
block|{
name|Revision
name|r
init|=
name|rv
operator|.
name|getBranchRevision
argument_list|()
decl_stmt|;
name|Branch
name|b
init|=
name|branches
operator|.
name|getBranch
argument_list|(
name|rv
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|addPathsForDiff
argument_list|(
name|path
argument_list|,
name|paths
argument_list|,
name|b
operator|.
name|getModifiedPathsUntil
argument_list|(
name|r
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|String
name|p
range|:
name|paths
control|)
block|{
name|DocumentNodeState
name|fromNode
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|fromRev
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|toNode
init|=
name|getNode
argument_list|(
name|p
argument_list|,
name|toRev
argument_list|)
decl_stmt|;
name|String
name|name
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"diffManyChildren: Changed Path {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
name|fromNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in fromRev
if|if
condition|(
name|toNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in both revisions
comment|// check if different
name|RevisionVector
name|a
init|=
name|fromNode
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
name|RevisionVector
name|b
init|=
name|toNode
operator|.
name|getLastRevision
argument_list|()
decl_stmt|;
if|if
condition|(
name|a
operator|==
literal|null
operator|&&
name|b
operator|==
literal|null
condition|)
block|{
comment|// ok
block|}
elseif|else
if|if
condition|(
name|a
operator|==
literal|null
operator|||
name|b
operator|==
literal|null
operator|||
operator|!
name|a
operator|.
name|equals
argument_list|(
name|b
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|name
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// does not exist in toRev -> was removed
name|w
operator|.
name|tag
argument_list|(
literal|'-'
argument_list|)
operator|.
name|value
argument_list|(
name|name
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// does not exist in fromRev
if|if
condition|(
name|toNode
operator|!=
literal|null
condition|)
block|{
comment|// exists in toRev
name|w
operator|.
name|tag
argument_list|(
literal|'+'
argument_list|)
operator|.
name|key
argument_list|(
name|name
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// does not exist in either revisions
comment|// -> do nothing
block|}
block|}
block|}
block|}
specifier|private
specifier|static
name|void
name|addPathsForDiff
parameter_list|(
name|String
name|path
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|paths
parameter_list|,
name|Iterable
argument_list|<
name|String
argument_list|>
name|modified
parameter_list|)
block|{
for|for
control|(
name|String
name|p
range|:
name|modified
control|)
block|{
if|if
condition|(
name|PathUtils
operator|.
name|denotesRoot
argument_list|(
name|p
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|String
name|parent
init|=
name|PathUtils
operator|.
name|getParentPath
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|equals
argument_list|(
name|parent
argument_list|)
condition|)
block|{
name|paths
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|diffFewChildren
parameter_list|(
name|JsopWriter
name|w
parameter_list|,
name|String
name|parentPath
parameter_list|,
name|DocumentNodeState
operator|.
name|Children
name|fromChildren
parameter_list|,
name|RevisionVector
name|fromRev
parameter_list|,
name|DocumentNodeState
operator|.
name|Children
name|toChildren
parameter_list|,
name|RevisionVector
name|toRev
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|childrenSet
init|=
name|Sets
operator|.
name|newHashSet
argument_list|(
name|toChildren
operator|.
name|children
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|n
range|:
name|fromChildren
operator|.
name|children
control|)
block|{
if|if
condition|(
operator|!
name|childrenSet
operator|.
name|contains
argument_list|(
name|n
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'-'
argument_list|)
operator|.
name|value
argument_list|(
name|n
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|path
init|=
name|concat
argument_list|(
name|parentPath
argument_list|,
name|n
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|n1
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|fromRev
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|n2
init|=
name|getNode
argument_list|(
name|path
argument_list|,
name|toRev
argument_list|)
decl_stmt|;
comment|// this is not fully correct:
comment|// a change is detected if the node changed recently,
comment|// even if the revisions are well in the past
comment|// if this is a problem it would need to be changed
name|checkNotNull
argument_list|(
name|n1
argument_list|,
literal|"Node at [%s] not found for fromRev [%s]"
argument_list|,
name|path
argument_list|,
name|fromRev
argument_list|)
expr_stmt|;
name|checkNotNull
argument_list|(
name|n2
argument_list|,
literal|"Node at [%s] not found for toRev [%s]"
argument_list|,
name|path
argument_list|,
name|toRev
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|n1
operator|.
name|getLastRevision
argument_list|()
operator|.
name|equals
argument_list|(
name|n2
operator|.
name|getLastRevision
argument_list|()
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'^'
argument_list|)
operator|.
name|key
argument_list|(
name|n
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|childrenSet
operator|=
name|Sets
operator|.
name|newHashSet
argument_list|(
name|fromChildren
operator|.
name|children
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|n
range|:
name|toChildren
operator|.
name|children
control|)
block|{
if|if
condition|(
operator|!
name|childrenSet
operator|.
name|contains
argument_list|(
name|n
argument_list|)
condition|)
block|{
name|w
operator|.
name|tag
argument_list|(
literal|'+'
argument_list|)
operator|.
name|key
argument_list|(
name|n
argument_list|)
operator|.
name|object
argument_list|()
operator|.
name|endObject
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
name|PathRev
name|childNodeCacheKey
parameter_list|(
annotation|@
name|Nonnull
name|String
name|path
parameter_list|,
annotation|@
name|Nonnull
name|RevisionVector
name|readRevision
parameter_list|,
annotation|@
name|Nullable
name|String
name|name
parameter_list|)
block|{
name|String
name|p
init|=
operator|(
name|name
operator|==
literal|null
condition|?
literal|""
else|:
name|name
operator|)
operator|+
name|path
decl_stmt|;
return|return
operator|new
name|PathRev
argument_list|(
name|p
argument_list|,
name|readRevision
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|DocumentRootBuilder
name|asDocumentRootBuilder
parameter_list|(
name|NodeBuilder
name|builder
parameter_list|)
throws|throws
name|IllegalArgumentException
block|{
if|if
condition|(
operator|!
operator|(
name|builder
operator|instanceof
name|DocumentRootBuilder
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"builder must be a "
operator|+
name|DocumentRootBuilder
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
return|return
operator|(
name|DocumentRootBuilder
operator|)
name|builder
return|;
block|}
specifier|private
specifier|static
name|long
name|now
parameter_list|()
block|{
return|return
name|System
operator|.
name|currentTimeMillis
argument_list|()
return|;
block|}
specifier|private
name|void
name|moveOrCopyNode
parameter_list|(
name|boolean
name|move
parameter_list|,
name|DocumentNodeState
name|source
parameter_list|,
name|String
name|targetPath
parameter_list|,
name|Commit
name|commit
parameter_list|)
block|{
comment|// TODO Optimize - Move logic would not work well with very move of very large subtrees
comment|// At minimum we can optimize by traversing breadth wise and collect node id
comment|// and fetch them via '$in' queries
comment|// TODO Transient Node - Current logic does not account for operations which are part
comment|// of this commit i.e. transient nodes. If its required it would need to be looked
comment|// into
name|RevisionVector
name|destRevision
init|=
name|commit
operator|.
name|getBaseRevision
argument_list|()
operator|.
name|update
argument_list|(
name|commit
operator|.
name|getRevision
argument_list|()
argument_list|)
decl_stmt|;
name|DocumentNodeState
name|newNode
init|=
operator|new
name|DocumentNodeState
argument_list|(
name|this
argument_list|,
name|targetPath
argument_list|,
name|destRevision
argument_list|)
decl_stmt|;
name|source
operator|.
name|copyTo
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
name|commit
operator|.
name|addNode
argument_list|(
name|newNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|move
condition|)
block|{
name|markAsDeleted
argument_list|(
name|source
argument_list|,
name|commit
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|DocumentNodeState
name|child
range|:
name|getChildNodes
argument_list|(
name|source
argument_list|,
literal|null
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
control|)
block|{
name|String
name|childName
init|=
name|PathUtils
operator|.
name|getName
argument_list|(
name|child
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|destChildPath
init|=
name|concat
argument_list|(
name|targetPath
argument_list|,
name|childName
argument_list|)
decl_stmt|;
name|moveOrCopyNode
argument_list|(
name|move
argument_list|,
name|child
argument_list|,
name|destChildPath
argument_list|,
name|commit
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Creates and returns a MarkSweepGarbageCollector if the current BlobStore      * supports garbage collection      *      * @param blobGcMaxAgeInSecs      * @param repositoryId      * @return garbage collector of the BlobStore supports GC otherwise null      */
annotation|@
name|CheckForNull
specifier|public
name|MarkSweepGarbageCollector
name|createBlobGarbageCollector
parameter_list|(
name|long
name|blobGcMaxAgeInSecs
parameter_list|,
name|String
name|repositoryId
parameter_list|)
block|{
name|MarkSweepGarbageCollector
name|blobGC
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|blobStore
operator|instanceof
name|GarbageCollectableBlobStore
condition|)
block|{
try|try
block|{
name|blobGC
operator|=
operator|new
name|MarkSweepGarbageCollector
argument_list|(
operator|new
name|DocumentBlobReferenceRetriever
argument_list|(
name|this
argument_list|)
argument_list|,
operator|(
name|GarbageCollectableBlobStore
operator|)
name|blobStore
argument_list|,
name|executor
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
operator|.
name|toMillis
argument_list|(
name|blobGcMaxAgeInSecs
argument_list|)
argument_list|,
name|repositoryId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Error occurred while initializing "
operator|+
literal|"the MarkSweepGarbageCollector"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|blobGC
return|;
block|}
name|void
name|setClusterStateChangeListener
parameter_list|(
name|ClusterStateChangeListener
name|clusterStateChangeListener
parameter_list|)
block|{
name|this
operator|.
name|clusterStateChangeListener
operator|=
name|clusterStateChangeListener
expr_stmt|;
block|}
name|void
name|signalClusterStateChange
parameter_list|()
block|{
if|if
condition|(
name|clusterStateChangeListener
operator|!=
literal|null
condition|)
block|{
name|clusterStateChangeListener
operator|.
name|handleClusterStateChange
argument_list|()
expr_stmt|;
block|}
block|}
comment|//-----------------------------< DocumentNodeStoreMBean>---------------------------------
specifier|public
name|DocumentNodeStoreMBean
name|getMBean
parameter_list|()
block|{
return|return
name|mbean
return|;
block|}
specifier|private
name|DocumentNodeStoreMBean
name|createMBean
parameter_list|()
block|{
try|try
block|{
return|return
operator|new
name|MBeanImpl
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|NotCompliantMBeanException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
class|class
name|MBeanImpl
extends|extends
name|AnnotatedStandardMBean
implements|implements
name|DocumentNodeStoreMBean
block|{
specifier|private
specifier|final
name|String
name|ISO_FORMAT
init|=
literal|"yyyy-MM-dd'T'HH:mm:ss.SSS zzz"
decl_stmt|;
specifier|private
specifier|final
name|TimeZone
name|TZ_UTC
init|=
name|TimeZone
operator|.
name|getTimeZone
argument_list|(
literal|"UTC"
argument_list|)
decl_stmt|;
specifier|protected
name|MBeanImpl
parameter_list|()
throws|throws
name|NotCompliantMBeanException
block|{
name|super
argument_list|(
name|DocumentNodeStoreMBean
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getRevisionComparatorState
parameter_list|()
block|{
return|return
literal|""
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getHead
parameter_list|()
block|{
return|return
name|getRoot
argument_list|()
operator|.
name|getRevision
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getUnmergedBranchCount
parameter_list|()
block|{
return|return
name|branches
operator|.
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
index|[]
name|getInactiveClusterNodes
parameter_list|()
block|{
return|return
name|toArray
argument_list|(
name|transform
argument_list|(
name|filter
argument_list|(
name|clusterNodes
operator|.
name|values
argument_list|()
argument_list|,
operator|new
name|Predicate
argument_list|<
name|ClusterNodeInfoDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
operator|!
name|input
operator|.
name|isActive
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
operator|new
name|Function
argument_list|<
name|ClusterNodeInfoDocument
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|getClusterId
argument_list|()
operator|+
literal|"="
operator|+
name|input
operator|.
name|getCreated
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
name|String
operator|.
name|class
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
index|[]
name|getActiveClusterNodes
parameter_list|()
block|{
return|return
name|toArray
argument_list|(
name|transform
argument_list|(
name|filter
argument_list|(
name|clusterNodes
operator|.
name|values
argument_list|()
argument_list|,
operator|new
name|Predicate
argument_list|<
name|ClusterNodeInfoDocument
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|isActive
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
operator|new
name|Function
argument_list|<
name|ClusterNodeInfoDocument
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|ClusterNodeInfoDocument
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|getClusterId
argument_list|()
operator|+
literal|"="
operator|+
name|input
operator|.
name|getLeaseEndTime
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
name|String
operator|.
name|class
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
index|[]
name|getLastKnownRevisions
parameter_list|()
block|{
return|return
name|toArray
argument_list|(
name|transform
argument_list|(
name|filter
argument_list|(
name|getHeadRevision
argument_list|()
argument_list|,
operator|new
name|Predicate
argument_list|<
name|Revision
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|apply
parameter_list|(
name|Revision
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|getClusterId
argument_list|()
operator|!=
name|getClusterId
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
operator|new
name|Function
argument_list|<
name|Revision
argument_list|,
name|String
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|Revision
name|input
parameter_list|)
block|{
return|return
name|input
operator|.
name|getClusterId
argument_list|()
operator|+
literal|"="
operator|+
name|input
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
argument_list|)
argument_list|,
name|String
operator|.
name|class
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|formatRevision
parameter_list|(
name|String
name|rev
parameter_list|,
name|boolean
name|utc
parameter_list|)
block|{
name|Revision
name|r
init|=
name|Revision
operator|.
name|fromString
argument_list|(
name|rev
argument_list|)
decl_stmt|;
specifier|final
name|SimpleDateFormat
name|sdf
init|=
operator|new
name|SimpleDateFormat
argument_list|(
name|ISO_FORMAT
argument_list|)
decl_stmt|;
if|if
condition|(
name|utc
condition|)
block|{
name|sdf
operator|.
name|setTimeZone
argument_list|(
name|TZ_UTC
argument_list|)
expr_stmt|;
block|}
return|return
name|sdf
operator|.
name|format
argument_list|(
name|r
operator|.
name|getTimestamp
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|determineServerTimeDifferenceMillis
parameter_list|()
block|{
return|return
name|store
operator|.
name|determineServerTimeDifferenceMillis
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompositeData
name|getMergeSuccessHistory
parameter_list|()
block|{
return|return
name|getTimeSeriesData
argument_list|(
name|DocumentNodeStoreStats
operator|.
name|MERGE_SUCCESS_COUNT
argument_list|,
literal|"Merge Success Count"
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompositeData
name|getMergeFailureHistory
parameter_list|()
block|{
return|return
name|getTimeSeriesData
argument_list|(
name|DocumentNodeStoreStats
operator|.
name|MERGE_FAILED_EXCLUSIVE
argument_list|,
literal|"Merge failure count"
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompositeData
name|getExternalChangeCountHistory
parameter_list|()
block|{
return|return
name|getTimeSeriesData
argument_list|(
name|DocumentNodeStoreStats
operator|.
name|BGR_NUM_CHANGES_RATE
argument_list|,
literal|"Count of nodes modified by other "
operator|+
literal|"cluster nodes since last background read"
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompositeData
name|getBackgroundUpdateCountHistory
parameter_list|()
block|{
return|return
name|getTimeSeriesData
argument_list|(
name|DocumentNodeStoreStats
operator|.
name|BGW_NUM_WRITES_RATE
argument_list|,
literal|"Count of nodes updated as part of "
operator|+
literal|"background update"
argument_list|)
return|;
block|}
specifier|private
name|CompositeData
name|getTimeSeriesData
parameter_list|(
name|String
name|name
parameter_list|,
name|String
name|desc
parameter_list|)
block|{
return|return
name|TimeSeriesStatsUtil
operator|.
name|asCompositeData
argument_list|(
name|getTimeSeries
argument_list|(
name|name
argument_list|)
argument_list|,
name|desc
argument_list|)
return|;
block|}
specifier|private
name|TimeSeries
name|getTimeSeries
parameter_list|(
name|String
name|name
parameter_list|)
block|{
return|return
name|statisticsProvider
operator|.
name|getStats
argument_list|()
operator|.
name|getTimeSeries
argument_list|(
name|name
argument_list|,
literal|true
argument_list|)
return|;
block|}
block|}
specifier|static
specifier|abstract
class|class
name|NodeStoreTask
implements|implements
name|Runnable
block|{
specifier|final
name|WeakReference
argument_list|<
name|DocumentNodeStore
argument_list|>
name|ref
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|isDisposed
decl_stmt|;
specifier|private
specifier|final
name|Supplier
argument_list|<
name|Integer
argument_list|>
name|delaySupplier
decl_stmt|;
name|NodeStoreTask
parameter_list|(
specifier|final
name|DocumentNodeStore
name|nodeStore
parameter_list|,
specifier|final
name|AtomicBoolean
name|isDisposed
parameter_list|,
name|Supplier
argument_list|<
name|Integer
argument_list|>
name|delay
parameter_list|)
block|{
name|this
operator|.
name|ref
operator|=
operator|new
name|WeakReference
argument_list|<
name|DocumentNodeStore
argument_list|>
argument_list|(
name|nodeStore
argument_list|)
expr_stmt|;
name|this
operator|.
name|isDisposed
operator|=
name|isDisposed
expr_stmt|;
if|if
condition|(
name|delay
operator|==
literal|null
condition|)
block|{
name|delay
operator|=
operator|new
name|Supplier
argument_list|<
name|Integer
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Integer
name|get
parameter_list|()
block|{
name|DocumentNodeStore
name|ns
init|=
name|ref
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
name|ns
operator|!=
literal|null
condition|?
name|ns
operator|.
name|getAsyncDelay
argument_list|()
else|:
literal|0
return|;
block|}
block|}
expr_stmt|;
block|}
name|this
operator|.
name|delaySupplier
operator|=
name|delay
expr_stmt|;
block|}
name|NodeStoreTask
parameter_list|(
specifier|final
name|DocumentNodeStore
name|nodeStore
parameter_list|,
specifier|final
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|this
argument_list|(
name|nodeStore
argument_list|,
name|isDisposed
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|protected
specifier|abstract
name|void
name|execute
parameter_list|(
annotation|@
name|Nonnull
name|DocumentNodeStore
name|nodeStore
parameter_list|)
function_decl|;
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|int
name|delay
init|=
name|delaySupplier
operator|.
name|get
argument_list|()
decl_stmt|;
while|while
condition|(
name|delay
operator|!=
literal|0
operator|&&
operator|!
name|isDisposed
operator|.
name|get
argument_list|()
condition|)
block|{
synchronized|synchronized
init|(
name|isDisposed
init|)
block|{
try|try
block|{
name|isDisposed
operator|.
name|wait
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// ignore
block|}
block|}
name|DocumentNodeStore
name|nodeStore
init|=
name|ref
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|nodeStore
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|execute
argument_list|(
name|nodeStore
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Background operation failed: "
operator|+
name|t
operator|.
name|toString
argument_list|()
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
name|delay
operator|=
name|delaySupplier
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// node store not in use anymore
break|break;
block|}
block|}
block|}
block|}
comment|/**      * Background operations.      */
specifier|static
class|class
name|BackgroundOperation
extends|extends
name|NodeStoreTask
block|{
name|BackgroundOperation
parameter_list|(
name|DocumentNodeStore
name|nodeStore
parameter_list|,
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|super
argument_list|(
name|nodeStore
argument_list|,
name|isDisposed
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|execute
parameter_list|(
annotation|@
name|Nonnull
name|DocumentNodeStore
name|nodeStore
parameter_list|)
block|{
name|nodeStore
operator|.
name|runBackgroundUpdateOperations
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Background read operations.      */
specifier|static
class|class
name|BackgroundReadOperation
extends|extends
name|NodeStoreTask
block|{
name|BackgroundReadOperation
parameter_list|(
name|DocumentNodeStore
name|nodeStore
parameter_list|,
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|super
argument_list|(
name|nodeStore
argument_list|,
name|isDisposed
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|execute
parameter_list|(
annotation|@
name|Nonnull
name|DocumentNodeStore
name|nodeStore
parameter_list|)
block|{
name|nodeStore
operator|.
name|runBackgroundReadOperations
argument_list|()
expr_stmt|;
block|}
block|}
specifier|static
class|class
name|BackgroundLeaseUpdate
extends|extends
name|NodeStoreTask
block|{
name|BackgroundLeaseUpdate
parameter_list|(
name|DocumentNodeStore
name|nodeStore
parameter_list|,
name|AtomicBoolean
name|isDisposed
parameter_list|)
block|{
name|super
argument_list|(
name|nodeStore
argument_list|,
name|isDisposed
argument_list|,
name|Suppliers
operator|.
name|ofInstance
argument_list|(
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|execute
parameter_list|(
annotation|@
name|Nonnull
name|DocumentNodeStore
name|nodeStore
parameter_list|)
block|{
comment|// first renew the clusterId lease
name|nodeStore
operator|.
name|renewClusterIdLease
argument_list|()
expr_stmt|;
comment|// then, independently if the lease had to be updated or not, check
comment|// the status:
if|if
condition|(
name|nodeStore
operator|.
name|updateClusterState
argument_list|()
condition|)
block|{
comment|// then inform the discovery lite listener - if it is registered
name|nodeStore
operator|.
name|signalClusterStateChange
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|BlobStore
name|getBlobStore
parameter_list|()
block|{
return|return
name|blobStore
return|;
block|}
name|BlobSerializer
name|getBlobSerializer
parameter_list|()
block|{
return|return
name|blobSerializer
return|;
block|}
comment|/**      * Returns an iterator for all the blob present in the store.      *      *<p>In some cases the iterator might implement {@link java.io.Closeable}. So      * callers should check for such iterator and close them</p>      *      * @see org.apache.jackrabbit.oak.plugins.document.mongo.MongoBlobReferenceIterator      * @return an iterator for all the blobs      */
specifier|public
name|Iterator
argument_list|<
name|ReferencedBlob
argument_list|>
name|getReferencedBlobsIterator
parameter_list|()
block|{
return|return
name|referencedBlobs
operator|.
name|iterator
argument_list|()
return|;
block|}
specifier|public
name|DiffCache
name|getDiffCache
parameter_list|()
block|{
return|return
name|diffCache
return|;
block|}
specifier|public
name|Clock
name|getClock
parameter_list|()
block|{
return|return
name|clock
return|;
block|}
specifier|public
name|Checkpoints
name|getCheckpoints
parameter_list|()
block|{
return|return
name|checkpoints
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|VersionGarbageCollector
name|getVersionGarbageCollector
parameter_list|()
block|{
return|return
name|versionGarbageCollector
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|JournalGarbageCollector
name|getJournalGarbageCollector
parameter_list|()
block|{
return|return
name|journalGarbageCollector
return|;
block|}
annotation|@
name|Nonnull
specifier|public
name|LastRevRecoveryAgent
name|getLastRevRecoveryAgent
parameter_list|()
block|{
return|return
name|lastRevRecoveryAgent
return|;
block|}
specifier|public
name|void
name|setPersistentCache
parameter_list|(
name|PersistentCache
name|persistentCache
parameter_list|)
block|{
name|this
operator|.
name|persistentCache
operator|=
name|persistentCache
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getInstanceId
parameter_list|()
block|{
return|return
name|String
operator|.
name|valueOf
argument_list|(
name|getClusterId
argument_list|()
argument_list|)
return|;
block|}
specifier|public
name|DocumentNodeStoreStatsCollector
name|getStatsCollector
parameter_list|()
block|{
return|return
name|nodeStoreStatsCollector
return|;
block|}
specifier|public
name|void
name|setNodeStateCache
parameter_list|(
name|DocumentNodeStateCache
name|nodeStateCache
parameter_list|)
block|{
name|this
operator|.
name|nodeStateCache
operator|=
name|nodeStateCache
expr_stmt|;
block|}
block|}
end_class

end_unit

