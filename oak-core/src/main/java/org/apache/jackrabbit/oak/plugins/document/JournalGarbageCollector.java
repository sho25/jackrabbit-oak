begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *   http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing,  * software distributed under the License is distributed on an  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY  * KIND, either express or implied.  See the License for the  * specific language governing permissions and limitations  * under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|jackrabbit
operator|.
name|oak
operator|.
name|plugins
operator|.
name|document
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Stopwatch
import|;
end_import

begin_comment
comment|/**  * The JournalGarbageCollector can clean up JournalEntries that are  * older than a particular age.  *<p>  * It would typically be invoked in conjunction with the VersionGarbageCollector  * but must not be confused with that one - 'journal' refers to the separate  * collection that contains changed paths per background writes used for   * observation.  */
end_comment

begin_class
specifier|public
class|class
name|JournalGarbageCollector
block|{
comment|//copied from VersionGarbageCollector:
specifier|private
specifier|static
specifier|final
name|int
name|DELETE_BATCH_SIZE
init|=
literal|450
decl_stmt|;
specifier|private
specifier|final
name|DocumentStore
name|ds
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|log
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|JournalGarbageCollector
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
name|JournalGarbageCollector
parameter_list|(
name|DocumentNodeStore
name|nodeStore
parameter_list|)
block|{
name|this
operator|.
name|ds
operator|=
name|nodeStore
operator|.
name|getDocumentStore
argument_list|()
expr_stmt|;
block|}
comment|/**      * Deletes entries in the journal that are older than the given maxRevisionAge.      * @param maxRevisionAge entries older than this age will be removed      * @param unit the timeunit for maxRevisionAge      * @return the number of entries that have been removed      */
specifier|public
name|int
name|gc
parameter_list|(
name|long
name|maxRevisionAge
parameter_list|,
name|TimeUnit
name|unit
parameter_list|)
block|{
name|long
name|maxRevisionAgeInMillis
init|=
name|unit
operator|.
name|toMillis
argument_list|(
name|maxRevisionAge
argument_list|)
decl_stmt|;
if|if
condition|(
name|log
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"gc: Journal garbage collection starts with maxAge: {} min."
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
operator|.
name|toMinutes
argument_list|(
name|maxRevisionAgeInMillis
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Stopwatch
name|sw
init|=
name|Stopwatch
operator|.
name|createStarted
argument_list|()
decl_stmt|;
comment|// the journal has ids of the following format:
comment|// 1-0000014db9aaf710-00000001
comment|// whereas the first number is the cluster node id.
comment|// now, this format prevents from doing a generic
comment|// query to get all 'old' entries, as the documentstore
comment|// can only query for a sequential list of entries.
comment|// (and the cluster node id here partitions the set
comment|// of entries that we have to delete)
comment|// To account for that, we simply iterate over all
comment|// cluster node ids and clean them up individually.
comment|// Note that there are possible alternatives, such
comment|// as: let each node clean up its own old entries
comment|// but the chosen path is also quite simple: it can
comment|// be started on any instance - but best on only one.
comment|// if it's run on multiple concurrently, then they
comment|// will compete at deletion, which is not optimal
comment|// due to performance, but does not harm.
comment|// 1. get the list of cluster node ids
specifier|final
name|List
argument_list|<
name|ClusterNodeInfoDocument
argument_list|>
name|clusterNodeInfos
init|=
name|ClusterNodeInfoDocument
operator|.
name|all
argument_list|(
name|ds
argument_list|)
decl_stmt|;
name|int
name|numDeleted
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|ClusterNodeInfoDocument
argument_list|>
name|it
init|=
name|clusterNodeInfos
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
comment|// current algorithm is to simply look at all cluster nodes
comment|// irrespective of whether they are active or inactive etc.
comment|// this could be optimized for inactive ones: at some point, all
comment|// journal entries of inactive ones would have been cleaned up
comment|// and at that point we could stop including those long-time-inactive ones.
comment|// that 'long time' aspect would have to be tracked though, to be sure
comment|// we don't leave garbage.
comment|// so simpler is to quickly do a query even for long-time inactive ones
specifier|final
name|ClusterNodeInfoDocument
name|clusterNodeInfoDocument
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
specifier|final
name|int
name|clusterNodeId
init|=
name|clusterNodeInfoDocument
operator|.
name|getClusterId
argument_list|()
decl_stmt|;
comment|// 2. iterate over that list and do a query with
comment|//    a limit of 'batch size'
name|boolean
name|branch
init|=
literal|false
decl_stmt|;
name|long
name|startPointer
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|String
name|fromKey
init|=
name|JournalEntry
operator|.
name|asId
argument_list|(
operator|new
name|Revision
argument_list|(
name|startPointer
argument_list|,
literal|0
argument_list|,
name|clusterNodeId
argument_list|,
name|branch
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|toKey
init|=
name|JournalEntry
operator|.
name|asId
argument_list|(
operator|new
name|Revision
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|maxRevisionAgeInMillis
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|,
name|clusterNodeId
argument_list|,
name|branch
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|limit
init|=
name|DELETE_BATCH_SIZE
decl_stmt|;
name|List
argument_list|<
name|JournalEntry
argument_list|>
name|deletionBatch
init|=
name|ds
operator|.
name|query
argument_list|(
name|Collection
operator|.
name|JOURNAL
argument_list|,
name|fromKey
argument_list|,
name|toKey
argument_list|,
name|limit
argument_list|)
decl_stmt|;
if|if
condition|(
name|deletionBatch
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|ds
operator|.
name|remove
argument_list|(
name|Collection
operator|.
name|JOURNAL
argument_list|,
name|asKeys
argument_list|(
name|deletionBatch
argument_list|)
argument_list|)
expr_stmt|;
name|numDeleted
operator|+=
name|deletionBatch
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|deletionBatch
operator|.
name|size
argument_list|()
operator|<
name|limit
condition|)
block|{
if|if
condition|(
operator|!
name|branch
condition|)
block|{
comment|// do the same for branches:
comment|// this will start at the beginning again with branch set to true
comment|// and eventually finish too
name|startPointer
operator|=
literal|0
expr_stmt|;
name|branch
operator|=
literal|true
expr_stmt|;
continue|continue;
block|}
break|break;
block|}
name|startPointer
operator|=
name|deletionBatch
operator|.
name|get
argument_list|(
name|deletionBatch
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getRevisionTimestamp
argument_list|()
expr_stmt|;
block|}
block|}
name|sw
operator|.
name|stop
argument_list|()
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"gc: Journal garbage collection took {}, deleted {} entries that were older than {} min."
argument_list|,
name|sw
argument_list|,
name|numDeleted
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
operator|.
name|toMinutes
argument_list|(
name|maxRevisionAgeInMillis
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|numDeleted
return|;
block|}
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|asKeys
parameter_list|(
name|List
argument_list|<
name|JournalEntry
argument_list|>
name|deletionBatch
parameter_list|)
block|{
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|keys
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|deletionBatch
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|JournalEntry
name|e
range|:
name|deletionBatch
control|)
block|{
name|keys
operator|.
name|add
argument_list|(
name|e
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|keys
return|;
block|}
block|}
end_class

end_unit

